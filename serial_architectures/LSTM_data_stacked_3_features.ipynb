{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,  mean_absolute_error, r2_score\n",
    " \n",
    "# tensorflow.reset_default_graph()\n",
    "tensorflow.random.set_seed(0)\n",
    "# random.seed(0)\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=14, day_offset=5):\n",
    "    dataX, dataY= [],[]\n",
    "    dataX=numpy.zeros([(len(dataset)-look_back),6,look_back])\n",
    "    \n",
    "    #print(dataX.shape)\n",
    "    for i in range(look_back,len(dataset)):\n",
    "       # print(i)\n",
    "        a = numpy.zeros([6,look_back])\n",
    "        t1=dataset[(i-look_back):i, 0]\n",
    "        t1=numpy.reshape(t1,[1,look_back])\n",
    "        t4=dataset[(i-look_back):i, 48]\n",
    "        t4=numpy.reshape(t4,[1,look_back])\n",
    "        #print(t1.shape)\n",
    "        t2=dataset[i, 48-look_back:48]\n",
    "        t2=numpy.reshape(t2,[1,look_back])\n",
    "        t6=dataset[i,-(look_back+3):-3]\n",
    "        t6=numpy.reshape(t6,[1,look_back])\n",
    "        t3=numpy.zeros([1,look_back])\n",
    "        if i>=((day_offset+1)*7+look_back):\n",
    "            t3[0,0:day_offset]=[dataset[j,0] for j in range(i-(((day_offset+1)*7)+look_back),i-(look_back+7),7)]\n",
    "        t5=numpy.zeros([1,look_back])\n",
    "        if i>=((day_offset+1)*7+look_back):\n",
    "            t5[0,0:day_offset]=[dataset[j,48] for j in range(i-(((day_offset+1)*7)+look_back),i-(look_back+7),7)]\n",
    "            \n",
    "            \n",
    "        #print(t2.shape)\n",
    "        a[0,:] = t1\n",
    "        a[1,:] = t4\n",
    "        a[2,:] = t2\n",
    "        a[3,:] = t6\n",
    "        a[4,:] = t3\n",
    "        a[5,:] = t5\n",
    "        dataX[i-look_back,:,:]=a\n",
    "#         a = numpy.concatenate([dataset[(i-look_back-7):i-7, 0], dataset[i,-14:]],axis=1)\n",
    "        \n",
    "        #dataX.append(a)\n",
    "        dataY.append(dataset[i,-1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(datarange, categorical=[]):  \n",
    "    datarange= pd.DataFrame(datarange)\n",
    "    if not categorical:\n",
    "        meandata=datarange.mean()\n",
    "        meandata=meandata.to_numpy()\n",
    "    else:\n",
    "        meandata=datarange.mean()\n",
    "        meandata=meandata.to_numpy()\n",
    "        \n",
    "        modedata = datarange.mode()\n",
    "        modedata = modedata.to_numpy()\n",
    "        modedata = modedata[0,:]\n",
    "        \n",
    "        for i in categorical:\n",
    "                meandata[i-1] = modedata[i]\n",
    "                \n",
    "    datetime_series = pd.to_datetime(datarange['fltdat'])\n",
    "    miss_idx=pd.date_range(start = '01-01-2015', end = '31-12-2019' ).difference(datetime_series)\n",
    "    datetime_index = pd.DatetimeIndex(datetime_series.values)\n",
    "    datarange=datarange.set_index(datetime_index)\n",
    "\n",
    "    datarange.drop('fltdat',axis=1,inplace=True)\n",
    "    newidx = pd.date_range('01-01-2015', '31-12-2019')\n",
    "    datarange = datarange.reindex(newidx, fill_value=0)\n",
    "    \n",
    "    meandata=meandata.reshape(1,meandata.shape[0])\n",
    "    dat = numpy.tile(meandata, [miss_idx.shape[0],1])\n",
    "    datarange.loc[miss_idx]=dat\n",
    "    return datarange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "        import numpy as np\n",
    "        t = np.array(y_test)\n",
    "        p = np.array(y_pred)\n",
    "        mae = list()\n",
    "        mape = list()\n",
    "        for i in range(len(t)):\n",
    "            if (t[i] == 0):\n",
    "                mae.append(abs(p[i]))\n",
    "            else:\n",
    "                mae.append(float(abs(t[i] - p[i])))\n",
    "                mape.append(float(abs((t[i] - p[i])/t[i])))\n",
    "        return np.mean(mae) , np.mean(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fltdat', 'paxcntfc', 'fltnum', 'legorg', 'legdst', 'acrtypcod',\n",
      "       'keyidr', 'totpaylodwgt', 'totpaylodvol', 'totpaylodpos', 'totsetfc',\n",
      "       'totpaxwgt', 'dp_51', 'dp_50', 'dp_49', 'dp_48', 'dp_47', 'dp_46',\n",
      "       'dp_45', 'dp_44', 'dp_43', 'dp_42', 'dp_41', 'dp_40', 'dp_39', 'dp_38',\n",
      "       'dp_37', 'dp_36', 'dp_35', 'dp_34', 'dp_33', 'dp_32', 'dp_31', 'dp_30',\n",
      "       'dp_29', 'dp_28', 'dp_27', 'dp_26', 'dp_25', 'dp_24', 'dp_23', 'dp_22',\n",
      "       'dp_21', 'dp_20', 'dp_19', 'dp_18', 'dp_17', 'dp_16', 'dp_15', 'dp_14',\n",
      "       'dp_13', 'dp_12', 'dp_11', 'dp_10', 'dp_9', 'dp_8', 'dp_7', 'dp_6',\n",
      "       'dp_5', 'dp_4', 'dp_3', 'dp_2', 'dp_1'],\n",
      "      dtype='object')\n",
      "Index(['fltdat', 'paxcntfc', 'acrtypcod', 'totpaylodwgt', 'totpaxwgt', 'dp_51',\n",
      "       'dp_50', 'dp_49', 'dp_48', 'dp_47', 'dp_46', 'dp_45', 'dp_44', 'dp_43',\n",
      "       'dp_42', 'dp_41', 'dp_40', 'dp_39', 'dp_38', 'dp_37', 'dp_36', 'dp_35',\n",
      "       'dp_34', 'dp_33', 'dp_32', 'dp_31', 'dp_30', 'dp_29', 'dp_28', 'dp_27',\n",
      "       'dp_26', 'dp_25', 'dp_24', 'dp_23', 'dp_22', 'dp_21', 'dp_20', 'dp_19',\n",
      "       'dp_18', 'dp_17', 'dp_16', 'dp_15', 'dp_14', 'dp_13', 'dp_12', 'dp_11',\n",
      "       'dp_10', 'dp_9', 'dp_8', 'paxcnty', 'dcp_51', 'dcp_50', 'dcp_49',\n",
      "       'dcp_48', 'dcp_47', 'dcp_46', 'dcp_45', 'dcp_44', 'dcp_43', 'dcp_42',\n",
      "       'dcp_41', 'dcp_40', 'dcp_39', 'dcp_38', 'dcp_37', 'dcp_36', 'dcp_35',\n",
      "       'dcp_34', 'dcp_33', 'dcp_3', 'dcp_31', 'dcp_30', 'dcp_29', 'dcp_28',\n",
      "       'dcp_27', 'dcp_26', 'dcp_25', 'dcp_24', 'dcp_23', 'dcp_22', 'dcp_21',\n",
      "       'dcp_20', 'dcp_19', 'dcp_18', 'dcp_17', 'dcp_16', 'dcp_15', 'dcp_14',\n",
      "       'dcp_13', 'dcp_12', 'dcp_11', 'dcp_10', 'dcp_9', 'dcp_8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('data/rmscapfc.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "print(dataframe.columns)\n",
    "dataframe.drop(dataframe.columns[[2,3,4,6,8,9,10,56,57,58,59,60,61,62] ], axis=1, inplace=True)\n",
    "\n",
    "dataframe2 = read_csv('data/rmscapy.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "# print(dataframe2.columns)\n",
    "f_column = dataframe2[[\"paxcnty\", \"dcp_51\", \"dcp_50\", \"dcp_49\", \"dcp_48\", \"dcp_47\", \"dcp_46\",\n",
    "       \"dcp_45\", \"dcp_44\", \"dcp_43\", \"dcp_42\", \"dcp_41\", \"dcp_40\", \"dcp_39\",\n",
    "       \"dcp_38\", \"dcp_37\", \"dcp_36\", \"dcp_35\", \"dcp_34\", \"dcp_33\", \"dcp_3\",\n",
    "       \"dcp_31\", \"dcp_30\", \"dcp_29\", \"dcp_28\", \"dcp_27\", \"dcp_26\", \"dcp_25\",\n",
    "       \"dcp_24\", \"dcp_23\", \"dcp_22\", \"dcp_21\", \"dcp_20\", \"dcp_19\", \"dcp_18\",\n",
    "       \"dcp_17\", \"dcp_16\", \"dcp_15\", \"dcp_14\", \"dcp_13\", \"dcp_12\", \"dcp_11\",\n",
    "       \"dcp_10\", \"dcp_9\", \"dcp_8\"]]\n",
    " \n",
    "\n",
    "dataframe = pd.concat([dataframe,f_column], axis = 1)\n",
    "# print(dataframe.columns)\n",
    "dataframe3 = read_csv('data/uldfc.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "\n",
    "dataframe3.drop(dataframe3.columns[[1,2,3] ], axis=1, inplace=True)\n",
    "dataframe4 = read_csv('data/uldy.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "dataframe4.drop(dataframe4.columns[[1,2,3] ], axis=1, inplace=True)\n",
    "f_column = dataframe4[[\"county\"]]\n",
    "dataframe3 = pd.concat([dataframe3,f_column], axis = 1)\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM=[0,1825,1825,1817,1816,1812,1821,1825,1824,1819,1825,1825,1824,1826,1819,1825,1822,1823,1813, 1826, 1820]\n",
    "NUMuld=[0,1817,1574,1808,1802,1807,1808,1730,1817,1385,1820,1816,1606,1819,1810,1817,421,1813,434,1532,1814]\n",
    "cat_inp=[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iist\\anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  import sys\n",
      "C:\\Users\\iist\\anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# dataset, datasetY = numpy.empty([1805,3,look_back]), []\n",
    "for i in range(0,len(NUM)-1):\n",
    "#     print(i)\n",
    "    datasub = dataframe.iloc[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "#     datasub=datasetall[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "    datasub = missing_values(datasub, cat_inp)\n",
    "    datasub = datasub.values\n",
    "    datasub = datasub.astype('float32')\n",
    "    \n",
    "    datasubuld = dataframe3.iloc[sum(NUMuld[0:i+1]):sum(NUMuld[0:i+2]),:]\n",
    "#     datasub=datasetall[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "    datasubuld = missing_values(datasubuld)\n",
    "    datasubuld = datasubuld.values\n",
    "    datasubuld = datasubuld.astype('float32')\n",
    "    \n",
    "    datasub = numpy.concatenate([datasub, datasubuld], axis=1)\n",
    "    if i==0:\n",
    "        data = datasub\n",
    "    else:\n",
    "        data = numpy.concatenate([data, datasub], axis =0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36520, 96)\n"
     ]
    }
   ],
   "source": [
    "out = data[:,2] - data[:,3] - (data[:,-1]*data[:,-2]*114)\n",
    "out = out.reshape(out.shape[0],1)\n",
    "data = numpy.concatenate([data,out], axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_data_build(data, look_back):\n",
    "    for i in range(0,20):\n",
    "        datasub = data[i*1826:((i+1)*1826),:]\n",
    "        X, Y = create_dataset(datasub, look_back)\n",
    "        Y = Y.reshape(Y.shape[0],1)\n",
    "        if i==0: \n",
    "            data_LSTM_X = X\n",
    "            data_LSTM_Y = Y\n",
    "        else:\n",
    "            data_LSTM_X = numpy.concatenate([data_LSTM_X, X],axis=0)\n",
    "            data_LSTM_Y = numpy.concatenate([data_LSTM_Y, Y],axis=0)\n",
    "    return data_LSTM_X, data_LSTM_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_build(X, Y, m1, m2):\n",
    "    spliter=int(X.shape[0]/20)\n",
    "    tot_len = m1\n",
    "    train_len = m2\n",
    "    for i in range(0,20):\n",
    "        Xsub = X[i*spliter:((i+1)*spliter),:]\n",
    "        Ysub = Y[i*spliter:((i+1)*spliter)]\n",
    "        if i==0:\n",
    "            trainX = Xsub[0:m2,:]\n",
    "            testX = Xsub[m2:m1,:]\n",
    "            trainY = Ysub[0:m2]\n",
    "            testY = Ysub[m2:m1]\n",
    "        else:\n",
    "            trainX = numpy.concatenate([trainX, Xsub[0:m2,:]], axis=0)\n",
    "            testX = numpy.concatenate([testX, Xsub[m2:m1,:]], axis=0)\n",
    "            trainY = numpy.concatenate([trainY, Ysub[0:m2]], axis=0)\n",
    "            testY = numpy.concatenate([testY, Ysub[m2:m1]], axis=0)\n",
    "        \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(trainX, trainY, testX, testY, units, saving =False, month=None, EarlyStop = False):\n",
    "    \n",
    "    if EarlyStop:\n",
    "        callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                                            mode = 'min', restore_best_weights=True)\n",
    "                                                                    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    if EarlyStop:\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=150, validation_data=(testX, testY),verbose=1,\n",
    "                            callbacks=[callback])\n",
    "    else:\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=150, validation_data=(testX, testY),verbose=1, )#callbacks=[callback]\n",
    "        \n",
    "                \n",
    "    testPredict = model.predict(testX)\n",
    "                \n",
    "    sh = testPredict.shape\n",
    "    inv_yhat = testPredict.reshape(sh[0]*sh[1],1)\n",
    "    inv_yhat = numpy.concatenate([ data[0:inv_yhat.shape[0],0:95], inv_yhat], axis=1)\n",
    "\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,-1]\n",
    "    testY = testY.reshape(sh[0]*sh[1],1)\n",
    " \n",
    "    inv_y = numpy.concatenate([data[0:testY.shape[0],0:95], testY], axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,-1]\n",
    "             \n",
    "    rmse = numpy.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    mae, mape = mean_absolute_percentage_error(inv_y, inv_yhat) \n",
    "    r2 = r2_score(inv_y, inv_yhat)\n",
    "    \n",
    "    res=[]\n",
    "    if saving:\n",
    "        inv_y = inv_y.reshape(inv_y.shape[0],1) \n",
    "        inv_yhat = inv_yhat.reshape(inv_yhat.shape[0],1) \n",
    "        res = numpy.concatenate([inv_y, inv_yhat], axis=1)\n",
    "        df = pd.DataFrame(res)\n",
    "        res = df.to_csv(\"ds_\" + month + \".csv\", index = False)\n",
    "    return rmse, mape,mae,r2, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(lag_vec = [7,14,21,28], units_vec = [2,4,8,16,32,64,128]):\n",
    "    results = numpy.zeros([4,3,len(lag_vec),len(units_vec)]) \n",
    "    for folds in range(0,3):\n",
    "        for i in range(0,len(lag_vec)):\n",
    "            data_LSTM_X, data_LSTM_Y = sequence_data_build(data, lag_vec[i])\n",
    "            lag = lag_vec[i]\n",
    "            totday = int(data_LSTM_X.shape[0]/20)\n",
    "#             print(totday)\n",
    "            m1 = [totday-152, totday-121, totday-91, ]\n",
    "            m2 = [m1[0]-31, m1[1]-31, m1[2]-30, ]\n",
    "            trainX, trainY, testX, testY= train_test_build(data_LSTM_X, data_LSTM_Y, m1[folds], m2[folds])\n",
    "            \n",
    "            testYcopy=testY\n",
    "            for j in range(0, len(units_vec)):\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"fold: {0}, lag: {1}, units: {2}\".format(folds, lag_vec[i], units_vec[j]))\n",
    "                units = units_vec[j]\n",
    "                rmse, mape, mae, r2, his = model_build(trainX, trainY, testX, testY, units, EarlyStop=True) \n",
    "                results[0,folds,i,j] = rmse \n",
    "                results[2,folds,i,j], results[1,folds,i,j] = mae, mape\n",
    "                results[3,folds,i,j] = r2\n",
    "    return results        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 2\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 166us/sample - loss: 0.1922 - val_loss: 0.1474\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1596 - val_loss: 0.1108\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1445 - val_loss: 0.1072\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1392 - val_loss: 0.1094\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1358 - val_loss: 0.1023\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1330 - val_loss: 0.1056\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1311 - val_loss: 0.0984\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1295 - val_loss: 0.1001\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1281 - val_loss: 0.0986\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1270 - val_loss: 0.1015\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1261 - val_loss: 0.1015\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1251 - val_loss: 0.1021\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1245 - val_loss: 0.0944\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1237 - val_loss: 0.0986\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1231 - val_loss: 0.0936\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1225 - val_loss: 0.0930\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1220 - val_loss: 0.0956\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1215 - val_loss: 0.0914\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1210 - val_loss: 0.0920\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1207 - val_loss: 0.0943\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 63us/sample - loss: 0.1203 - val_loss: 0.0937\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 63us/sample - loss: 0.1200 - val_loss: 0.0943\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1197 - val_loss: 0.0947\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1194 - val_loss: 0.0904\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1192 - val_loss: 0.0902\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1189 - val_loss: 0.0924\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1186 - val_loss: 0.0903\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 63us/sample - loss: 0.1184 - val_loss: 0.0917\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1182 - val_loss: 0.0900\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1179 - val_loss: 0.0903\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1178 - val_loss: 0.0905\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1175 - val_loss: 0.0959\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1175 - val_loss: 0.0912\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1173 - val_loss: 0.0876\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1172 - val_loss: 0.0915\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1169 - val_loss: 0.0908\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1167 - val_loss: 0.0875\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1166 - val_loss: 0.0881\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1164 - val_loss: 0.0883\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1164 - val_loss: 0.0879\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1162 - val_loss: 0.0896\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1161 - val_loss: 0.0890\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1160 - val_loss: 0.0908\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1158 - val_loss: 0.0900\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1158 - val_loss: 0.0882\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1157 - val_loss: 0.0916\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1155 - val_loss: 0.0897\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 4\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 164us/sample - loss: 0.1735 - val_loss: 0.1150\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1441 - val_loss: 0.1072\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1362 - val_loss: 0.1074\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1317 - val_loss: 0.1068\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1282 - val_loss: 0.0982\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1250 - val_loss: 0.1001\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1223 - val_loss: 0.0924\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1198 - val_loss: 0.0909\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1180 - val_loss: 0.0925\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1169 - val_loss: 0.0914\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1160 - val_loss: 0.0967\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1153 - val_loss: 0.0936\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1146 - val_loss: 0.0924\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1142 - val_loss: 0.0916\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1136 - val_loss: 0.0889\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1131 - val_loss: 0.0933\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1128 - val_loss: 0.0917\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1120 - val_loss: 0.0909\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1115 - val_loss: 0.0910\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1110 - val_loss: 0.0909\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1104 - val_loss: 0.0864\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1098 - val_loss: 0.0866\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1091 - val_loss: 0.0878\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.1084 - val_loss: 0.0859\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.1078 - val_loss: 0.0834\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1070 - val_loss: 0.0842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1061 - val_loss: 0.0812\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1056 - val_loss: 0.0854\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1048 - val_loss: 0.0808\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1042 - val_loss: 0.0830\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1036 - val_loss: 0.0787\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1032 - val_loss: 0.0774\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.1028 - val_loss: 0.0772\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1023 - val_loss: 0.0758\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.1021 - val_loss: 0.0755\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1018 - val_loss: 0.0801\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1016 - val_loss: 0.0760\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1013 - val_loss: 0.0747\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1012 - val_loss: 0.0748\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1008 - val_loss: 0.0718\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1008 - val_loss: 0.0753\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1004 - val_loss: 0.0741\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1004 - val_loss: 0.0721\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0722\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0723\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0999 - val_loss: 0.0738\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0997 - val_loss: 0.0717\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0996 - val_loss: 0.0711\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0994 - val_loss: 0.0718\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0993 - val_loss: 0.0713\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0717\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0990 - val_loss: 0.0702\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0988 - val_loss: 0.0716\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0988 - val_loss: 0.0723\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0986 - val_loss: 0.0754\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0986 - val_loss: 0.0706\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0984 - val_loss: 0.0686\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0984 - val_loss: 0.0705\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0983 - val_loss: 0.0685\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0983 - val_loss: 0.0720\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0982 - val_loss: 0.0719\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0980 - val_loss: 0.0737\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0980 - val_loss: 0.0683\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0978 - val_loss: 0.0697\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0979 - val_loss: 0.0695\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0688\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0977 - val_loss: 0.0712\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0685\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 63us/sample - loss: 0.0975 - val_loss: 0.0679\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0974 - val_loss: 0.0693\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0974 - val_loss: 0.0692\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0730\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0972 - val_loss: 0.0681\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0972 - val_loss: 0.0683\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0972 - val_loss: 0.0682\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0972 - val_loss: 0.0680\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0970 - val_loss: 0.0733\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0969 - val_loss: 0.0706\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0970 - val_loss: 0.0684\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 8\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 146us/sample - loss: 0.1566 - val_loss: 0.1104\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1334 - val_loss: 0.1049\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1289 - val_loss: 0.0961\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1248 - val_loss: 0.0968\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1213 - val_loss: 0.0963\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1188 - val_loss: 0.0958\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1169 - val_loss: 0.0937\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1159 - val_loss: 0.0856\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1147 - val_loss: 0.0932\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1140 - val_loss: 0.0949\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1130 - val_loss: 0.0879\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1119 - val_loss: 0.0844\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1109 - val_loss: 0.0883\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1099 - val_loss: 0.0822\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1091 - val_loss: 0.0809\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1077 - val_loss: 0.0828\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1072 - val_loss: 0.0794\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1065 - val_loss: 0.0755\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1058 - val_loss: 0.0761\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1054 - val_loss: 0.0736\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1050 - val_loss: 0.0783\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1044 - val_loss: 0.0738\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1043 - val_loss: 0.0724\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1036 - val_loss: 0.0726\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1032 - val_loss: 0.0743\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0719\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1025 - val_loss: 0.0707\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1023 - val_loss: 0.0793\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1021 - val_loss: 0.0713\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1017 - val_loss: 0.0750\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1012 - val_loss: 0.0686\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1011 - val_loss: 0.0708\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1007 - val_loss: 0.0707\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1004 - val_loss: 0.0679\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0677\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0679\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0994 - val_loss: 0.0668\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0682\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0992 - val_loss: 0.0684\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0990 - val_loss: 0.0665\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0989 - val_loss: 0.0745\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0986 - val_loss: 0.0686\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0983 - val_loss: 0.0657\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0982 - val_loss: 0.0682\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0981 - val_loss: 0.0649\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0980 - val_loss: 0.0677\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0978 - val_loss: 0.0665\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0978 - val_loss: 0.0649\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0977 - val_loss: 0.0646\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0975 - val_loss: 0.0643\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0974 - val_loss: 0.0661\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0973 - val_loss: 0.0686\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0973 - val_loss: 0.0644\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0971 - val_loss: 0.0670\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0971 - val_loss: 0.0702\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0972 - val_loss: 0.0649\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0970 - val_loss: 0.0642\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0968 - val_loss: 0.0648\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0969 - val_loss: 0.0650\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0968 - val_loss: 0.0675\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0967 - val_loss: 0.0660\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0966 - val_loss: 0.0704\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0966 - val_loss: 0.0644\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0668\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0963 - val_loss: 0.0638\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0961 - val_loss: 0.0660\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0963 - val_loss: 0.0675\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0962 - val_loss: 0.0651\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0960 - val_loss: 0.0618\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0959 - val_loss: 0.0639\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0961 - val_loss: 0.0648\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0958 - val_loss: 0.0640\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0961 - val_loss: 0.0626\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0957 - val_loss: 0.0637\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0635\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0956 - val_loss: 0.0626\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0955 - val_loss: 0.0666\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0956 - val_loss: 0.0630\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0957 - val_loss: 0.0665\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 16\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 6s 169us/sample - loss: 0.1525 - val_loss: 0.1021\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1301 - val_loss: 0.1052\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1257 - val_loss: 0.0942\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1209 - val_loss: 0.1016\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1179 - val_loss: 0.0976\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1151 - val_loss: 0.0998\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1136 - val_loss: 0.0898\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1120 - val_loss: 0.0829\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1106 - val_loss: 0.0899\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1090 - val_loss: 0.0893\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1078 - val_loss: 0.0789\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1062 - val_loss: 0.0790\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1049 - val_loss: 0.0764\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1040 - val_loss: 0.0798\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1032 - val_loss: 0.0742\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1025 - val_loss: 0.0746\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1018 - val_loss: 0.0720\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1015 - val_loss: 0.0711\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1007 - val_loss: 0.0700\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1003 - val_loss: 0.0679\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0693\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.0996 - val_loss: 0.0678\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.0991 - val_loss: 0.0666\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0986 - val_loss: 0.0663\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0988 - val_loss: 0.0644\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0983 - val_loss: 0.0695\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0981 - val_loss: 0.0664\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0980 - val_loss: 0.0665\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0977 - val_loss: 0.0653\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0975 - val_loss: 0.0653\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0971 - val_loss: 0.0650\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0969 - val_loss: 0.0640\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0966 - val_loss: 0.0628\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0963 - val_loss: 0.0620\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0963 - val_loss: 0.0631\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0960 - val_loss: 0.0626\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0955 - val_loss: 0.0629\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0957 - val_loss: 0.0630\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0956 - val_loss: 0.0635\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0955 - val_loss: 0.0622\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0952 - val_loss: 0.0669\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0949 - val_loss: 0.0631\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0950 - val_loss: 0.0615\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0948 - val_loss: 0.0601\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0946 - val_loss: 0.0630\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0944 - val_loss: 0.0606\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0943 - val_loss: 0.0619\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0940 - val_loss: 0.0615\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0946 - val_loss: 0.0614\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0650\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0939 - val_loss: 0.0595\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0613\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0935 - val_loss: 0.0591\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0933 - val_loss: 0.0627\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0934 - val_loss: 0.0602\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0931 - val_loss: 0.0606\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0934 - val_loss: 0.0611\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0929 - val_loss: 0.0602\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0930 - val_loss: 0.0653\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0931 - val_loss: 0.0625\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0927 - val_loss: 0.0614\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0924 - val_loss: 0.0600\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0922 - val_loss: 0.0593\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 32\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 147us/sample - loss: 0.1479 - val_loss: 0.1025\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1241 - val_loss: 0.0914\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1197 - val_loss: 0.0986\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1178 - val_loss: 0.0954\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.1172 - val_loss: 0.0908\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1160 - val_loss: 0.0966\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.1150 - val_loss: 0.0953\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1137 - val_loss: 0.0867\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1127 - val_loss: 0.0903\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1105 - val_loss: 0.0855\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1095 - val_loss: 0.0780\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1085 - val_loss: 0.0786\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1073 - val_loss: 0.0777\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1060 - val_loss: 0.0878\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.1052 - val_loss: 0.0737\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1040 - val_loss: 0.0866\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1038 - val_loss: 0.0807\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 63us/sample - loss: 0.1030 - val_loss: 0.0733\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1021 - val_loss: 0.0686\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1013 - val_loss: 0.0753\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1009 - val_loss: 0.0689\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1002 - val_loss: 0.0696\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1002 - val_loss: 0.0681\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0988 - val_loss: 0.0656\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0987 - val_loss: 0.0651\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0980 - val_loss: 0.0685\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0981 - val_loss: 0.0663\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0710\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0663\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0967 - val_loss: 0.0665\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0960 - val_loss: 0.0643\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0961 - val_loss: 0.0645\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0954 - val_loss: 0.0625\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0950 - val_loss: 0.0616\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0947 - val_loss: 0.0631\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0946 - val_loss: 0.0610\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0941 - val_loss: 0.0642\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0940 - val_loss: 0.0619\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0940 - val_loss: 0.0618\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0937 - val_loss: 0.0615\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0936 - val_loss: 0.0639\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0935 - val_loss: 0.0621\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0928 - val_loss: 0.0612\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0931 - val_loss: 0.0624\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0928 - val_loss: 0.0623\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0927 - val_loss: 0.0602\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0926 - val_loss: 0.0631\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0640\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0618\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0921 - val_loss: 0.0602\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0917 - val_loss: 0.0627\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.0919 - val_loss: 0.0615\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0917 - val_loss: 0.0604\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0914 - val_loss: 0.0626\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0914 - val_loss: 0.0610\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 62us/sample - loss: 0.0913 - val_loss: 0.0610\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 64\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 6s 180us/sample - loss: 0.1418 - val_loss: 0.0882\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.1211 - val_loss: 0.0919\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.1192 - val_loss: 0.0953\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.1178 - val_loss: 0.0994\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.1173 - val_loss: 0.0956\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.1159 - val_loss: 0.0974\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.1144 - val_loss: 0.0949\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.1122 - val_loss: 0.0915\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.1106 - val_loss: 0.0894\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.1086 - val_loss: 0.0935\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.1081 - val_loss: 0.0869\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.1067 - val_loss: 0.0791\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.1057 - val_loss: 0.0790\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.1039 - val_loss: 0.0790\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.1026 - val_loss: 0.0756\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.1017 - val_loss: 0.0973\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.1007 - val_loss: 0.0731\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0999 - val_loss: 0.0707\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0991 - val_loss: 0.0669\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0987 - val_loss: 0.0731\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0979 - val_loss: 0.0660\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0972 - val_loss: 0.0661\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0964 - val_loss: 0.0629\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0957 - val_loss: 0.0628\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 68us/sample - loss: 0.0954 - val_loss: 0.0626\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0960 - val_loss: 0.0637\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0950 - val_loss: 0.0621\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0946 - val_loss: 0.0639\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0943 - val_loss: 0.0606\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0942 - val_loss: 0.0668\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0936 - val_loss: 0.0612\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0931 - val_loss: 0.0612\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0932 - val_loss: 0.0590\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0924 - val_loss: 0.0582\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0922 - val_loss: 0.0577\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0921 - val_loss: 0.0584\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0917 - val_loss: 0.0567\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0916 - val_loss: 0.0613\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 66us/sample - loss: 0.0917 - val_loss: 0.0605\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 64us/sample - loss: 0.0915 - val_loss: 0.0588\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 66us/sample - loss: 0.0910 - val_loss: 0.0560\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0909 - val_loss: 0.0574\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0907 - val_loss: 0.0570\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0911 - val_loss: 0.0568\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0906 - val_loss: 0.0606\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0902 - val_loss: 0.0554\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0901 - val_loss: 0.0569\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0898 - val_loss: 0.0562\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0899 - val_loss: 0.0561\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0892 - val_loss: 0.0553\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0892 - val_loss: 0.0563\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0894 - val_loss: 0.0575\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0889 - val_loss: 0.0561\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0888 - val_loss: 0.0573\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0889 - val_loss: 0.0553\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0886 - val_loss: 0.0552\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0884 - val_loss: 0.0547\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0885 - val_loss: 0.0566\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0887 - val_loss: 0.0583\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0882 - val_loss: 0.0562\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0882 - val_loss: 0.0591\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0879 - val_loss: 0.0539\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0877 - val_loss: 0.0537\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0877 - val_loss: 0.0574\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0874 - val_loss: 0.0572\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0873 - val_loss: 0.0545\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0871 - val_loss: 0.0541\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0873 - val_loss: 0.0686\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0869 - val_loss: 0.0520\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0868 - val_loss: 0.0540\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0868 - val_loss: 0.0573\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0866 - val_loss: 0.0552\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0866 - val_loss: 0.0527\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0862 - val_loss: 0.0539\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0862 - val_loss: 0.0520\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0862 - val_loss: 0.0552\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0862 - val_loss: 0.0558\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 73us/sample - loss: 0.0856 - val_loss: 0.0533\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 72us/sample - loss: 0.0859 - val_loss: 0.0542\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 69us/sample - loss: 0.0859 - val_loss: 0.0530\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0855 - val_loss: 0.0520\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0854 - val_loss: 0.0529\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0854 - val_loss: 0.0533\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 70us/sample - loss: 0.0854 - val_loss: 0.0545\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 71us/sample - loss: 0.0855 - val_loss: 0.0530\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 128\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 7s 203us/sample - loss: 0.1393 - val_loss: 0.0902\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.1211 - val_loss: 0.0970\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.1191 - val_loss: 0.0954\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.1181 - val_loss: 0.0990\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.1163 - val_loss: 0.0887\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.1133 - val_loss: 0.0892\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.1109 - val_loss: 0.0839\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.1083 - val_loss: 0.0788\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.1053 - val_loss: 0.0737\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.1036 - val_loss: 0.0734\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.1025 - val_loss: 0.0739\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.1014 - val_loss: 0.0723\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 4s 111us/sample - loss: 0.0996 - val_loss: 0.0719\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0988 - val_loss: 0.0671\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0985 - val_loss: 0.0644\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0976 - val_loss: 0.0684\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0972 - val_loss: 0.0639\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0970 - val_loss: 0.0639\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0959 - val_loss: 0.0633\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0954 - val_loss: 0.0695\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0951 - val_loss: 0.0615\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0945 - val_loss: 0.0660\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0942 - val_loss: 0.0614\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 4s 111us/sample - loss: 0.0938 - val_loss: 0.0611\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0935 - val_loss: 0.0589\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0928 - val_loss: 0.0619\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0927 - val_loss: 0.0599\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0927 - val_loss: 0.0596\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0922 - val_loss: 0.0588\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0917 - val_loss: 0.0613\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0911 - val_loss: 0.0594\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0912 - val_loss: 0.0599\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0912 - val_loss: 0.0573\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0904 - val_loss: 0.0583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0902 - val_loss: 0.0571\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0901 - val_loss: 0.0579\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0896 - val_loss: 0.0570\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0897 - val_loss: 0.0585\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0894 - val_loss: 0.0569\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0891 - val_loss: 0.0556\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0890 - val_loss: 0.0572\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0887 - val_loss: 0.0594\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0887 - val_loss: 0.0565\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 4s 116us/sample - loss: 0.0884 - val_loss: 0.0562\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0880 - val_loss: 0.0574\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 4s 111us/sample - loss: 0.0877 - val_loss: 0.0549\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0876 - val_loss: 0.0551\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 4s 111us/sample - loss: 0.0870 - val_loss: 0.0568\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0873 - val_loss: 0.0560\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0866 - val_loss: 0.0553\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0867 - val_loss: 0.0557\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0867 - val_loss: 0.0541\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0861 - val_loss: 0.0566\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0861 - val_loss: 0.0585\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0860 - val_loss: 0.0535\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0855 - val_loss: 0.0543\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0853 - val_loss: 0.0549\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0852 - val_loss: 0.0547\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0851 - val_loss: 0.0574\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0851 - val_loss: 0.0554\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0845 - val_loss: 0.0558\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 4s 112us/sample - loss: 0.0845 - val_loss: 0.0553\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 4s 113us/sample - loss: 0.0842 - val_loss: 0.0544\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 4s 114us/sample - loss: 0.0838 - val_loss: 0.0556\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 4s 115us/sample - loss: 0.0834 - val_loss: 0.0574\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 2\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 6s 178us/sample - loss: 0.1819 - val_loss: 0.1238\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1453 - val_loss: 0.0976\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1344 - val_loss: 0.1003\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1315 - val_loss: 0.0935\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1299 - val_loss: 0.0966\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1287 - val_loss: 0.0956\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1278 - val_loss: 0.0939\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1270 - val_loss: 0.0984\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1263 - val_loss: 0.0960\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1257 - val_loss: 0.0927\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1250 - val_loss: 0.0936\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1246 - val_loss: 0.0932\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1242 - val_loss: 0.0904\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1236 - val_loss: 0.0959\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1234 - val_loss: 0.0942\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1230 - val_loss: 0.0935\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1225 - val_loss: 0.0952\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1222 - val_loss: 0.0927\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1218 - val_loss: 0.0966\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1215 - val_loss: 0.0909\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1211 - val_loss: 0.0894\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1208 - val_loss: 0.0887\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1205 - val_loss: 0.0923\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1202 - val_loss: 0.0964\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1203 - val_loss: 0.0948\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1198 - val_loss: 0.0919\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1193 - val_loss: 0.0991\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1192 - val_loss: 0.0930\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1188 - val_loss: 0.0939\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1186 - val_loss: 0.0933\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1184 - val_loss: 0.0932\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1181 - val_loss: 0.0940\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 4\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 153us/sample - loss: 0.1675 - val_loss: 0.1064\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1396 - val_loss: 0.1042\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1343 - val_loss: 0.1071\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1307 - val_loss: 0.0944\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1277 - val_loss: 0.0984\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1252 - val_loss: 0.0924\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1231 - val_loss: 0.0937\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1211 - val_loss: 0.0964\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1199 - val_loss: 0.1019\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1184 - val_loss: 0.0948\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1169 - val_loss: 0.0880\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1157 - val_loss: 0.0873\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1152 - val_loss: 0.0820\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1139 - val_loss: 0.0863\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1128 - val_loss: 0.0886\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1119 - val_loss: 0.0822\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.1111 - val_loss: 0.0856\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1099 - val_loss: 0.0823\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1092 - val_loss: 0.0839\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1086 - val_loss: 0.0805\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1079 - val_loss: 0.0818\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.1072 - val_loss: 0.0832\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1068 - val_loss: 0.0829\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1063 - val_loss: 0.0781\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1059 - val_loss: 0.0767\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1055 - val_loss: 0.0782\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1052 - val_loss: 0.0823\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1051 - val_loss: 0.0843\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1047 - val_loss: 0.0827\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1043 - val_loss: 0.0774\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1039 - val_loss: 0.0785\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1037 - val_loss: 0.0737\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1036 - val_loss: 0.0768\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1033 - val_loss: 0.0773\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1028 - val_loss: 0.0738\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1024 - val_loss: 0.0798\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1023 - val_loss: 0.0781\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1023 - val_loss: 0.0784\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1019 - val_loss: 0.0742\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1014 - val_loss: 0.0730\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1011 - val_loss: 0.0766\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 64us/sample - loss: 0.1009 - val_loss: 0.0792\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1007 - val_loss: 0.0757\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1005 - val_loss: 0.0730\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1003 - val_loss: 0.0722\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1000 - val_loss: 0.0799\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1000 - val_loss: 0.0766\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0998 - val_loss: 0.0779\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0996 - val_loss: 0.0720\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0995 - val_loss: 0.0761\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0994 - val_loss: 0.0744\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0990 - val_loss: 0.0713\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0992 - val_loss: 0.0743\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0988 - val_loss: 0.0720\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0988 - val_loss: 0.0765\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0991 - val_loss: 0.0706\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0985 - val_loss: 0.0714\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0982 - val_loss: 0.0699\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0979 - val_loss: 0.0724\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0981 - val_loss: 0.0798\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0981 - val_loss: 0.0727\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0979 - val_loss: 0.0766\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0977 - val_loss: 0.0711\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0977 - val_loss: 0.0704\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0975 - val_loss: 0.0804\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0974 - val_loss: 0.0691\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0718\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0972 - val_loss: 0.0686\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0970 - val_loss: 0.0699\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0970 - val_loss: 0.0686\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0971 - val_loss: 0.0688\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0969 - val_loss: 0.0764\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0968 - val_loss: 0.0724\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0969 - val_loss: 0.0687\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0968 - val_loss: 0.0719\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0725\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0966 - val_loss: 0.0688\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0964 - val_loss: 0.0686\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 8\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 166us/sample - loss: 0.1693 - val_loss: 0.1074\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1330 - val_loss: 0.0968\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1266 - val_loss: 0.1041\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1219 - val_loss: 0.0934\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1190 - val_loss: 0.0894\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1172 - val_loss: 0.0852\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1153 - val_loss: 0.0875\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1136 - val_loss: 0.0814\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1121 - val_loss: 0.0828\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1110 - val_loss: 0.0798\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1091 - val_loss: 0.0818\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1078 - val_loss: 0.0772\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1066 - val_loss: 0.0736\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1053 - val_loss: 0.0733\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1042 - val_loss: 0.0725\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1032 - val_loss: 0.0695\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1023 - val_loss: 0.0730\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1017 - val_loss: 0.0710\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1014 - val_loss: 0.0719\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1013 - val_loss: 0.0682\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1006 - val_loss: 0.0693\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1003 - val_loss: 0.0719\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1001 - val_loss: 0.0716\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0997 - val_loss: 0.0688\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0996 - val_loss: 0.0684\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0992 - val_loss: 0.0667\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0988 - val_loss: 0.0730\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0987 - val_loss: 0.0682\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0987 - val_loss: 0.0672\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0987 - val_loss: 0.0678\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0985 - val_loss: 0.0660\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0980 - val_loss: 0.0666\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0981 - val_loss: 0.0662\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0982 - val_loss: 0.0671\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0977 - val_loss: 0.0660\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0660\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0674\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0971 - val_loss: 0.0650\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0972 - val_loss: 0.0655\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0969 - val_loss: 0.0651\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0966 - val_loss: 0.0668\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0966 - val_loss: 0.0683\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0965 - val_loss: 0.0680\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0961 - val_loss: 0.0663\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0962 - val_loss: 0.0659\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0960 - val_loss: 0.0643\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0964 - val_loss: 0.0667\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0961 - val_loss: 0.0672\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0957 - val_loss: 0.0700\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0963 - val_loss: 0.0650\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0956 - val_loss: 0.0651\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0955 - val_loss: 0.0653\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0957 - val_loss: 0.0646\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0953 - val_loss: 0.0654\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0956 - val_loss: 0.0712\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0960 - val_loss: 0.0671\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 16\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 146us/sample - loss: 0.1526 - val_loss: 0.1041\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1247 - val_loss: 0.0896\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1191 - val_loss: 0.0983\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1155 - val_loss: 0.0895\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1136 - val_loss: 0.0897\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1121 - val_loss: 0.0847\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1105 - val_loss: 0.0841\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1090 - val_loss: 0.0853\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1075 - val_loss: 0.0858\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1059 - val_loss: 0.0776\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1040 - val_loss: 0.0821\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1024 - val_loss: 0.0733\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1009 - val_loss: 0.0725\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1004 - val_loss: 0.0742\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0991 - val_loss: 0.0738\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0985 - val_loss: 0.0678\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0981 - val_loss: 0.0688\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0977 - val_loss: 0.0671\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0974 - val_loss: 0.0681\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0972 - val_loss: 0.0654\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0965 - val_loss: 0.0667\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0966 - val_loss: 0.0655\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0961 - val_loss: 0.0710\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0957 - val_loss: 0.0654\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0960 - val_loss: 0.0645\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0955 - val_loss: 0.0635\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0953 - val_loss: 0.0640\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0951 - val_loss: 0.0649\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0947 - val_loss: 0.0620\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0944 - val_loss: 0.0641\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0942 - val_loss: 0.0630\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0943 - val_loss: 0.0645\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0936 - val_loss: 0.0625\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0939 - val_loss: 0.0658\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0937 - val_loss: 0.0639\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0929 - val_loss: 0.0634\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0931 - val_loss: 0.0622\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0930 - val_loss: 0.0617\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0620\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0604\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0923 - val_loss: 0.0621\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0927 - val_loss: 0.0683\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0619\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0919 - val_loss: 0.0606\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0918 - val_loss: 0.0604\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0916 - val_loss: 0.0604\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0915 - val_loss: 0.0626\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0916 - val_loss: 0.0618\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0913 - val_loss: 0.0605\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0913 - val_loss: 0.0602\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0914 - val_loss: 0.0602\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0909 - val_loss: 0.0608\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0908 - val_loss: 0.0592\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0907 - val_loss: 0.0602\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0906 - val_loss: 0.0622\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0907 - val_loss: 0.0595\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0903 - val_loss: 0.0601\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0899 - val_loss: 0.0598\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0900 - val_loss: 0.0602\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0899 - val_loss: 0.0614\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0900 - val_loss: 0.0604\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0896 - val_loss: 0.0653\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0595\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 32\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 162us/sample - loss: 0.1439 - val_loss: 0.0956\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1207 - val_loss: 0.0966\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1178 - val_loss: 0.1066\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1164 - val_loss: 0.0868\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1160 - val_loss: 0.0941\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1140 - val_loss: 0.0911\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1128 - val_loss: 0.0944\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1120 - val_loss: 0.0914\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1096 - val_loss: 0.0865\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1080 - val_loss: 0.0809\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1068 - val_loss: 0.0957\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1056 - val_loss: 0.0812\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1052 - val_loss: 0.0786\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1035 - val_loss: 0.0797\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1025 - val_loss: 0.0884\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.1016 - val_loss: 0.0721\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1013 - val_loss: 0.0804\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1009 - val_loss: 0.0736\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0998 - val_loss: 0.0733\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0995 - val_loss: 0.0677\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0988 - val_loss: 0.0686\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0979 - val_loss: 0.0711\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0978 - val_loss: 0.0681\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0969 - val_loss: 0.0723\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0965 - val_loss: 0.0711\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0962 - val_loss: 0.0653\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0952 - val_loss: 0.0664\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0954 - val_loss: 0.0797\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0641\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0944 - val_loss: 0.0651\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0935 - val_loss: 0.0638\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0932 - val_loss: 0.0640\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0930 - val_loss: 0.0615\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0926 - val_loss: 0.0642\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0651\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0920 - val_loss: 0.0604\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0919 - val_loss: 0.0630\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0914 - val_loss: 0.0600\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0626\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0609\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0906 - val_loss: 0.0602\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0903 - val_loss: 0.0614\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0901 - val_loss: 0.0634\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0900 - val_loss: 0.0622\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0899 - val_loss: 0.0607\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0893 - val_loss: 0.0614\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0893 - val_loss: 0.0589\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0892 - val_loss: 0.0596\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0888 - val_loss: 0.0622\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0888 - val_loss: 0.0678\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0889 - val_loss: 0.0568\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0883 - val_loss: 0.0585\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0884 - val_loss: 0.0583\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.0881 - val_loss: 0.0604\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.0887 - val_loss: 0.0605\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0884 - val_loss: 0.0574\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0882 - val_loss: 0.0570\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 64us/sample - loss: 0.0878 - val_loss: 0.0566\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0873 - val_loss: 0.0612\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0876 - val_loss: 0.0576\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0878 - val_loss: 0.0574\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0873 - val_loss: 0.0571\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0872 - val_loss: 0.0582\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0871 - val_loss: 0.0580\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0866 - val_loss: 0.0548\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0873 - val_loss: 0.0554\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0864 - val_loss: 0.0566\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0863 - val_loss: 0.0606\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0865 - val_loss: 0.0605\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0864 - val_loss: 0.0612\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0864 - val_loss: 0.0562\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0861 - val_loss: 0.0590\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0857 - val_loss: 0.0568\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0855 - val_loss: 0.0543\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0858 - val_loss: 0.0615\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0862 - val_loss: 0.0559\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0855 - val_loss: 0.0560\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0856 - val_loss: 0.0542\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0851 - val_loss: 0.0574\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0849 - val_loss: 0.0552\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0852 - val_loss: 0.0597\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0852 - val_loss: 0.0547\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0847 - val_loss: 0.0573\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0848 - val_loss: 0.0573\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0848 - val_loss: 0.0553\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0846 - val_loss: 0.0571\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0844 - val_loss: 0.0563\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0843 - val_loss: 0.0564\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 64\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 153us/sample - loss: 0.1395 - val_loss: 0.0908\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1181 - val_loss: 0.0880\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1166 - val_loss: 0.1112\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 76us/sample - loss: 0.1153 - val_loss: 0.0878\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.1158 - val_loss: 0.0963\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.1135 - val_loss: 0.0922\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1120 - val_loss: 0.0905\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.1092 - val_loss: 0.0839\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1072 - val_loss: 0.0824\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1060 - val_loss: 0.0753\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.1044 - val_loss: 0.0802\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.1032 - val_loss: 0.0757\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.1013 - val_loss: 0.0753\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.1000 - val_loss: 0.0799\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 76us/sample - loss: 0.0994 - val_loss: 0.0702\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0980 - val_loss: 0.0702\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0972 - val_loss: 0.0845\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0966 - val_loss: 0.0660\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0958 - val_loss: 0.0644\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0952 - val_loss: 0.0637\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0943 - val_loss: 0.0641\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0945 - val_loss: 0.0653\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 76us/sample - loss: 0.0939 - val_loss: 0.0654\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 70us/sample - loss: 0.0930 - val_loss: 0.0616\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0923 - val_loss: 0.0622\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0924 - val_loss: 0.0655\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0920 - val_loss: 0.0645\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0913 - val_loss: 0.0643\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0911 - val_loss: 0.0618\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0906 - val_loss: 0.0590\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0906 - val_loss: 0.0611\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0904 - val_loss: 0.0629\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0896 - val_loss: 0.0572\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 70us/sample - loss: 0.0891 - val_loss: 0.0608\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0893 - val_loss: 0.0606\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0887 - val_loss: 0.0587\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0887 - val_loss: 0.0572\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.0886 - val_loss: 0.0549\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0886 - val_loss: 0.0565\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0875 - val_loss: 0.0577\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0872 - val_loss: 0.0572\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 76us/sample - loss: 0.0874 - val_loss: 0.0602\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0866 - val_loss: 0.0626\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 76us/sample - loss: 0.0867 - val_loss: 0.0594\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 70us/sample - loss: 0.0867 - val_loss: 0.0581\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.0862 - val_loss: 0.0558\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 75us/sample - loss: 0.0859 - val_loss: 0.0609\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0863 - val_loss: 0.0541\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.0860 - val_loss: 0.0572\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0855 - val_loss: 0.0556\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 73us/sample - loss: 0.0855 - val_loss: 0.0554\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0854 - val_loss: 0.0560\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 71us/sample - loss: 0.0850 - val_loss: 0.0559\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 69us/sample - loss: 0.0849 - val_loss: 0.0569\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 74us/sample - loss: 0.0850 - val_loss: 0.0552\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 72us/sample - loss: 0.0846 - val_loss: 0.0555\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 70us/sample - loss: 0.0845 - val_loss: 0.0550\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 70us/sample - loss: 0.0843 - val_loss: 0.0551\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 128\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 7s 214us/sample - loss: 0.1340 - val_loss: 0.0997\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.1170 - val_loss: 0.0877\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.1170 - val_loss: 0.1039\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.1158 - val_loss: 0.0870\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.1140 - val_loss: 0.0926\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 4s 112us/sample - loss: 0.1117 - val_loss: 0.0952\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.1086 - val_loss: 0.0832\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.1060 - val_loss: 0.0794\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.1032 - val_loss: 0.0759\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.1023 - val_loss: 0.0704\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.1006 - val_loss: 0.0729\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0993 - val_loss: 0.0688\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0975 - val_loss: 0.0654\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0967 - val_loss: 0.0640\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0960 - val_loss: 0.0673\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0945 - val_loss: 0.0593\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0934 - val_loss: 0.0635\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0929 - val_loss: 0.0599\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 4s 107us/sample - loss: 0.0920 - val_loss: 0.0620\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0914 - val_loss: 0.0575\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0906 - val_loss: 0.0580\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0904 - val_loss: 0.0558\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0898 - val_loss: 0.0577\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0894 - val_loss: 0.0559\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0888 - val_loss: 0.0597\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0887 - val_loss: 0.0556\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 4s 111us/sample - loss: 0.0877 - val_loss: 0.0605\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 4s 111us/sample - loss: 0.0875 - val_loss: 0.0564\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 4s 111us/sample - loss: 0.0874 - val_loss: 0.0599\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 4s 111us/sample - loss: 0.0866 - val_loss: 0.0592TA: 0s - loss: 0\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0867 - val_loss: 0.0552\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0869 - val_loss: 0.0572\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0857 - val_loss: 0.0554\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 4s 112us/sample - loss: 0.0858 - val_loss: 0.0576\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0854 - val_loss: 0.0555\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0852 - val_loss: 0.0539\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0847 - val_loss: 0.0571\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0849 - val_loss: 0.0531\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0847 - val_loss: 0.0545\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 3s 106us/sample - loss: 0.0840 - val_loss: 0.0529\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0837 - val_loss: 0.0572\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0844 - val_loss: 0.0580\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 3s 106us/sample - loss: 0.0833 - val_loss: 0.0597\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 3s 106us/sample - loss: 0.0834 - val_loss: 0.0548\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 3s 107us/sample - loss: 0.0830 - val_loss: 0.0549\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 4s 110us/sample - loss: 0.0823 - val_loss: 0.0546\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 3s 107us/sample - loss: 0.0824 - val_loss: 0.0561\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 4s 109us/sample - loss: 0.0824 - val_loss: 0.0534\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 4s 108us/sample - loss: 0.0817 - val_loss: 0.0580\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 3s 107us/sample - loss: 0.0815 - val_loss: 0.0599\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 2\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 148us/sample - loss: 0.2129 - val_loss: 0.1633\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1791 - val_loss: 0.1436\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1558 - val_loss: 0.1081\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1437 - val_loss: 0.1086\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1391 - val_loss: 0.1106\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1360 - val_loss: 0.1093\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1335 - val_loss: 0.1086\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1316 - val_loss: 0.1060\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1299 - val_loss: 0.1087\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1285 - val_loss: 0.1079\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1272 - val_loss: 0.1051\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1262 - val_loss: 0.1039\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1253 - val_loss: 0.1008\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1244 - val_loss: 0.1008\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1237 - val_loss: 0.0998\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1230 - val_loss: 0.0985\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1223 - val_loss: 0.1005\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1218 - val_loss: 0.0958\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1211 - val_loss: 0.0967\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1207 - val_loss: 0.0955\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1201 - val_loss: 0.1004\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1196 - val_loss: 0.0975\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1192 - val_loss: 0.0964\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1189 - val_loss: 0.0968\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1186 - val_loss: 0.0953\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1183 - val_loss: 0.0925\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 64us/sample - loss: 0.1180 - val_loss: 0.0953\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1176 - val_loss: 0.0929\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1174 - val_loss: 0.0918\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1171 - val_loss: 0.0928\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1169 - val_loss: 0.0936\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 64us/sample - loss: 0.1167 - val_loss: 0.0940\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1163 - val_loss: 0.0994\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.1163 - val_loss: 0.0922\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1159 - val_loss: 0.0918\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1158 - val_loss: 0.0932\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1156 - val_loss: 0.0931\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1154 - val_loss: 0.0919\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1154 - val_loss: 0.0930\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 4\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 6s 166us/sample - loss: 0.1739 - val_loss: 0.1137\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1387 - val_loss: 0.1035\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1306 - val_loss: 0.1046\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1259 - val_loss: 0.1083\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1229 - val_loss: 0.1011\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1203 - val_loss: 0.1002\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1190 - val_loss: 0.0954\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1176 - val_loss: 0.0931\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1167 - val_loss: 0.0953\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1160 - val_loss: 0.0967\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1151 - val_loss: 0.0940\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1144 - val_loss: 0.1035\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1135 - val_loss: 0.0952\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1128 - val_loss: 0.0953\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1121 - val_loss: 0.0927\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1118 - val_loss: 0.0880\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1112 - val_loss: 0.0940\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1105 - val_loss: 0.0901\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1099 - val_loss: 0.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1094 - val_loss: 0.0931\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1089 - val_loss: 0.0959\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1087 - val_loss: 0.0880\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1086 - val_loss: 0.0898\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.1080 - val_loss: 0.0928\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1075 - val_loss: 0.0884\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.1075 - val_loss: 0.0876\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1069 - val_loss: 0.0890\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1066 - val_loss: 0.0920\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1066 - val_loss: 0.0918\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1063 - val_loss: 0.0905\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1059 - val_loss: 0.0936\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1062 - val_loss: 0.0867\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1056 - val_loss: 0.0891\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1053 - val_loss: 0.0857\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1051 - val_loss: 0.0851\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1051 - val_loss: 0.0840\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1049 - val_loss: 0.0962\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1049 - val_loss: 0.0847\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1044 - val_loss: 0.0831\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1040 - val_loss: 0.0840\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1039 - val_loss: 0.0844\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1039 - val_loss: 0.0839\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1037 - val_loss: 0.0845\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1036 - val_loss: 0.0834\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1037 - val_loss: 0.0860\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0822\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0843\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0818\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1028 - val_loss: 0.0838\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1026 - val_loss: 0.0820\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1025 - val_loss: 0.0852\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1022 - val_loss: 0.0806\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1022 - val_loss: 0.0806\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1021 - val_loss: 0.0813\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1019 - val_loss: 0.0872\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1020 - val_loss: 0.0808\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1021 - val_loss: 0.0806\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1016 - val_loss: 0.0805\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.1015 - val_loss: 0.0826\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1017 - val_loss: 0.0873\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1015 - val_loss: 0.0842\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1016 - val_loss: 0.0819\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1013 - val_loss: 0.0795\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1015 - val_loss: 0.0795\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1010 - val_loss: 0.0796\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1010 - val_loss: 0.0789\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1008 - val_loss: 0.0803\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1009 - val_loss: 0.0806\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1008 - val_loss: 0.0785\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1007 - val_loss: 0.0793\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1007 - val_loss: 0.0831\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1007 - val_loss: 0.0798\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.1004 - val_loss: 0.0789\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1005 - val_loss: 0.0793\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1003 - val_loss: 0.0787\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1004 - val_loss: 0.0824\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1003 - val_loss: 0.0782\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1002 - val_loss: 0.0860\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1003 - val_loss: 0.0780\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1002 - val_loss: 0.0801\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0999 - val_loss: 0.0796\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1000 - val_loss: 0.0786\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0998 - val_loss: 0.0790\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1001 - val_loss: 0.0779\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0998 - val_loss: 0.0789\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0998 - val_loss: 0.0791\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0997 - val_loss: 0.0800\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0995 - val_loss: 0.0787\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0995 - val_loss: 0.0788\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0995 - val_loss: 0.0799\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 66us/sample - loss: 0.0995 - val_loss: 0.0776\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0996 - val_loss: 0.0780\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0996 - val_loss: 0.0780\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0994 - val_loss: 0.0775\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0991 - val_loss: 0.0783\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0994 - val_loss: 0.0770\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0991 - val_loss: 0.0778\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0991 - val_loss: 0.0786\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0991 - val_loss: 0.0774\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0991 - val_loss: 0.0798\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 8\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 144us/sample - loss: 0.1629 - val_loss: 0.1088\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1331 - val_loss: 0.1042\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1258 - val_loss: 0.1149\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1207 - val_loss: 0.1009\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1178 - val_loss: 0.1013\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1159 - val_loss: 0.1010\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1145 - val_loss: 0.1009\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1131 - val_loss: 0.0912\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1123 - val_loss: 0.0928\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1113 - val_loss: 0.0954\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1104 - val_loss: 0.0973\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1100 - val_loss: 0.0931\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1093 - val_loss: 0.1008\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1088 - val_loss: 0.0910\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.0917\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1076 - val_loss: 0.0892\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1073 - val_loss: 0.0904\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1068 - val_loss: 0.0863\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1064 - val_loss: 0.0866\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1063 - val_loss: 0.0882\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1056 - val_loss: 0.0871\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1053 - val_loss: 0.0854\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1052 - val_loss: 0.0873\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1047 - val_loss: 0.0869\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1045 - val_loss: 0.0854\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1041 - val_loss: 0.0864\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1040 - val_loss: 0.0828\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0838\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1033 - val_loss: 0.0859\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0812\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1027 - val_loss: 0.0869\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1023 - val_loss: 0.0806\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1019 - val_loss: 0.0794\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1018 - val_loss: 0.0816\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1014 - val_loss: 0.0779\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1011 - val_loss: 0.0769\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1006 - val_loss: 0.0852\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1005 - val_loss: 0.0835\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1000 - val_loss: 0.0753\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0997 - val_loss: 0.0805\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0994 - val_loss: 0.0746\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0992 - val_loss: 0.0759\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0989 - val_loss: 0.0766\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0987 - val_loss: 0.0725\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0987 - val_loss: 0.0761\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0980 - val_loss: 0.0762\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0805\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0979 - val_loss: 0.0721\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0974 - val_loss: 0.0707\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0711\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0973 - val_loss: 0.0738\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0968 - val_loss: 0.0708\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0968 - val_loss: 0.0702\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0968 - val_loss: 0.0695\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0968 - val_loss: 0.0815\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0706\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0966 - val_loss: 0.0698\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0961 - val_loss: 0.0705\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0704\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0960 - val_loss: 0.0760\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0961 - val_loss: 0.0758\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0959 - val_loss: 0.0705\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0959 - val_loss: 0.0685\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0955 - val_loss: 0.0726\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0954 - val_loss: 0.0698\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0953 - val_loss: 0.0683\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0951 - val_loss: 0.0720\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.0951 - val_loss: 0.0753\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.0950 - val_loss: 0.0692\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0950 - val_loss: 0.0697\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0950 - val_loss: 0.0714\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0683\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0946 - val_loss: 0.0681\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0947 - val_loss: 0.0736\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0945 - val_loss: 0.0676\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0948 - val_loss: 0.0732\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0942 - val_loss: 0.0713\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0945 - val_loss: 0.0699\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0944 - val_loss: 0.0690\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0941 - val_loss: 0.0683\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0940 - val_loss: 0.0692\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0940 - val_loss: 0.0664\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0941 - val_loss: 0.0662\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0942 - val_loss: 0.0675\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0939 - val_loss: 0.0690\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0938 - val_loss: 0.0677\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.0938 - val_loss: 0.0687\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0939 - val_loss: 0.0696\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0937 - val_loss: 0.0681\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0935 - val_loss: 0.0701\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0662\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0938 - val_loss: 0.0689\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0662\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0935 - val_loss: 0.0700\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0934 - val_loss: 0.0662\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0933 - val_loss: 0.0672\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0933 - val_loss: 0.0668\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0931 - val_loss: 0.0676\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0682\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0932 - val_loss: 0.0719\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 16\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 142us/sample - loss: 0.1521 - val_loss: 0.1080\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1281 - val_loss: 0.1042\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1227 - val_loss: 0.1067\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1187 - val_loss: 0.1010\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1168 - val_loss: 0.0949\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1146 - val_loss: 0.1117\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1134 - val_loss: 0.1010\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1120 - val_loss: 0.0872\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1115 - val_loss: 0.0911\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.1103 - val_loss: 0.0899\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 46us/sample - loss: 0.1088 - val_loss: 0.0950\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.1082 - val_loss: 0.0857\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1074 - val_loss: 0.0884\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1068 - val_loss: 0.0904\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1061 - val_loss: 0.0840\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1051 - val_loss: 0.0901\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1047 - val_loss: 0.0868\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1038 - val_loss: 0.0794\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1034 - val_loss: 0.0763\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1028 - val_loss: 0.0918\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1020 - val_loss: 0.0844\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1016 - val_loss: 0.0736\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1013 - val_loss: 0.0749\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1006 - val_loss: 0.0732\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1003 - val_loss: 0.0704\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0774\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0995 - val_loss: 0.0793\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0774\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0993 - val_loss: 0.0803\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0990 - val_loss: 0.0696\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0984 - val_loss: 0.0841\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0982 - val_loss: 0.0710\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0980 - val_loss: 0.0889\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0980 - val_loss: 0.0720\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0679\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0976 - val_loss: 0.0710\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0973 - val_loss: 0.0831\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0974 - val_loss: 0.0755\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0968 - val_loss: 0.0717\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0964 - val_loss: 0.0706\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0963 - val_loss: 0.0678\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0961 - val_loss: 0.0714\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0959 - val_loss: 0.0690\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0959 - val_loss: 0.0673\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0959 - val_loss: 0.0674\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0958 - val_loss: 0.0784\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0954 - val_loss: 0.0799\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0953 - val_loss: 0.0672\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0951 - val_loss: 0.0759\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0947 - val_loss: 0.0740\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0707\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0800\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0941 - val_loss: 0.0721\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0942 - val_loss: 0.0632\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0945 - val_loss: 0.0731\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0943 - val_loss: 0.0671\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0943 - val_loss: 0.0652\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0940 - val_loss: 0.0905\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0936 - val_loss: 0.0642\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0934 - val_loss: 0.0727\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0934 - val_loss: 0.0726\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0933 - val_loss: 0.0658\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0643\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0930 - val_loss: 0.0641\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 32\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 146us/sample - loss: 0.1437 - val_loss: 0.0992\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1215 - val_loss: 0.1070\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1180 - val_loss: 0.1050\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1173 - val_loss: 0.1097\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1162 - val_loss: 0.1051\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1147 - val_loss: 0.1152\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1133 - val_loss: 0.1042\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1114 - val_loss: 0.0887\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1101 - val_loss: 0.0947\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1078 - val_loss: 0.0876\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1066 - val_loss: 0.0992\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1057 - val_loss: 0.0789\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1040 - val_loss: 0.0794\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1030 - val_loss: 0.0781\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1024 - val_loss: 0.0731\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1021 - val_loss: 0.0757\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1013 - val_loss: 0.0808\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.1003 - val_loss: 0.0693\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1000 - val_loss: 0.0703\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0994 - val_loss: 0.0794\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0987 - val_loss: 0.0722\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0985 - val_loss: 0.0706\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0975 - val_loss: 0.0694\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0969 - val_loss: 0.0677\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0968 - val_loss: 0.0688\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0662\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0960 - val_loss: 0.0741\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0719\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0956 - val_loss: 0.0731\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0953 - val_loss: 0.0644\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.0755\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0945 - val_loss: 0.0691\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0942 - val_loss: 0.0708\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0940 - val_loss: 0.0659\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0935 - val_loss: 0.0653\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0933 - val_loss: 0.0606\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0933 - val_loss: 0.0732\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0931 - val_loss: 0.0638\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 62us/sample - loss: 0.0929 - val_loss: 0.0675\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0924 - val_loss: 0.0634\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0924 - val_loss: 0.0633\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0924 - val_loss: 0.0621\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0922 - val_loss: 0.0622\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0921 - val_loss: 0.0639\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0918 - val_loss: 0.0707\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0917 - val_loss: 0.0657\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 64\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 158us/sample - loss: 0.1403 - val_loss: 0.1036\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1211 - val_loss: 0.1088\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1184 - val_loss: 0.0961\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1178 - val_loss: 0.1051\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1169 - val_loss: 0.1098\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 70us/sample - loss: 0.1155 - val_loss: 0.1108\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1133 - val_loss: 0.0972\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1100 - val_loss: 0.0865\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1073 - val_loss: 0.0863\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1056 - val_loss: 0.0764\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1036 - val_loss: 0.0853\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1029 - val_loss: 0.0781\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.1014 - val_loss: 0.0732\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.1007 - val_loss: 0.0725\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0997 - val_loss: 0.0673\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0992 - val_loss: 0.0709\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0988 - val_loss: 0.0719\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0985 - val_loss: 0.0666\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0981 - val_loss: 0.0648\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0968 - val_loss: 0.0853\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 70us/sample - loss: 0.0968 - val_loss: 0.0660\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0963 - val_loss: 0.0690\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0956 - val_loss: 0.0632\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0952 - val_loss: 0.0663\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0948 - val_loss: 0.0728\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 73us/sample - loss: 0.0945 - val_loss: 0.0648\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0941 - val_loss: 0.0647\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 71us/sample - loss: 0.0941 - val_loss: 0.0668\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 72us/sample - loss: 0.0931 - val_loss: 0.0660\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 73us/sample - loss: 0.0933 - val_loss: 0.0632\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 74us/sample - loss: 0.0928 - val_loss: 0.0660\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 70us/sample - loss: 0.0923 - val_loss: 0.0665\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 70us/sample - loss: 0.0922 - val_loss: 0.0704\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 128\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 7s 225us/sample - loss: 0.1392 - val_loss: 0.1122\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 4s 114us/sample - loss: 0.1213 - val_loss: 0.1097\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1185 - val_loss: 0.1070\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1171 - val_loss: 0.0995\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1147 - val_loss: 0.0977\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.1113 - val_loss: 0.1006\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1087 - val_loss: 0.0923\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1066 - val_loss: 0.0780\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.1037 - val_loss: 0.0750\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.1022 - val_loss: 0.0725\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 4s 114us/sample - loss: 0.1003 - val_loss: 0.0820\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.1000 - val_loss: 0.0755\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0979 - val_loss: 0.0696\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0973 - val_loss: 0.0752\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0963 - val_loss: 0.0660\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0951 - val_loss: 0.0647\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0948 - val_loss: 0.0654\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0945 - val_loss: 0.0651\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0943 - val_loss: 0.0741\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0933 - val_loss: 0.0795\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0927 - val_loss: 0.0642\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0928 - val_loss: 0.0631\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0925 - val_loss: 0.0610\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0915 - val_loss: 0.0622\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0915 - val_loss: 0.0636\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0914 - val_loss: 0.0659\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0906 - val_loss: 0.0631\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0906 - val_loss: 0.0710\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 4s 110us/sample - loss: 0.0902 - val_loss: 0.0640\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0897 - val_loss: 0.0624\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 4s 114us/sample - loss: 0.0894 - val_loss: 0.0667\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 4s 113us/sample - loss: 0.0893 - val_loss: 0.0630\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 4s 112us/sample - loss: 0.0891 - val_loss: 0.0643\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 2\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 144us/sample - loss: 0.1750 - val_loss: 0.1137\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1435 - val_loss: 0.1164\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1384 - val_loss: 0.1079\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1353 - val_loss: 0.1067\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1332 - val_loss: 0.1062\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1315 - val_loss: 0.1081\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1302 - val_loss: 0.1026\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1293 - val_loss: 0.1017\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1283 - val_loss: 0.1062\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1276 - val_loss: 0.1002\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1269 - val_loss: 0.0995\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1262 - val_loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1257 - val_loss: 0.1062\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1251 - val_loss: 0.1020\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1246 - val_loss: 0.0952\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1241 - val_loss: 0.0985\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1235 - val_loss: 0.0971\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1228 - val_loss: 0.0974\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1221 - val_loss: 0.0913\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1211 - val_loss: 0.0949\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1200 - val_loss: 0.0920\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 64us/sample - loss: 0.1191 - val_loss: 0.0944\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1184 - val_loss: 0.0911\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1179 - val_loss: 0.0965\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1174 - val_loss: 0.0959\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1171 - val_loss: 0.0901\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1166 - val_loss: 0.0950\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 67us/sample - loss: 0.1165 - val_loss: 0.0927\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1160 - val_loss: 0.0894\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1157 - val_loss: 0.0885\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1154 - val_loss: 0.0900\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1151 - val_loss: 0.0882\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1148 - val_loss: 0.0912\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1146 - val_loss: 0.0903\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1143 - val_loss: 0.0886\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1140 - val_loss: 0.0899\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 64us/sample - loss: 0.1137 - val_loss: 0.0892\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 65us/sample - loss: 0.1135 - val_loss: 0.0869\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1134 - val_loss: 0.0894\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1130 - val_loss: 0.0869\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1127 - val_loss: 0.0909\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1125 - val_loss: 0.0874\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1123 - val_loss: 0.0879\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1120 - val_loss: 0.0896\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1118 - val_loss: 0.0876\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1115 - val_loss: 0.0872\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1113 - val_loss: 0.0894\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1111 - val_loss: 0.0831\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1109 - val_loss: 0.0890\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1106 - val_loss: 0.0851\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1103 - val_loss: 0.0843\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1102 - val_loss: 0.0836\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1100 - val_loss: 0.0901\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1097 - val_loss: 0.0842\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1096 - val_loss: 0.0839\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1093 - val_loss: 0.0807\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1093 - val_loss: 0.0830\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1088 - val_loss: 0.0839\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1087 - val_loss: 0.0822\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 64us/sample - loss: 0.1085 - val_loss: 0.0836\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1083 - val_loss: 0.0832\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1081 - val_loss: 0.0813\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1080 - val_loss: 0.0839\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1078 - val_loss: 0.0840\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1076 - val_loss: 0.0842\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1074 - val_loss: 0.0800\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1073 - val_loss: 0.0819\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1071 - val_loss: 0.0822\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1070 - val_loss: 0.0830\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1069 - val_loss: 0.0804\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1067 - val_loss: 0.0771\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1066 - val_loss: 0.0810\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1065 - val_loss: 0.0811\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1063 - val_loss: 0.0810\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1061 - val_loss: 0.0820\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1061 - val_loss: 0.0794\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1059 - val_loss: 0.0798\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1058 - val_loss: 0.0768\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1057 - val_loss: 0.0784\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1056 - val_loss: 0.0763\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1054 - val_loss: 0.0768\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1053 - val_loss: 0.0757\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1053 - val_loss: 0.0769\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1051 - val_loss: 0.0780\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1050 - val_loss: 0.0766\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1049 - val_loss: 0.0758\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1048 - val_loss: 0.0767\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1048 - val_loss: 0.0774\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1047 - val_loss: 0.0760\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1046 - val_loss: 0.0755\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1046 - val_loss: 0.0749\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1044 - val_loss: 0.0776\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1043 - val_loss: 0.0773\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1044 - val_loss: 0.0750\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1043 - val_loss: 0.0748\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 47us/sample - loss: 0.1042 - val_loss: 0.0749\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1041 - val_loss: 0.0745\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1041 - val_loss: 0.0765\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1039 - val_loss: 0.0777\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1038 - val_loss: 0.0753\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 4\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 6s 166us/sample - loss: 0.1640 - val_loss: 0.1088\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1317 - val_loss: 0.1091\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1264 - val_loss: 0.1023\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1233 - val_loss: 0.1034\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1207 - val_loss: 0.1030\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1188 - val_loss: 0.1075\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1172 - val_loss: 0.1015\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1157 - val_loss: 0.0997\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1144 - val_loss: 0.0973\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1134 - val_loss: 0.0935\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1125 - val_loss: 0.0968\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1114 - val_loss: 0.0920\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1106 - val_loss: 0.1020\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1104 - val_loss: 0.1017\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1095 - val_loss: 0.0894\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1087 - val_loss: 0.0882\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1083 - val_loss: 0.0874\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1079 - val_loss: 0.0913\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1073 - val_loss: 0.0906\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1071 - val_loss: 0.0870\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1064 - val_loss: 0.0896\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1060 - val_loss: 0.0875\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1058 - val_loss: 0.0907\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1054 - val_loss: 0.0856\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1051 - val_loss: 0.0891\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1049 - val_loss: 0.0847\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1046 - val_loss: 0.0846\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1043 - val_loss: 0.0858\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1039 - val_loss: 0.0865\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1037 - val_loss: 0.0858\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1038 - val_loss: 0.0846\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0893\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1029 - val_loss: 0.0904\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1030 - val_loss: 0.0803\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0900\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1024 - val_loss: 0.0823\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1021 - val_loss: 0.0855\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1019 - val_loss: 0.0823\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1017 - val_loss: 0.0848\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1015 - val_loss: 0.0840\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1014 - val_loss: 0.0856\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1012 - val_loss: 0.0837\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1010 - val_loss: 0.0793\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1008 - val_loss: 0.0835\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1007 - val_loss: 0.0806\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1007 - val_loss: 0.0812\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1004 - val_loss: 0.0804\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1002 - val_loss: 0.0823\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1003 - val_loss: 0.0764\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1000 - val_loss: 0.0809\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0999 - val_loss: 0.0780\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0997 - val_loss: 0.0831\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0996 - val_loss: 0.0809\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0995 - val_loss: 0.0765\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0994 - val_loss: 0.0812\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0993 - val_loss: 0.0757\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0991 - val_loss: 0.0807\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0989 - val_loss: 0.0774\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0988 - val_loss: 0.0764\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0987 - val_loss: 0.0751\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0770\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0985 - val_loss: 0.0755\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0985 - val_loss: 0.0776\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0981 - val_loss: 0.0809\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0981 - val_loss: 0.0759\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0979 - val_loss: 0.0784\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0980 - val_loss: 0.0796\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0977 - val_loss: 0.0744\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0976 - val_loss: 0.0736\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0975 - val_loss: 0.0747\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0973 - val_loss: 0.0758\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0972 - val_loss: 0.0738\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.0767\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0969 - val_loss: 0.0740\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0970 - val_loss: 0.0771\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0969 - val_loss: 0.0789\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0966 - val_loss: 0.0734\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0967 - val_loss: 0.0724\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0728\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0963 - val_loss: 0.0709\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0964 - val_loss: 0.0743\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0962 - val_loss: 0.0739\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0961 - val_loss: 0.0748\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0960 - val_loss: 0.0716\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0962 - val_loss: 0.0734\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0958 - val_loss: 0.0716\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0957 - val_loss: 0.0731\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0957 - val_loss: 0.0750\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0956 - val_loss: 0.0731\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0954 - val_loss: 0.0741\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 8\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 148us/sample - loss: 0.1589 - val_loss: 0.1083\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1342 - val_loss: 0.1147\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1281 - val_loss: 0.0982\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1219 - val_loss: 0.0982\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1178 - val_loss: 0.0995\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1149 - val_loss: 0.0975\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1131 - val_loss: 0.0946\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1114 - val_loss: 0.0927\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1098 - val_loss: 0.0936\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1082 - val_loss: 0.0861\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1073 - val_loss: 0.0860\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1059 - val_loss: 0.0874\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1053 - val_loss: 0.0903\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1045 - val_loss: 0.0867\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1035 - val_loss: 0.0781\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1030 - val_loss: 0.0805\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1023 - val_loss: 0.0755\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1019 - val_loss: 0.0788\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.1012 - val_loss: 0.0827\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1010 - val_loss: 0.0754\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1003 - val_loss: 0.0778\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1000 - val_loss: 0.0782\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0997 - val_loss: 0.0789\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0992 - val_loss: 0.0732\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0987 - val_loss: 0.0775\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0985 - val_loss: 0.0725\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0982 - val_loss: 0.0726\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0980 - val_loss: 0.0747\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0977 - val_loss: 0.0705\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0974 - val_loss: 0.0753\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0973 - val_loss: 0.0724\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0971 - val_loss: 0.0735\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0967 - val_loss: 0.0747\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0967 - val_loss: 0.0698\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0968 - val_loss: 0.0742\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0963 - val_loss: 0.0708\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0960 - val_loss: 0.0731\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0958 - val_loss: 0.0696\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0957 - val_loss: 0.0700\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0955 - val_loss: 0.0683\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0955 - val_loss: 0.0700\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0953 - val_loss: 0.0710\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0951 - val_loss: 0.0682\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0948 - val_loss: 0.0702\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.0702\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0947 - val_loss: 0.0735\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0948 - val_loss: 0.0700\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0943 - val_loss: 0.0700\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0943 - val_loss: 0.0670\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0942 - val_loss: 0.0695\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0939 - val_loss: 0.0717\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0939 - val_loss: 0.0726\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0938 - val_loss: 0.0681\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 64us/sample - loss: 0.0936 - val_loss: 0.0669\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0935 - val_loss: 0.0706\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 64us/sample - loss: 0.0934 - val_loss: 0.0646\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0934 - val_loss: 0.0698\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0935 - val_loss: 0.0679\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0930 - val_loss: 0.0645\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0930 - val_loss: 0.0659\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0930 - val_loss: 0.0676\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0928 - val_loss: 0.0643\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0928 - val_loss: 0.0659\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0927 - val_loss: 0.0692\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0925 - val_loss: 0.0650\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0924 - val_loss: 0.0676\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0925 - val_loss: 0.0704\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0921 - val_loss: 0.0650\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0922 - val_loss: 0.0630\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0658\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0920 - val_loss: 0.0654\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0920 - val_loss: 0.0696\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0920 - val_loss: 0.0717\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0919 - val_loss: 0.0640\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0919 - val_loss: 0.0643\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0914 - val_loss: 0.0653\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0916 - val_loss: 0.0661\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0917 - val_loss: 0.0636\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0914 - val_loss: 0.0651\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 16\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 146us/sample - loss: 0.1544 - val_loss: 0.0992\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1234 - val_loss: 0.1187\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1194 - val_loss: 0.0947\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1158 - val_loss: 0.0969\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1123 - val_loss: 0.0900\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1095 - val_loss: 0.0936\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1076 - val_loss: 0.0882\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1055 - val_loss: 0.0884\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0751\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1017 - val_loss: 0.0847\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1014 - val_loss: 0.0760\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1005 - val_loss: 0.0803\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1003 - val_loss: 0.0912\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0816\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0990 - val_loss: 0.0745\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0987 - val_loss: 0.0862\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0980 - val_loss: 0.0699\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0980 - val_loss: 0.0701\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0975 - val_loss: 0.0768\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0734\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0969 - val_loss: 0.0784\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0965 - val_loss: 0.0800\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0963 - val_loss: 0.0748\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0961 - val_loss: 0.0764\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0956 - val_loss: 0.0814\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0956 - val_loss: 0.0799\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0949 - val_loss: 0.0691\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0951 - val_loss: 0.0691\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0945 - val_loss: 0.0709\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0941 - val_loss: 0.0717\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0937 - val_loss: 0.0704\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0936 - val_loss: 0.0702\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0935 - val_loss: 0.0699\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0933 - val_loss: 0.0672\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0703\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0929 - val_loss: 0.0700\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0923 - val_loss: 0.0663\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0920 - val_loss: 0.0666\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0922 - val_loss: 0.0650\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0917 - val_loss: 0.0662\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0916 - val_loss: 0.0785\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0913 - val_loss: 0.0709\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0914 - val_loss: 0.0653\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0659\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0909 - val_loss: 0.0715\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0908 - val_loss: 0.0681\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0906 - val_loss: 0.0660\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0902 - val_loss: 0.0636\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0904 - val_loss: 0.0626\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0900 - val_loss: 0.0658\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0898 - val_loss: 0.0776\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0704\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0898 - val_loss: 0.0647\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0666\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0893 - val_loss: 0.0746\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0890 - val_loss: 0.0616\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0888 - val_loss: 0.0619\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0888 - val_loss: 0.0642\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0886 - val_loss: 0.0618\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0887 - val_loss: 0.0654\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0884 - val_loss: 0.0643\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0881 - val_loss: 0.0612\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0882 - val_loss: 0.0617\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0881 - val_loss: 0.0661\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0880 - val_loss: 0.0606\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0879 - val_loss: 0.0625\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0880 - val_loss: 0.0647\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0876 - val_loss: 0.0651\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0873 - val_loss: 0.0608\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0872 - val_loss: 0.0621\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0873 - val_loss: 0.0628\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0873 - val_loss: 0.0656\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0874 - val_loss: 0.0652\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0874 - val_loss: 0.0613\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0869 - val_loss: 0.0605\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0865 - val_loss: 0.0609\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0870 - val_loss: 0.0625\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0873 - val_loss: 0.0603\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0865 - val_loss: 0.0631\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0866 - val_loss: 0.0601\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0868 - val_loss: 0.0603\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0866 - val_loss: 0.0628\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0863 - val_loss: 0.0627\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0861 - val_loss: 0.0595\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0866 - val_loss: 0.0618\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0860 - val_loss: 0.0615\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0862 - val_loss: 0.0604\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0863 - val_loss: 0.0653\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0860 - val_loss: 0.0616\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0858 - val_loss: 0.0633\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0859 - val_loss: 0.0584\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0856 - val_loss: 0.0615\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0858 - val_loss: 0.0602\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0855 - val_loss: 0.0594\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0858 - val_loss: 0.0622\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0852 - val_loss: 0.0602\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0857 - val_loss: 0.0608\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0851 - val_loss: 0.0605\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0850 - val_loss: 0.0616\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0854 - val_loss: 0.0618\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 32\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 148us/sample - loss: 0.1462 - val_loss: 0.1013\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1204 - val_loss: 0.0977\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1164 - val_loss: 0.0949\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1139 - val_loss: 0.1022\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.1140 - val_loss: 0.0944\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1116 - val_loss: 0.0987\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1100 - val_loss: 0.1020\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1082 - val_loss: 0.0941\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1047 - val_loss: 0.0816\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1029 - val_loss: 0.0851\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1016 - val_loss: 0.0803\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1000 - val_loss: 0.0852\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1004 - val_loss: 0.0838\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0986 - val_loss: 0.0748\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0982 - val_loss: 0.0685\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0978 - val_loss: 0.0754\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0969 - val_loss: 0.0698\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0971 - val_loss: 0.0731\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0957 - val_loss: 0.0740\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0960 - val_loss: 0.0714\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0954 - val_loss: 0.0771\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0945 - val_loss: 0.0814\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0941 - val_loss: 0.0675\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0936 - val_loss: 0.0667\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0937 - val_loss: 0.0668\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0930 - val_loss: 0.0662\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0925 - val_loss: 0.0655\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0926 - val_loss: 0.0623\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0926 - val_loss: 0.0626\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0654\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0916 - val_loss: 0.0663\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0915 - val_loss: 0.0667\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0909 - val_loss: 0.0689\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0915 - val_loss: 0.0605\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0910 - val_loss: 0.0644\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0907 - val_loss: 0.0648\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0906 - val_loss: 0.0642\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 63us/sample - loss: 0.0902 - val_loss: 0.0646\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0898 - val_loss: 0.0606\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0900 - val_loss: 0.0620\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0895 - val_loss: 0.0819\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0894 - val_loss: 0.0643\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0895 - val_loss: 0.0589\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0895 - val_loss: 0.0636\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0890 - val_loss: 0.0617\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0889 - val_loss: 0.0642\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0887 - val_loss: 0.0602\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0884 - val_loss: 0.0610\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0880 - val_loss: 0.0663\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0884 - val_loss: 0.0612\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0881 - val_loss: 0.0615\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0876 - val_loss: 0.0652\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 62us/sample - loss: 0.0877 - val_loss: 0.0608\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 64\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 161us/sample - loss: 0.1373 - val_loss: 0.0942\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.1179 - val_loss: 0.1080\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 75us/sample - loss: 0.1158 - val_loss: 0.0984\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 3s 76us/sample - loss: 0.1127 - val_loss: 0.1065\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.1113 - val_loss: 0.0948\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.1089 - val_loss: 0.0953\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.1067 - val_loss: 0.0928\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 75us/sample - loss: 0.1037 - val_loss: 0.0786\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.1011 - val_loss: 0.0751\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 75us/sample - loss: 0.1004 - val_loss: 0.0776\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0986 - val_loss: 0.0748\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0974 - val_loss: 0.0790\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 72us/sample - loss: 0.0972 - val_loss: 0.0868\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0967 - val_loss: 0.0824\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0955 - val_loss: 0.0654\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 75us/sample - loss: 0.0957 - val_loss: 0.0727\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 3s 76us/sample - loss: 0.0948 - val_loss: 0.0636\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0942 - val_loss: 0.0718\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0934 - val_loss: 0.0697\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0933 - val_loss: 0.0637\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0930 - val_loss: 0.0646\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 72us/sample - loss: 0.0919 - val_loss: 0.0791\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0917 - val_loss: 0.0686\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0913 - val_loss: 0.0629\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0913 - val_loss: 0.0735\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0909 - val_loss: 0.0681\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0906 - val_loss: 0.0667\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 72us/sample - loss: 0.0897 - val_loss: 0.0629\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 72us/sample - loss: 0.0900 - val_loss: 0.0616\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0898 - val_loss: 0.0632\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 69us/sample - loss: 0.0893 - val_loss: 0.0636\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0887 - val_loss: 0.0659\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 69us/sample - loss: 0.0889 - val_loss: 0.0699\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0886 - val_loss: 0.0642\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 71us/sample - loss: 0.0881 - val_loss: 0.0619\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 72us/sample - loss: 0.0878 - val_loss: 0.0645\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 71us/sample - loss: 0.0878 - val_loss: 0.0622\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 74us/sample - loss: 0.0872 - val_loss: 0.0625\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 73us/sample - loss: 0.0870 - val_loss: 0.0635\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 128\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 8s 227us/sample - loss: 0.1351 - val_loss: 0.0961\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.1183 - val_loss: 0.1049\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.1163 - val_loss: 0.0967\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.1137 - val_loss: 0.1073\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.1127 - val_loss: 0.0975\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.1104 - val_loss: 0.0912\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.1072 - val_loss: 0.0966\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.1048 - val_loss: 0.0884\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.1027 - val_loss: 0.0752\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.1003 - val_loss: 0.0770\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0985 - val_loss: 0.0707\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0972 - val_loss: 0.0814\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0970 - val_loss: 0.0757\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0952 - val_loss: 0.0800\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0944 - val_loss: 0.0671\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0933 - val_loss: 0.0658\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0930 - val_loss: 0.0636\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0922 - val_loss: 0.0717\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0914 - val_loss: 0.0650\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0910 - val_loss: 0.0616\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0905 - val_loss: 0.0667\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0899 - val_loss: 0.0675\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0896 - val_loss: 0.0657\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0888 - val_loss: 0.0729\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0884 - val_loss: 0.0689\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 4s 115us/sample - loss: 0.0883 - val_loss: 0.0650\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0876 - val_loss: 0.0651\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0871 - val_loss: 0.0619\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0873 - val_loss: 0.0596\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0867 - val_loss: 0.0616\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0862 - val_loss: 0.0665\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0864 - val_loss: 0.0603\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0860 - val_loss: 0.0619\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0854 - val_loss: 0.0608\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0851 - val_loss: 0.0622\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 4s 118us/sample - loss: 0.0847 - val_loss: 0.0597\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0847 - val_loss: 0.0616\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0844 - val_loss: 0.0596\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0844 - val_loss: 0.0633\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0835 - val_loss: 0.0618\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0834 - val_loss: 0.0635\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 4s 114us/sample - loss: 0.0834 - val_loss: 0.0643\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 4s 115us/sample - loss: 0.0831 - val_loss: 0.0613\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0829 - val_loss: 0.0676\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0824 - val_loss: 0.0597\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 4s 117us/sample - loss: 0.0825 - val_loss: 0.0636\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 4s 116us/sample - loss: 0.0819 - val_loss: 0.0603\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 4s 115us/sample - loss: 0.0817 - val_loss: 0.0613\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 2\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 142us/sample - loss: 0.1780 - val_loss: 0.1467\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.1507 - val_loss: 0.1282\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1401 - val_loss: 0.1229\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1351 - val_loss: 0.1199\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1317 - val_loss: 0.1213\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1294 - val_loss: 0.1152\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1277 - val_loss: 0.1150\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1263 - val_loss: 0.1159\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1251 - val_loss: 0.1129\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1239 - val_loss: 0.1126\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1228 - val_loss: 0.1085\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1218 - val_loss: 0.1096\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1209 - val_loss: 0.1106\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1200 - val_loss: 0.1094\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1191 - val_loss: 0.1098\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1185 - val_loss: 0.1093\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1177 - val_loss: 0.1080\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1172 - val_loss: 0.1060\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1167 - val_loss: 0.1060\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1162 - val_loss: 0.1076\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1156 - val_loss: 0.1039\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1153 - val_loss: 0.1042\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1149 - val_loss: 0.1046\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1147 - val_loss: 0.1031\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1142 - val_loss: 0.1042\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1140 - val_loss: 0.1027\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1136 - val_loss: 0.1025\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1135 - val_loss: 0.1039\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1133 - val_loss: 0.1050\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1131 - val_loss: 0.1030\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1129 - val_loss: 0.1031\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1128 - val_loss: 0.1029\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1125 - val_loss: 0.1019\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1124 - val_loss: 0.1022\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1124 - val_loss: 0.1012\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1122 - val_loss: 0.1033\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1120 - val_loss: 0.1053\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1119 - val_loss: 0.1028\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1117 - val_loss: 0.1013\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1117 - val_loss: 0.1002\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1117 - val_loss: 0.1032\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1115 - val_loss: 0.1007\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1114 - val_loss: 0.1008\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1114 - val_loss: 0.1015\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1113 - val_loss: 0.0997\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1112 - val_loss: 0.1022\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1111 - val_loss: 0.1027\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1110 - val_loss: 0.1003\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1110 - val_loss: 0.1019\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1110 - val_loss: 0.1008\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1109 - val_loss: 0.0999\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1110 - val_loss: 0.1023\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1107 - val_loss: 0.1004\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1106 - val_loss: 0.1027\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1106 - val_loss: 0.1000\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 4\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 142us/sample - loss: 0.1627 - val_loss: 0.1282\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1337 - val_loss: 0.1196\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1298 - val_loss: 0.1198\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1277 - val_loss: 0.1184\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1258 - val_loss: 0.1181\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1242 - val_loss: 0.1132\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1226 - val_loss: 0.1109\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1209 - val_loss: 0.1100\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1194 - val_loss: 0.1086\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1182 - val_loss: 0.1094\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1171 - val_loss: 0.1054\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.1046\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1153 - val_loss: 0.1051\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1144 - val_loss: 0.1045\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1137 - val_loss: 0.1034\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1132 - val_loss: 0.1020\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1124 - val_loss: 0.1023\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1117 - val_loss: 0.1005\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1114 - val_loss: 0.1027\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1106 - val_loss: 0.0995\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1100 - val_loss: 0.0984\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1093 - val_loss: 0.0979\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1090 - val_loss: 0.0977\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1085 - val_loss: 0.0953\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1079 - val_loss: 0.0960\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1075 - val_loss: 0.0954\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1066 - val_loss: 0.0935\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1063 - val_loss: 0.0937\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1058 - val_loss: 0.0945\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1051 - val_loss: 0.0927\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1044 - val_loss: 0.0906\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1047 - val_loss: 0.1005\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1037 - val_loss: 0.0907\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0912\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1033 - val_loss: 0.0888\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1028 - val_loss: 0.0916\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1019 - val_loss: 0.0905\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1019 - val_loss: 0.0894\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1016 - val_loss: 0.0902\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1015 - val_loss: 0.0919\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1013 - val_loss: 0.0915\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1009 - val_loss: 0.0883\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1007 - val_loss: 0.0880\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1006 - val_loss: 0.0876\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1005 - val_loss: 0.0860\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1003 - val_loss: 0.0871\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0880\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0999 - val_loss: 0.0858\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0998 - val_loss: 0.0904\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1002 - val_loss: 0.0885\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0996 - val_loss: 0.0868\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0995 - val_loss: 0.0891\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0995 - val_loss: 0.0863\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0862\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0993 - val_loss: 0.0861\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0992 - val_loss: 0.0873\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0990 - val_loss: 0.0873\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0988 - val_loss: 0.0854\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0987 - val_loss: 0.0880\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0987 - val_loss: 0.0856\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0987 - val_loss: 0.0877\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0986 - val_loss: 0.0869\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0986 - val_loss: 0.0879\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0860\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0985 - val_loss: 0.0846\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0984 - val_loss: 0.0855\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0982 - val_loss: 0.0874\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0980 - val_loss: 0.0862\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0981 - val_loss: 0.0866\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0983 - val_loss: 0.0882\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0980 - val_loss: 0.0853\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0980 - val_loss: 0.0855\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0980 - val_loss: 0.0857\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0977 - val_loss: 0.0851\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0976 - val_loss: 0.0848\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 8\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 138us/sample - loss: 0.1569 - val_loss: 0.1188\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1321 - val_loss: 0.1132\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1285 - val_loss: 0.1125\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1260 - val_loss: 0.1143\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1237 - val_loss: 0.1121\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1207 - val_loss: 0.1079\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.1180 - val_loss: 0.1004\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1153 - val_loss: 0.0998\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1135 - val_loss: 0.1091\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1114 - val_loss: 0.1060\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1103 - val_loss: 0.1020\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1088 - val_loss: 0.0997\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1079 - val_loss: 0.0992\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1069 - val_loss: 0.0961\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1062 - val_loss: 0.1011\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1057 - val_loss: 0.0988\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1050 - val_loss: 0.0973\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1042 - val_loss: 0.0936\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1036 - val_loss: 0.0954\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1033 - val_loss: 0.0940\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1031 - val_loss: 0.0927\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1025 - val_loss: 0.0945\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1021 - val_loss: 0.0920\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1020 - val_loss: 0.0919\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1019 - val_loss: 0.0942\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1017 - val_loss: 0.0926\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1013 - val_loss: 0.0894\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1011 - val_loss: 0.0913\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1009 - val_loss: 0.0928\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1007 - val_loss: 0.0903\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1006 - val_loss: 0.0887\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1003 - val_loss: 0.0934\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0894\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1000 - val_loss: 0.0887\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0887\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0998 - val_loss: 0.0899\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0994 - val_loss: 0.0915\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0881\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0991 - val_loss: 0.0904\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0989 - val_loss: 0.0912\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0989 - val_loss: 0.0905\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0900\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0986 - val_loss: 0.0898\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0986 - val_loss: 0.0895\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0987 - val_loss: 0.0858\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0983 - val_loss: 0.0898\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0980 - val_loss: 0.0869\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0979 - val_loss: 0.0860\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0978 - val_loss: 0.0899\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0978 - val_loss: 0.0887\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0975 - val_loss: 0.0898\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0974 - val_loss: 0.0875\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0975 - val_loss: 0.0875\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0973 - val_loss: 0.0901\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.0892\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 16\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 140us/sample - loss: 0.1499 - val_loss: 0.1179\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1287 - val_loss: 0.1117\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1235 - val_loss: 0.1144\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1196 - val_loss: 0.1141\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1171 - val_loss: 0.1014\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1156 - val_loss: 0.1060\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1148 - val_loss: 0.0991\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1135 - val_loss: 0.0995\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1125 - val_loss: 0.1093\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1115 - val_loss: 0.1058\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1107 - val_loss: 0.1015\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1084 - val_loss: 0.1004\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1072 - val_loss: 0.0966\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1056 - val_loss: 0.0957\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1044 - val_loss: 0.0945\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1037 - val_loss: 0.0935\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1034 - val_loss: 0.0947\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1028 - val_loss: 0.0951\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1021 - val_loss: 0.0950\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1019 - val_loss: 0.0926\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1011 - val_loss: 0.0935\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1009 - val_loss: 0.0928\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1005 - val_loss: 0.0932\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0936\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0994 - val_loss: 0.0928\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0988 - val_loss: 0.0933\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0983 - val_loss: 0.0892\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0980 - val_loss: 0.0895\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0979 - val_loss: 0.0908\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0975 - val_loss: 0.0879\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0968 - val_loss: 0.0859\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0892\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0965 - val_loss: 0.0888\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0962 - val_loss: 0.0887\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0966 - val_loss: 0.0841\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0955 - val_loss: 0.0873\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0953 - val_loss: 0.0900\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0952 - val_loss: 0.0871\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0949 - val_loss: 0.0882\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0875\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0946 - val_loss: 0.0866\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0948 - val_loss: 0.0855\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0942 - val_loss: 0.0856\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0942 - val_loss: 0.0851\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0940 - val_loss: 0.0859\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 32\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 6s 165us/sample - loss: 0.1452 - val_loss: 0.1087\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.1236 - val_loss: 0.1048\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1188 - val_loss: 0.1047\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.1163 - val_loss: 0.1094\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.1145 - val_loss: 0.1004\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.1127 - val_loss: 0.1017\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 62us/sample - loss: 0.1112 - val_loss: 0.0979\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1099 - val_loss: 0.0977\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1091 - val_loss: 0.1030\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1082 - val_loss: 0.1067\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1074 - val_loss: 0.0971\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1050 - val_loss: 0.0943\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1040 - val_loss: 0.0943\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1027 - val_loss: 0.0975\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 63us/sample - loss: 0.1013 - val_loss: 0.0916\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1006 - val_loss: 0.0898\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.1002 - val_loss: 0.0875\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0992 - val_loss: 0.0915\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0986 - val_loss: 0.0876\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0981 - val_loss: 0.0867\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0975 - val_loss: 0.0856\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0978 - val_loss: 0.0854\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0969 - val_loss: 0.0861\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0840\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0959 - val_loss: 0.0849\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0953 - val_loss: 0.0830\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0953 - val_loss: 0.0845\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0947 - val_loss: 0.0910\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0831\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0938 - val_loss: 0.0806\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0936 - val_loss: 0.0809\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0933 - val_loss: 0.0838\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0933 - val_loss: 0.0831\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0928 - val_loss: 0.0818\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0932 - val_loss: 0.0790\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0925 - val_loss: 0.0801\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 62us/sample - loss: 0.0921 - val_loss: 0.0848\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0921 - val_loss: 0.0819\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 62us/sample - loss: 0.0920 - val_loss: 0.0861\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0916 - val_loss: 0.0864\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0916 - val_loss: 0.0827\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0913 - val_loss: 0.0816\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0910 - val_loss: 0.0778\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0907 - val_loss: 0.0785\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 63us/sample - loss: 0.0910 - val_loss: 0.0786\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0902 - val_loss: 0.0790\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0903 - val_loss: 0.0830\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0903 - val_loss: 0.0759\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0897 - val_loss: 0.0819\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0898 - val_loss: 0.0799\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0898 - val_loss: 0.0816\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0901 - val_loss: 0.0834\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0896 - val_loss: 0.0753\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0894 - val_loss: 0.0777\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0896 - val_loss: 0.0793\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0891 - val_loss: 0.0854\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0888 - val_loss: 0.0815\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0887 - val_loss: 0.0775\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0882 - val_loss: 0.0833\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0885 - val_loss: 0.0790\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0886 - val_loss: 0.0754\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0885 - val_loss: 0.0780\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0881 - val_loss: 0.0818\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 64\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 157us/sample - loss: 0.1413 - val_loss: 0.1054\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.1217 - val_loss: 0.1086\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.1181 - val_loss: 0.1032\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.1175 - val_loss: 0.1085\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 74us/sample - loss: 0.1161 - val_loss: 0.1028\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.1149 - val_loss: 0.1058\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.1126 - val_loss: 0.1000\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.1105 - val_loss: 0.0982\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.1081 - val_loss: 0.0960\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.1059 - val_loss: 0.0951\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.1044 - val_loss: 0.0943\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.1015 - val_loss: 0.0887\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.1010 - val_loss: 0.0933\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 68us/sample - loss: 0.0999 - val_loss: 0.0943\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0993 - val_loss: 0.0888\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0981 - val_loss: 0.0894\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0976 - val_loss: 0.0922\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0968 - val_loss: 0.0931\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.0967 - val_loss: 0.0878\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0962 - val_loss: 0.0854\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0951 - val_loss: 0.0857\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0950 - val_loss: 0.0842\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0947 - val_loss: 0.0904\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0944 - val_loss: 0.0849\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0936 - val_loss: 0.0835\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0935 - val_loss: 0.0929\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0928 - val_loss: 0.0880\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0928 - val_loss: 0.0847\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0929 - val_loss: 0.0844\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0924 - val_loss: 0.0882\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0918 - val_loss: 0.0826\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.0918 - val_loss: 0.0879\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0917 - val_loss: 0.0820\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0911 - val_loss: 0.0861\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 72us/sample - loss: 0.0908 - val_loss: 0.0815\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0910 - val_loss: 0.0856\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0904 - val_loss: 0.0826\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0901 - val_loss: 0.0898\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0899 - val_loss: 0.0871\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0894 - val_loss: 0.0801\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0894 - val_loss: 0.0909\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 66us/sample - loss: 0.0895 - val_loss: 0.0880\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0892 - val_loss: 0.0753\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0890 - val_loss: 0.0850\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0886 - val_loss: 0.0814\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0885 - val_loss: 0.0786\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0888 - val_loss: 0.0878\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0885 - val_loss: 0.0761\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0883 - val_loss: 0.0840\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 70us/sample - loss: 0.0879 - val_loss: 0.0819\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0879 - val_loss: 0.0827\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 69us/sample - loss: 0.0878 - val_loss: 0.0874\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 71us/sample - loss: 0.0876 - val_loss: 0.0801\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 128\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 7s 197us/sample - loss: 0.1394 - val_loss: 0.1022\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.1209 - val_loss: 0.1162\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.1186 - val_loss: 0.1092\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.1170 - val_loss: 0.1155\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.1147 - val_loss: 0.0996\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.1129 - val_loss: 0.0977\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.1106 - val_loss: 0.0988\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.1082 - val_loss: 0.0905\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.1054 - val_loss: 0.0901\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.1026 - val_loss: 0.0926\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 4s 111us/sample - loss: 0.1015 - val_loss: 0.0887\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0991 - val_loss: 0.0906\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0985 - val_loss: 0.0870\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0973 - val_loss: 0.0876\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0963 - val_loss: 0.0868\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0960 - val_loss: 0.0867\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0953 - val_loss: 0.0878\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0949 - val_loss: 0.0873\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0950 - val_loss: 0.0839\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0947 - val_loss: 0.0810\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0935 - val_loss: 0.0827\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0935 - val_loss: 0.0860\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0931 - val_loss: 0.0884\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0926 - val_loss: 0.0837\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0921 - val_loss: 0.0849\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0919 - val_loss: 0.0861\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0912 - val_loss: 0.0853\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0913 - val_loss: 0.0868\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0912 - val_loss: 0.0846\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0910 - val_loss: 0.0803\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0900 - val_loss: 0.0805\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0904 - val_loss: 0.0822\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0900 - val_loss: 0.0765\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0897 - val_loss: 0.0812\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 4s 110us/sample - loss: 0.0892 - val_loss: 0.0801\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0889 - val_loss: 0.0831\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 4s 111us/sample - loss: 0.0884 - val_loss: 0.0825\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0887 - val_loss: 0.0860\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0879 - val_loss: 0.0856\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0879 - val_loss: 0.0801\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 4s 114us/sample - loss: 0.0876 - val_loss: 0.0817\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 4s 113us/sample - loss: 0.0875 - val_loss: 0.0821\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 4s 112us/sample - loss: 0.0872 - val_loss: 0.0796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 2\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 6s 176us/sample - loss: 0.1796 - val_loss: 0.1496\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1435 - val_loss: 0.1263\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1322 - val_loss: 0.1197\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1296 - val_loss: 0.1173\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1280 - val_loss: 0.1202\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1266 - val_loss: 0.1177\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1256 - val_loss: 0.1193\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1245 - val_loss: 0.1159\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1238 - val_loss: 0.1121\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1230 - val_loss: 0.1105\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1223 - val_loss: 0.1110\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1217 - val_loss: 0.1127\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1210 - val_loss: 0.1113\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1204 - val_loss: 0.1114\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1197 - val_loss: 0.1099\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1191 - val_loss: 0.1123\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1185 - val_loss: 0.1098\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1179 - val_loss: 0.1092\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1173 - val_loss: 0.1075\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1170 - val_loss: 0.1099\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1162 - val_loss: 0.1096\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1158 - val_loss: 0.1064\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1153 - val_loss: 0.1124\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1149 - val_loss: 0.1095\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1145 - val_loss: 0.1082\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1143 - val_loss: 0.1057\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1137 - val_loss: 0.1064\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1135 - val_loss: 0.1105\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1131 - val_loss: 0.1052\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1129 - val_loss: 0.1072\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1126 - val_loss: 0.1105\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1129 - val_loss: 0.1096\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1123 - val_loss: 0.1083\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1123 - val_loss: 0.1064\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1118 - val_loss: 0.1056\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1114 - val_loss: 0.1074\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1114 - val_loss: 0.1081\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1110 - val_loss: 0.1051\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1111 - val_loss: 0.1093\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1107 - val_loss: 0.1103\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1106 - val_loss: 0.1040\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1105 - val_loss: 0.1058\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1104 - val_loss: 0.1059\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1101 - val_loss: 0.1036\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1100 - val_loss: 0.1083\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1098 - val_loss: 0.1071\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1098 - val_loss: 0.1061\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1097 - val_loss: 0.1036\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1097 - val_loss: 0.1094\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1093 - val_loss: 0.1032\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1093 - val_loss: 0.1110\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1091 - val_loss: 0.1048\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1092 - val_loss: 0.1073\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1092 - val_loss: 0.1128\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1093 - val_loss: 0.1053\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1092 - val_loss: 0.1095\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1086 - val_loss: 0.1079\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.1091 - val_loss: 0.1032\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.1085 - val_loss: 0.1031\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.1086 - val_loss: 0.1039\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.1092 - val_loss: 0.1082\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.1054\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1084 - val_loss: 0.1042\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1084 - val_loss: 0.1041\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1082 - val_loss: 0.1055\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1084 - val_loss: 0.1028\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1084 - val_loss: 0.1079\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1082 - val_loss: 0.1063\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1081 - val_loss: 0.1052\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.1048\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1081 - val_loss: 0.1022\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1079 - val_loss: 0.1044\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.1035\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1080 - val_loss: 0.1101\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1083 - val_loss: 0.1047\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1077 - val_loss: 0.1032\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1078 - val_loss: 0.1035\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1076 - val_loss: 0.1072\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1077 - val_loss: 0.1030\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1075 - val_loss: 0.1023\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1076 - val_loss: 0.1124\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 4\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 147us/sample - loss: 0.1683 - val_loss: 0.1272\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1382 - val_loss: 0.1180\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1331 - val_loss: 0.1127\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1297 - val_loss: 0.1089\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1267 - val_loss: 0.1108\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1241 - val_loss: 0.1078\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1219 - val_loss: 0.1107\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1200 - val_loss: 0.1072\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1185 - val_loss: 0.1025\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1169 - val_loss: 0.1022\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1158 - val_loss: 0.1033\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1151 - val_loss: 0.1033\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1140 - val_loss: 0.1043\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1133 - val_loss: 0.1061\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1126 - val_loss: 0.1038\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1118 - val_loss: 0.1050\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1113 - val_loss: 0.0989\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1105 - val_loss: 0.1016\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1098 - val_loss: 0.1013\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1094 - val_loss: 0.1006\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1085 - val_loss: 0.1021\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1080 - val_loss: 0.0990\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1075 - val_loss: 0.1001\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.0974\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1065 - val_loss: 0.0981\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1058 - val_loss: 0.0969\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1054 - val_loss: 0.0963\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0972\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1047 - val_loss: 0.0949\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1043 - val_loss: 0.0939\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1042 - val_loss: 0.0944\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1038 - val_loss: 0.0946\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1036 - val_loss: 0.0918\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1033 - val_loss: 0.0931\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0926\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1029 - val_loss: 0.0920\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1027 - val_loss: 0.0921\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1024 - val_loss: 0.0934\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1026 - val_loss: 0.0929\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1022 - val_loss: 0.0930\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1021 - val_loss: 0.0897\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1020 - val_loss: 0.0913\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1017 - val_loss: 0.0911\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0920\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1017 - val_loss: 0.0916\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1014 - val_loss: 0.0922\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1015 - val_loss: 0.0901\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1012 - val_loss: 0.0920\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1013 - val_loss: 0.0899\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1011 - val_loss: 0.0914\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1009 - val_loss: 0.0887\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1007 - val_loss: 0.0905\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1008 - val_loss: 0.0895\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1008 - val_loss: 0.0921\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1005 - val_loss: 0.0893\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1004 - val_loss: 0.0896\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1003 - val_loss: 0.0896\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1003 - val_loss: 0.0917\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1003 - val_loss: 0.0880\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1002 - val_loss: 0.0879\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1004 - val_loss: 0.0891\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0891\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1000 - val_loss: 0.0894\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0998 - val_loss: 0.0877\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0998 - val_loss: 0.0874\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0997 - val_loss: 0.0897\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0996 - val_loss: 0.0906\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0995 - val_loss: 0.0901\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0996 - val_loss: 0.0891\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0994 - val_loss: 0.0864\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0993 - val_loss: 0.0874\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0993 - val_loss: 0.0881\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0995 - val_loss: 0.0878\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0991 - val_loss: 0.0876\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0993 - val_loss: 0.0887\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0992 - val_loss: 0.0874\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0990 - val_loss: 0.0871\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0873\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0988 - val_loss: 0.0874\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0989 - val_loss: 0.0887\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 8\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 144us/sample - loss: 0.1589 - val_loss: 0.1223\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1291 - val_loss: 0.1142\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1207 - val_loss: 0.1055\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1157 - val_loss: 0.1061\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1131 - val_loss: 0.1070\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1116 - val_loss: 0.1052\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1106 - val_loss: 0.1012\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1092 - val_loss: 0.1012\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1079 - val_loss: 0.0981\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1070 - val_loss: 0.0965\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1057 - val_loss: 0.0956\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.1045 - val_loss: 0.0945\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1036 - val_loss: 0.0961\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1030 - val_loss: 0.0958\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1023 - val_loss: 0.0929\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1018 - val_loss: 0.0924\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1012 - val_loss: 0.0914\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1009 - val_loss: 0.0899\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1008 - val_loss: 0.0910\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1002 - val_loss: 0.0913\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0997 - val_loss: 0.0919\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0889\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0990 - val_loss: 0.0903\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0989 - val_loss: 0.0894\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0988 - val_loss: 0.0889\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0979 - val_loss: 0.0866\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0884\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0875\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0970 - val_loss: 0.0882\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0968 - val_loss: 0.0889\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0965 - val_loss: 0.0887\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0962 - val_loss: 0.0867\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0962 - val_loss: 0.0877\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0956 - val_loss: 0.0860\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0955 - val_loss: 0.0872\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0950 - val_loss: 0.0844\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0948 - val_loss: 0.0881\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0946 - val_loss: 0.0881\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0944 - val_loss: 0.0852\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0940 - val_loss: 0.0844\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0939 - val_loss: 0.0825\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0937 - val_loss: 0.0853\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0937 - val_loss: 0.0855\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0934 - val_loss: 0.0844\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0934 - val_loss: 0.0852\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0833\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0927 - val_loss: 0.0843\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0928 - val_loss: 0.0807\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0928 - val_loss: 0.0823\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0923 - val_loss: 0.0850\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0835\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0920 - val_loss: 0.0818\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0918 - val_loss: 0.0827\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0918 - val_loss: 0.0813\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0916 - val_loss: 0.0819\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0914 - val_loss: 0.0806\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0912 - val_loss: 0.0819\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0914 - val_loss: 0.0790\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0834\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0912 - val_loss: 0.0820\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0909 - val_loss: 0.0814\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0908 - val_loss: 0.0805\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0907 - val_loss: 0.0815\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0906 - val_loss: 0.0800\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0906 - val_loss: 0.0814\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0905 - val_loss: 0.0810\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0903 - val_loss: 0.0801\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0903 - val_loss: 0.0799\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 16\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 140us/sample - loss: 0.1516 - val_loss: 0.1133\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1261 - val_loss: 0.1122\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1201 - val_loss: 0.1056\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1164 - val_loss: 0.1036\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1137 - val_loss: 0.1070\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1124 - val_loss: 0.1053\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1105 - val_loss: 0.1032\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1091 - val_loss: 0.1009\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1067 - val_loss: 0.1011\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1054 - val_loss: 0.0976\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1033 - val_loss: 0.0988\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1017 - val_loss: 0.0942\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1008 - val_loss: 0.0946\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1003 - val_loss: 0.0927\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0990 - val_loss: 0.0926\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0985 - val_loss: 0.0928\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0983 - val_loss: 0.0923\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0975 - val_loss: 0.0930\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0971 - val_loss: 0.0899\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0971 - val_loss: 0.0923\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0963 - val_loss: 0.0925\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0960 - val_loss: 0.0911\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0953 - val_loss: 0.0982\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0952 - val_loss: 0.0918\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0952 - val_loss: 0.0911\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0943 - val_loss: 0.0856\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0930\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0940 - val_loss: 0.0876\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0935 - val_loss: 0.0889\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0933 - val_loss: 0.0888\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0933 - val_loss: 0.0893\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0901\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0923 - val_loss: 0.0865\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0920 - val_loss: 0.0858\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0919 - val_loss: 0.0847\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0917 - val_loss: 0.0893\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0914 - val_loss: 0.0858\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0858\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0911 - val_loss: 0.0860\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0909 - val_loss: 0.0848\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0908 - val_loss: 0.0887\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0903 - val_loss: 0.0848\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0907 - val_loss: 0.0828\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0902 - val_loss: 0.0827\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0898 - val_loss: 0.0821\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0896 - val_loss: 0.0896\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0896 - val_loss: 0.0809\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0894 - val_loss: 0.0862\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0890 - val_loss: 0.0841\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0891 - val_loss: 0.0824\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0887 - val_loss: 0.0901\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0889 - val_loss: 0.0820\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0884 - val_loss: 0.0855\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0882 - val_loss: 0.0837\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0881 - val_loss: 0.0796\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0879 - val_loss: 0.0872\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0879 - val_loss: 0.0835\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0876 - val_loss: 0.0910\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0880 - val_loss: 0.0888\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0877 - val_loss: 0.0834\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0872 - val_loss: 0.0815\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0873 - val_loss: 0.0773\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0872 - val_loss: 0.0832\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0868 - val_loss: 0.0782\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0868 - val_loss: 0.0846\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0868 - val_loss: 0.0791\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0867 - val_loss: 0.0784\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0867 - val_loss: 0.0809\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0864 - val_loss: 0.0758\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0865 - val_loss: 0.0780\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0862 - val_loss: 0.0801\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0863 - val_loss: 0.0736\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0864 - val_loss: 0.0856\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0863 - val_loss: 0.0805\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0858 - val_loss: 0.0830\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0861 - val_loss: 0.0810\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0859 - val_loss: 0.0802\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0859 - val_loss: 0.0767\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0856 - val_loss: 0.0818\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0858 - val_loss: 0.0789\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0856 - val_loss: 0.0748\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0856 - val_loss: 0.0791\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 32\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 148us/sample - loss: 0.1427 - val_loss: 0.1132\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.1194 - val_loss: 0.1016\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1166 - val_loss: 0.1037\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1150 - val_loss: 0.1069\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1127 - val_loss: 0.1025\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1108 - val_loss: 0.1016\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1101 - val_loss: 0.1122\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1080 - val_loss: 0.1064\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1049 - val_loss: 0.0956\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.1032 - val_loss: 0.0937\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.1017 - val_loss: 0.0900\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.1004 - val_loss: 0.0908\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0996 - val_loss: 0.0936\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0985 - val_loss: 0.0925\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0971 - val_loss: 0.0896\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0965 - val_loss: 0.0892\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0956 - val_loss: 0.0867\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0957 - val_loss: 0.0886\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0952 - val_loss: 0.0874\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0943 - val_loss: 0.0876\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0938 - val_loss: 0.0884\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0937 - val_loss: 0.0891\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0933 - val_loss: 0.0919\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0930 - val_loss: 0.0876\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0931 - val_loss: 0.0843\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 64us/sample - loss: 0.0923 - val_loss: 0.0797\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 64us/sample - loss: 0.0926 - val_loss: 0.0876\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0922 - val_loss: 0.0848\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0914 - val_loss: 0.0839\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0918 - val_loss: 0.0878\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0912 - val_loss: 0.0869\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.0910 - val_loss: 0.0877\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0912 - val_loss: 0.0832\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0905 - val_loss: 0.0832\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 63us/sample - loss: 0.0904 - val_loss: 0.0821\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 62us/sample - loss: 0.0903 - val_loss: 0.0838\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 64\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 159us/sample - loss: 0.1376 - val_loss: 0.1070\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.1177 - val_loss: 0.1030\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 3s 75us/sample - loss: 0.1161 - val_loss: 0.1020\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 3s 75us/sample - loss: 0.1145 - val_loss: 0.1117\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.1123 - val_loss: 0.1017\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 3s 74us/sample - loss: 0.1095 - val_loss: 0.1006\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.1077 - val_loss: 0.1020\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 72us/sample - loss: 0.1052 - val_loss: 0.1017\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.1022 - val_loss: 0.0949\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.1005 - val_loss: 0.0918\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0991 - val_loss: 0.0899\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0991 - val_loss: 0.0910\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0979 - val_loss: 0.0991\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0968 - val_loss: 0.0912\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0961 - val_loss: 0.0851\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0955 - val_loss: 0.0894\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0946 - val_loss: 0.0850\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 3s 74us/sample - loss: 0.0938 - val_loss: 0.0881\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 71us/sample - loss: 0.0936 - val_loss: 0.0860\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0937 - val_loss: 0.0872\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0925 - val_loss: 0.0912\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0923 - val_loss: 0.0874\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 3s 74us/sample - loss: 0.0919 - val_loss: 0.0904\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0916 - val_loss: 0.0805\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0911 - val_loss: 0.0817\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0901 - val_loss: 0.0795\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0901 - val_loss: 0.0838\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 3s 74us/sample - loss: 0.0897 - val_loss: 0.0905\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0889 - val_loss: 0.0807\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0890 - val_loss: 0.0828\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0889 - val_loss: 0.0819\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 74us/sample - loss: 0.0882 - val_loss: 0.0821\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0883 - val_loss: 0.0781\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0878 - val_loss: 0.0820\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 72us/sample - loss: 0.0873 - val_loss: 0.0800\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 72us/sample - loss: 0.0873 - val_loss: 0.0834\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 70us/sample - loss: 0.0871 - val_loss: 0.0973\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 72us/sample - loss: 0.0870 - val_loss: 0.0827\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0870 - val_loss: 0.0867\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 71us/sample - loss: 0.0866 - val_loss: 0.0873\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 72us/sample - loss: 0.0862 - val_loss: 0.0816\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 73us/sample - loss: 0.0858 - val_loss: 0.0787\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 71us/sample - loss: 0.0862 - val_loss: 0.0854\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 128\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 7s 198us/sample - loss: 0.1362 - val_loss: 0.1100\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.1171 - val_loss: 0.1062\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 4s 111us/sample - loss: 0.1157 - val_loss: 0.1037\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 4s 115us/sample - loss: 0.1154 - val_loss: 0.1104\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.1116 - val_loss: 0.1029\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.1091 - val_loss: 0.1013\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.1070 - val_loss: 0.1036\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 4s 115us/sample - loss: 0.1038 - val_loss: 0.0951\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.1012 - val_loss: 0.1007\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0996 - val_loss: 0.0873\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0979 - val_loss: 0.0873\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.0970 - val_loss: 0.0893\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.0953 - val_loss: 0.0953\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0945 - val_loss: 0.0888\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0932 - val_loss: 0.0808\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 4s 112us/sample - loss: 0.0926 - val_loss: 0.0846\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.0918 - val_loss: 0.0798\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 4s 117us/sample - loss: 0.0911 - val_loss: 0.0891\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0908 - val_loss: 0.0766\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 4s 117us/sample - loss: 0.0909 - val_loss: 0.0811\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0895 - val_loss: 0.0886\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0893 - val_loss: 0.0862\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0891 - val_loss: 0.0867\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0888 - val_loss: 0.0796\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0882 - val_loss: 0.0760\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0878 - val_loss: 0.0816\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0878 - val_loss: 0.0848\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0871 - val_loss: 0.0913\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 4s 115us/sample - loss: 0.0866 - val_loss: 0.0773\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 4s 113us/sample - loss: 0.0866 - val_loss: 0.0776\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0863 - val_loss: 0.0825\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 4s 114us/sample - loss: 0.0855 - val_loss: 0.0793\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 4s 115us/sample - loss: 0.0855 - val_loss: 0.0769\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 4s 115us/sample - loss: 0.0851 - val_loss: 0.0809\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 4s 116us/sample - loss: 0.0844 - val_loss: 0.0808\n"
     ]
    }
   ],
   "source": [
    "lag_vec = [7,14,]\n",
    "units_vec = [2,4,8,16,32,64,128]\n",
    "results = cross_validation(lag_vec, units_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4389.88818162 3408.24324912 3103.29016507 2965.58806074 3019.14940067\n",
      "   2608.55434964 2683.15787905]\n",
      "  [4453.38832929 3442.1507907  3227.14643948 2968.87168205 2718.9573569\n",
      "   2713.91022752 2655.83005214]]\n",
      "\n",
      " [[4605.46512057 4004.06025351 3605.53991896 3172.28842222 3042.41855508\n",
      "   3169.64465529 3060.23380088]\n",
      "  [3776.32098074 3557.99835284 3162.24124559 3101.85057255 2953.73276092\n",
      "   3090.39474704 2989.88227854]]\n",
      "\n",
      " [[5005.0684729  4243.57393758 4306.15818705 4220.97475769 3778.54128133\n",
      "   3777.11471354 3841.22236003]\n",
      "  [5130.66436686 4336.27614299 3963.32270915 3690.7031368  3999.54302653\n",
      "   3921.47391968 3815.08659587]]]\n",
      "14 128\n"
     ]
    }
   ],
   "source": [
    "MAE = results[2,:]\n",
    "print(MAE)\n",
    "MAE = numpy.sum(MAE, axis=0)\n",
    "ind = numpy.unravel_index(numpy.argmin(MAE, axis=None), MAE.shape)\n",
    "\n",
    "lag = lag_vec[ind[0]]\n",
    "units = units_vec[ind[1]]\n",
    "print(lag,units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14000.4217751 , 11655.87744021, 11014.98827108, 10358.85124065,\n",
       "         9840.10923709,  9555.31371847,  9584.61403995],\n",
       "       [13360.37367689, 11336.42528652, 10352.71039422,  9761.4253914 ,\n",
       "         9672.23314435,  9725.77889424,  9460.79892654]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34540 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "34540/34540 [==============================] - 5s 144us/sample - loss: 0.1449 - val_loss: 0.1508\n",
      "Epoch 2/100\n",
      "34540/34540 [==============================] - 2s 64us/sample - loss: 0.1227 - val_loss: 0.1610\n",
      "Epoch 3/100\n",
      "34540/34540 [==============================] - 2s 60us/sample - loss: 0.1185 - val_loss: 0.1658\n",
      "Epoch 4/100\n",
      "34540/34540 [==============================] - 2s 60us/sample - loss: 0.1172 - val_loss: 0.1717\n",
      "Epoch 5/100\n",
      "34540/34540 [==============================] - 2s 62us/sample - loss: 0.1167 - val_loss: 0.1666\n",
      "Epoch 6/100\n",
      "34540/34540 [==============================] - 2s 61us/sample - loss: 0.1152 - val_loss: 0.1733\n",
      "Epoch 7/100\n",
      "34540/34540 [==============================] - 2s 58us/sample - loss: 0.1141 - val_loss: 0.1676\n",
      "Epoch 8/100\n",
      "34540/34540 [==============================] - 2s 61us/sample - loss: 0.1117 - val_loss: 0.1633\n",
      "Epoch 9/100\n",
      "34540/34540 [==============================] - 2s 62us/sample - loss: 0.1089 - val_loss: 0.1662\n",
      "Epoch 10/100\n",
      "34540/34540 [==============================] - 2s 60us/sample - loss: 0.1062 - val_loss: 0.1628\n",
      "Epoch 11/100\n",
      "34540/34540 [==============================] - 2s 59us/sample - loss: 0.1051 - val_loss: 0.1600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 11006.736328125\n",
      "MAPE: 0.2291406225500865\n",
      "MAE: 7564.96230389995\n",
      "R2 score: 0.36527386291844055\n",
      " \n",
      " \n",
      "---------------------------------------------------\n",
      "Train on 35160 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "35160/35160 [==============================] - 5s 142us/sample - loss: 0.1436 - val_loss: 0.1228\n",
      "Epoch 2/100\n",
      "35160/35160 [==============================] - 2s 62us/sample - loss: 0.1223 - val_loss: 0.1333\n",
      "Epoch 3/100\n",
      "35160/35160 [==============================] - 2s 63us/sample - loss: 0.1181 - val_loss: 0.1376\n",
      "Epoch 4/100\n",
      "35160/35160 [==============================] - 2s 60us/sample - loss: 0.1162 - val_loss: 0.1361\n",
      "Epoch 5/100\n",
      "35160/35160 [==============================] - 2s 60us/sample - loss: 0.1147 - val_loss: 0.1421\n",
      "Epoch 6/100\n",
      "35160/35160 [==============================] - 2s 62us/sample - loss: 0.1140 - val_loss: 0.1479\n",
      "Epoch 7/100\n",
      "35160/35160 [==============================] - 2s 60us/sample - loss: 0.1118 - val_loss: 0.1372\n",
      "Epoch 8/100\n",
      "35160/35160 [==============================] - 2s 62us/sample - loss: 0.1103 - val_loss: 0.1432\n",
      "Epoch 9/100\n",
      "35160/35160 [==============================] - 2s 61us/sample - loss: 0.1080 - val_loss: 0.1418\n",
      "Epoch 10/100\n",
      "35160/35160 [==============================] - 2s 60us/sample - loss: 0.1059 - val_loss: 0.1379\n",
      "Epoch 11/100\n",
      "35160/35160 [==============================] - 2s 60us/sample - loss: 0.1044 - val_loss: 0.1388\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 9429.8095703125\n",
      "MAPE: 0.7025817692160733\n",
      "MAE: 6163.05313639323\n",
      "R2 score: -0.1806358236668757\n",
      " \n",
      " \n",
      "---------------------------------------------------\n",
      "Train on 35760 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "35760/35760 [==============================] - 5s 138us/sample - loss: 0.1449 - val_loss: 0.0884\n",
      "Epoch 2/100\n",
      "35760/35760 [==============================] - 2s 59us/sample - loss: 0.1239 - val_loss: 0.0833\n",
      "Epoch 3/100\n",
      "35760/35760 [==============================] - 2s 58us/sample - loss: 0.1194 - val_loss: 0.0837\n",
      "Epoch 4/100\n",
      "35760/35760 [==============================] - 2s 59us/sample - loss: 0.1172 - val_loss: 0.0802\n",
      "Epoch 5/100\n",
      "35760/35760 [==============================] - 2s 57us/sample - loss: 0.1159 - val_loss: 0.0816\n",
      "Epoch 6/100\n",
      "35760/35760 [==============================] - 2s 60us/sample - loss: 0.1145 - val_loss: 0.0797\n",
      "Epoch 7/100\n",
      "35760/35760 [==============================] - 2s 59us/sample - loss: 0.1124 - val_loss: 0.0779\n",
      "Epoch 8/100\n",
      "35760/35760 [==============================] - 2s 60us/sample - loss: 0.1104 - val_loss: 0.0766\n",
      "Epoch 9/100\n",
      "35760/35760 [==============================] - 2s 61us/sample - loss: 0.1082 - val_loss: 0.0753\n",
      "Epoch 10/100\n",
      "35760/35760 [==============================] - 2s 59us/sample - loss: 0.1062 - val_loss: 0.0761\n",
      "Epoch 11/100\n",
      "35760/35760 [==============================] - 2s 61us/sample - loss: 0.1049 - val_loss: 0.0765\n",
      "Epoch 12/100\n",
      "35760/35760 [==============================] - 2s 58us/sample - loss: 0.1034 - val_loss: 0.0782\n",
      "Epoch 13/100\n",
      "35760/35760 [==============================] - 2s 60us/sample - loss: 0.1016 - val_loss: 0.0789\n",
      "Epoch 14/100\n",
      "35760/35760 [==============================] - 2s 58us/sample - loss: 0.1009 - val_loss: 0.0784\n",
      "Epoch 15/100\n",
      "35760/35760 [==============================] - 2s 58us/sample - loss: 0.1006 - val_loss: 0.0788\n",
      "Epoch 16/100\n",
      "35760/35760 [==============================] - 2s 61us/sample - loss: 0.0996 - val_loss: 0.0771\n",
      "Epoch 17/100\n",
      "35760/35760 [==============================] - 2s 60us/sample - loss: 0.0990 - val_loss: 0.0782\n",
      "Epoch 18/100\n",
      "35760/35760 [==============================] - 2s 58us/sample - loss: 0.0984 - val_loss: 0.0785\n",
      "Epoch 19/100\n",
      "35760/35760 [==============================] - 2s 60us/sample - loss: 0.0982 - val_loss: 0.0766\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 5854.46240234375\n",
      "MAPE: 0.14334865492365356\n",
      "MAE: 3778.870342426915\n",
      "R2 score: 0.4256840095050578\n",
      " \n",
      " \n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# lag=14\n",
    "ds=['october','november','december']\n",
    "data_LSTM_X, data_LSTM_Y = sequence_data_build(data, 7)\n",
    "totday = int(data_LSTM_X.shape[0]/20)\n",
    "m1 = [totday-61, totday-31, totday, ]\n",
    "m2 = [m1[0]-31, m1[1]-30, m1[2]-31, ]\n",
    "for i in range(len(m1)):\n",
    "    trainX, trainY, testX, testY = train_test_build(data_LSTM_X, data_LSTM_Y, m1[i], m2[i])\n",
    "    testYcopy=testY\n",
    "    saving = True\n",
    "    EarlyStop = True\n",
    "    rmse, mape, mae, r2, history = model_build(trainX, trainY, testX, testY, 32, saving, ds[i], EarlyStop)\n",
    "        \n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.xlabel(\"Epochs\")\n",
    "    pyplot.ylabel(\"Mean absolute error\")\n",
    "    pyplot.savefig(\"SM3F_\" + ds[i] + \".png\")\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "    print(\"Root mean square error: {0}\".format(rmse))\n",
    "    print(\"MAPE: {0}\".format(mape))\n",
    "    print(\"MAE: {0}\".format(mae))\n",
    "    print(\"R2 score: {0}\".format(r2))\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag vector\n",
      "[7, 14]\n",
      "LSTM units\n",
      "[2, 4, 8, 16, 32, 64, 128]\n",
      "----------------------------\n",
      "RMSE\n",
      "[[[5985.91162109 4749.82861328 4370.43457031 4174.17382812 4218.47705078\n",
      "   3893.57202148 3996.71826172]\n",
      "  [5865.63330078 4829.68261719 4406.78662109 4150.89355469 3893.29785156\n",
      "   3894.04223633 3847.32983398]]\n",
      "\n",
      " [[6069.59326172 5535.50976562 4828.40820312 4439.98730469 4249.96337891\n",
      "   4357.0234375  4317.10449219]\n",
      "  [5152.12939453 4925.87695312 4467.83105469 4445.28417969 4200.15380859\n",
      "   4365.25195312 4361.67773438]]\n",
      "\n",
      " [[7509.93115234 6428.03369141 6465.31347656 6728.41748047 6197.22705078\n",
      "   5894.04052734 6287.8359375 ]\n",
      "  [7705.02539062 6597.67675781 6333.01757812 5985.27294922 6577.32275391\n",
      "   6475.97460938 6022.95800781]]]\n",
      "----------------------------\n",
      "MAE\n",
      "[[[0.22139527 0.13834338 0.11626332 0.11280267 0.12330396 0.09892969\n",
      "   0.10336064]\n",
      "  [0.23090733 0.1289079  0.12457249 0.11528977 0.10052719 0.10414752\n",
      "   0.09509252]]\n",
      "\n",
      " [[0.23515796 0.17776685 0.17986985 0.13008136 0.11991255 0.13197155\n",
      "   0.1238133 ]\n",
      "  [0.16527762 0.14339163 0.1225106  0.12737076 0.12130688 0.1217796\n",
      "   0.12267475]]\n",
      "\n",
      " [[0.2007273  0.15262968 0.1629624  0.14630271 0.13533673 0.13364207\n",
      "   0.13385817]\n",
      "  [0.19215142 0.15468605 0.13757903 0.13203595 0.14819011 0.1572632\n",
      "   0.13362645]]]\n",
      "----------------------------\n",
      "MAPE\n",
      "[[[4389.88818162 3408.24324912 3103.29016507 2965.58806074 3019.14940067\n",
      "   2608.55434964 2683.15787905]\n",
      "  [4453.38832929 3442.1507907  3227.14643948 2968.87168205 2718.9573569\n",
      "   2713.91022752 2655.83005214]]\n",
      "\n",
      " [[4605.46512057 4004.06025351 3605.53991896 3172.28842222 3042.41855508\n",
      "   3169.64465529 3060.23380088]\n",
      "  [3776.32098074 3557.99835284 3162.24124559 3101.85057255 2953.73276092\n",
      "   3090.39474704 2989.88227854]]\n",
      "\n",
      " [[5005.0684729  4243.57393758 4306.15818705 4220.97475769 3778.54128133\n",
      "   3777.11471354 3841.22236003]\n",
      "  [5130.66436686 4336.27614299 3963.32270915 3690.7031368  3999.54302653\n",
      "   3921.47391968 3815.08659587]]]\n",
      "----------------------------\n",
      "R2-score\n",
      "[[[0.73658397 0.83414158 0.85957939 0.87190782 0.86917433 0.88855053\n",
      "   0.88256742]\n",
      "  [0.74706356 0.82851789 0.85723372 0.87333261 0.88856622 0.8885236\n",
      "   0.89118207]]\n",
      "\n",
      " [[0.7295348  0.77503885 0.82884081 0.85527094 0.86739414 0.86062913\n",
      "   0.86317123]\n",
      "  [0.80512067 0.82186086 0.85345002 0.85492542 0.87048422 0.86010219\n",
      "   0.86033119]]\n",
      "\n",
      " [[0.66563348 0.75503323 0.75218356 0.73160356 0.77230907 0.79404274\n",
      "   0.76560234]\n",
      "  [0.64803533 0.74193271 0.76222168 0.78761743 0.74352253 0.75136563\n",
      "   0.78493459]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"lag vector\")\n",
    "print(lag_vec)\n",
    "print(\"LSTM units\")\n",
    "print(units_vec)\n",
    "print(\"----------------------------\")\n",
    "print(\"RMSE\")\n",
    "print(results[0,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"MAE\")\n",
    "print(results[1,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"MAPE\")\n",
    "print(results[2,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"R2-score\")\n",
    "print(results[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1751, 1781, 1812]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1720, 1751, 1781]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
