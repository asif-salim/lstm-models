{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,  mean_absolute_error, r2_score\n",
    " \n",
    "# tensorflow.reset_default_graph()\n",
    "tensorflow.random.set_seed(0)\n",
    "# random.seed(0)\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=14, day_offset=5):\n",
    "    dataX, dataY= [],[]\n",
    "    dataX=numpy.zeros([(len(dataset)-look_back),4,look_back])\n",
    "    \n",
    "    #print(dataX.shape)\n",
    "    for i in range(look_back,len(dataset)):\n",
    "       # print(i)\n",
    "        a = numpy.zeros([4,look_back])\n",
    "        t1=dataset[(i-look_back):i, 0]\n",
    "        t1=numpy.reshape(t1,[1,look_back])\n",
    "        t4=dataset[(i-look_back):i, 48]\n",
    "        t4=numpy.reshape(t4,[1,look_back])\n",
    "        #print(t1.shape)\n",
    "        t2=dataset[i, 48-look_back:48]\n",
    "        t2=numpy.reshape(t2,[1,look_back])\n",
    "        t6=dataset[i,-(look_back+3):-3]\n",
    "        t6=numpy.reshape(t6,[1,look_back])\n",
    "#         t3=numpy.zeros([1,look_back])\n",
    "#         if i>=((day_offset+1)*7+look_back):\n",
    "#             t3[0,0:day_offset]=[dataset[j,0] for j in range(i-(((day_offset+1)*7)+look_back),i-(look_back+7),7)]\n",
    "#         t5=numpy.zeros([1,look_back])\n",
    "#         if i>=((day_offset+1)*7+look_back):\n",
    "#             t5[0,0:day_offset]=[dataset[j,48] for j in range(i-(((day_offset+1)*7)+look_back),i-(look_back+7),7)]\n",
    "            \n",
    "            \n",
    "        #print(t2.shape)\n",
    "        a[0,:] = t1\n",
    "        a[1,:] = t4\n",
    "        a[2,:] = t2\n",
    "        a[3,:] = t6\n",
    "        \n",
    "        dataX[i-look_back,:,:]=a\n",
    "#         a = numpy.concatenate([dataset[(i-look_back-7):i-7, 0], dataset[i,-14:]],axis=1)\n",
    "        \n",
    "        #dataX.append(a)\n",
    "        dataY.append(dataset[i,-1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(datarange, categorical=[]):  \n",
    "    datarange= pd.DataFrame(datarange)\n",
    "    if not categorical:\n",
    "        meandata=datarange.mean()\n",
    "        meandata=meandata.to_numpy()\n",
    "    else:\n",
    "        meandata=datarange.mean()\n",
    "        meandata=meandata.to_numpy()\n",
    "        \n",
    "        modedata = datarange.mode()\n",
    "        modedata = modedata.to_numpy()\n",
    "        modedata = modedata[0,:]\n",
    "        \n",
    "        for i in categorical:\n",
    "                meandata[i-1] = modedata[i]\n",
    "                \n",
    "    datetime_series = pd.to_datetime(datarange['fltdat'])\n",
    "    miss_idx=pd.date_range(start = '01-01-2015', end = '31-12-2019' ).difference(datetime_series)\n",
    "    datetime_index = pd.DatetimeIndex(datetime_series.values)\n",
    "    datarange=datarange.set_index(datetime_index)\n",
    "\n",
    "    datarange.drop('fltdat',axis=1,inplace=True)\n",
    "    newidx = pd.date_range('01-01-2015', '31-12-2019')\n",
    "    datarange = datarange.reindex(newidx, fill_value=0)\n",
    "    \n",
    "    meandata=meandata.reshape(1,meandata.shape[0])\n",
    "    dat = numpy.tile(meandata, [miss_idx.shape[0],1])\n",
    "    datarange.loc[miss_idx]=dat\n",
    "    return datarange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "        import numpy as np\n",
    "        t = np.array(y_test)\n",
    "        p = np.array(y_pred)\n",
    "        mae = list()\n",
    "        mape = list()\n",
    "        for i in range(len(t)):\n",
    "            if (t[i] == 0):\n",
    "                mae.append(abs(p[i]))\n",
    "            else:\n",
    "                mae.append(float(abs(t[i] - p[i])))\n",
    "                mape.append(float(abs((t[i] - p[i])/t[i])))\n",
    "        return np.mean(mae) , np.mean(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fltdat', 'paxcntfc', 'fltnum', 'legorg', 'legdst', 'acrtypcod',\n",
      "       'keyidr', 'totpaylodwgt', 'totpaylodvol', 'totpaylodpos', 'totsetfc',\n",
      "       'totpaxwgt', 'dp_51', 'dp_50', 'dp_49', 'dp_48', 'dp_47', 'dp_46',\n",
      "       'dp_45', 'dp_44', 'dp_43', 'dp_42', 'dp_41', 'dp_40', 'dp_39', 'dp_38',\n",
      "       'dp_37', 'dp_36', 'dp_35', 'dp_34', 'dp_33', 'dp_32', 'dp_31', 'dp_30',\n",
      "       'dp_29', 'dp_28', 'dp_27', 'dp_26', 'dp_25', 'dp_24', 'dp_23', 'dp_22',\n",
      "       'dp_21', 'dp_20', 'dp_19', 'dp_18', 'dp_17', 'dp_16', 'dp_15', 'dp_14',\n",
      "       'dp_13', 'dp_12', 'dp_11', 'dp_10', 'dp_9', 'dp_8', 'dp_7', 'dp_6',\n",
      "       'dp_5', 'dp_4', 'dp_3', 'dp_2', 'dp_1'],\n",
      "      dtype='object')\n",
      "Index(['fltdat', 'paxcntfc', 'acrtypcod', 'totpaylodwgt', 'totpaxwgt', 'dp_51',\n",
      "       'dp_50', 'dp_49', 'dp_48', 'dp_47', 'dp_46', 'dp_45', 'dp_44', 'dp_43',\n",
      "       'dp_42', 'dp_41', 'dp_40', 'dp_39', 'dp_38', 'dp_37', 'dp_36', 'dp_35',\n",
      "       'dp_34', 'dp_33', 'dp_32', 'dp_31', 'dp_30', 'dp_29', 'dp_28', 'dp_27',\n",
      "       'dp_26', 'dp_25', 'dp_24', 'dp_23', 'dp_22', 'dp_21', 'dp_20', 'dp_19',\n",
      "       'dp_18', 'dp_17', 'dp_16', 'dp_15', 'dp_14', 'dp_13', 'dp_12', 'dp_11',\n",
      "       'dp_10', 'dp_9', 'dp_8', 'paxcnty', 'dcp_51', 'dcp_50', 'dcp_49',\n",
      "       'dcp_48', 'dcp_47', 'dcp_46', 'dcp_45', 'dcp_44', 'dcp_43', 'dcp_42',\n",
      "       'dcp_41', 'dcp_40', 'dcp_39', 'dcp_38', 'dcp_37', 'dcp_36', 'dcp_35',\n",
      "       'dcp_34', 'dcp_33', 'dcp_3', 'dcp_31', 'dcp_30', 'dcp_29', 'dcp_28',\n",
      "       'dcp_27', 'dcp_26', 'dcp_25', 'dcp_24', 'dcp_23', 'dcp_22', 'dcp_21',\n",
      "       'dcp_20', 'dcp_19', 'dcp_18', 'dcp_17', 'dcp_16', 'dcp_15', 'dcp_14',\n",
      "       'dcp_13', 'dcp_12', 'dcp_11', 'dcp_10', 'dcp_9', 'dcp_8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('data/rmscapfc.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "print(dataframe.columns)\n",
    "dataframe.drop(dataframe.columns[[2,3,4,6,8,9,10,56,57,58,59,60,61,62] ], axis=1, inplace=True)\n",
    "\n",
    "dataframe2 = read_csv('data/rmscapy.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "# print(dataframe2.columns)\n",
    "f_column = dataframe2[[\"paxcnty\", \"dcp_51\", \"dcp_50\", \"dcp_49\", \"dcp_48\", \"dcp_47\", \"dcp_46\",\n",
    "       \"dcp_45\", \"dcp_44\", \"dcp_43\", \"dcp_42\", \"dcp_41\", \"dcp_40\", \"dcp_39\",\n",
    "       \"dcp_38\", \"dcp_37\", \"dcp_36\", \"dcp_35\", \"dcp_34\", \"dcp_33\", \"dcp_3\",\n",
    "       \"dcp_31\", \"dcp_30\", \"dcp_29\", \"dcp_28\", \"dcp_27\", \"dcp_26\", \"dcp_25\",\n",
    "       \"dcp_24\", \"dcp_23\", \"dcp_22\", \"dcp_21\", \"dcp_20\", \"dcp_19\", \"dcp_18\",\n",
    "       \"dcp_17\", \"dcp_16\", \"dcp_15\", \"dcp_14\", \"dcp_13\", \"dcp_12\", \"dcp_11\",\n",
    "       \"dcp_10\", \"dcp_9\", \"dcp_8\"]]\n",
    " \n",
    "\n",
    "dataframe = pd.concat([dataframe,f_column], axis = 1)\n",
    "# print(dataframe.columns)\n",
    "dataframe3 = read_csv('data/uldfc.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "\n",
    "dataframe3.drop(dataframe3.columns[[1,2,3] ], axis=1, inplace=True)\n",
    "dataframe4 = read_csv('data/uldy.csv', parse_dates=['fltdat'],dayfirst=True)\n",
    "dataframe4.drop(dataframe4.columns[[1,2,3] ], axis=1, inplace=True)\n",
    "f_column = dataframe4[[\"county\"]]\n",
    "dataframe3 = pd.concat([dataframe3,f_column], axis = 1)\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM=[0,1825,1825,1817,1816,1812,1821,1825,1824,1819,1825,1825,1824,1826,1819,1825,1822,1823,1813, 1826, 1820]\n",
    "NUMuld=[0,1817,1574,1808,1802,1807,1808,1730,1817,1385,1820,1816,1606,1819,1810,1817,421,1813,434,1532,1814]\n",
    "cat_inp=[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iist\\anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  import sys\n",
      "C:\\Users\\iist\\anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# dataset, datasetY = numpy.empty([1805,3,look_back]), []\n",
    "for i in range(0,len(NUM)-1):\n",
    "#     print(i)\n",
    "    datasub = dataframe.iloc[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "#     datasub=datasetall[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "    datasub = missing_values(datasub, cat_inp)\n",
    "    datasub = datasub.values\n",
    "    datasub = datasub.astype('float32')\n",
    "    \n",
    "    datasubuld = dataframe3.iloc[sum(NUMuld[0:i+1]):sum(NUMuld[0:i+2]),:]\n",
    "#     datasub=datasetall[sum(NUM[0:i+1]):sum(NUM[0:i+2]),:]\n",
    "    datasubuld = missing_values(datasubuld)\n",
    "    datasubuld = datasubuld.values\n",
    "    datasubuld = datasubuld.astype('float32')\n",
    "    \n",
    "    datasub = numpy.concatenate([datasub, datasubuld], axis=1)\n",
    "    if i==0:\n",
    "        data = datasub\n",
    "    else:\n",
    "        data = numpy.concatenate([data, datasub], axis =0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36520, 96)\n"
     ]
    }
   ],
   "source": [
    "out = data[:,2] - data[:,3] - (data[:,-1]*data[:,-2]*114)\n",
    "out = out.reshape(out.shape[0],1)\n",
    "data = numpy.concatenate([data,out], axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_data_build(data, look_back):\n",
    "    for i in range(0,20):\n",
    "        datasub = data[i*1826:((i+1)*1826),:]\n",
    "        X, Y = create_dataset(datasub, look_back)\n",
    "        Y = Y.reshape(Y.shape[0],1)\n",
    "        if i==0: \n",
    "            data_LSTM_X = X\n",
    "            data_LSTM_Y = Y\n",
    "        else:\n",
    "            data_LSTM_X = numpy.concatenate([data_LSTM_X, X],axis=0)\n",
    "            data_LSTM_Y = numpy.concatenate([data_LSTM_Y, Y],axis=0)\n",
    "    return data_LSTM_X, data_LSTM_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_build(X, Y, m1, m2):\n",
    "    spliter = int(X.shape[0]/20)\n",
    "    tot_len = m1\n",
    "    train_len = m2\n",
    "    for i in range(0,20):\n",
    "        Xsub = X[i*spliter:((i+1)*spliter),:]\n",
    "        Ysub = Y[i*spliter:((i+1)*spliter)]\n",
    "        if i==0:\n",
    "            trainX = Xsub[0:m2,:]\n",
    "            testX = Xsub[m2:m1,:]\n",
    "            trainY = Ysub[0:m2]\n",
    "            testY = Ysub[m2:m1]\n",
    "        else:\n",
    "            trainX = numpy.concatenate([trainX, Xsub[0:m2,:]], axis=0)\n",
    "            testX = numpy.concatenate([testX, Xsub[m2:m1,:]], axis=0)\n",
    "            trainY = numpy.concatenate([trainY, Ysub[0:m2]], axis=0)\n",
    "            testY = numpy.concatenate([testY, Ysub[m2:m1]], axis=0)\n",
    "        \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(trainX, trainY, testX, testY, units, saving =False, month=None, EarlyStop = False):\n",
    "    \n",
    "    if EarlyStop:\n",
    "        callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,\n",
    "                                                            mode = 'min', restore_best_weights=True)\n",
    "                                                            \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    if EarlyStop:\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=150, validation_data=(testX, testY),verbose=1,\n",
    "                            callbacks=[callback])\n",
    "    else:\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=150, validation_data=(testX, testY),verbose=1, )#callbacks=[callback]\n",
    "                  \n",
    "    testPredict = model.predict(testX)\n",
    "                \n",
    "    sh = testPredict.shape\n",
    "    inv_yhat = testPredict.reshape(sh[0]*sh[1],1)\n",
    "    inv_yhat = numpy.concatenate([ data[0:inv_yhat.shape[0],0:95], inv_yhat], axis=1)\n",
    "\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,-1]\n",
    "    testY = testY.reshape(sh[0]*sh[1],1)\n",
    " \n",
    "    inv_y = numpy.concatenate([data[0:testY.shape[0],0:95], testY], axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,-1]\n",
    "             \n",
    "    rmse = numpy.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    mae, mape = mean_absolute_percentage_error(inv_y, inv_yhat) \n",
    "    r2 = r2_score(inv_y, inv_yhat)\n",
    "    \n",
    "    res=[]\n",
    "    if saving:\n",
    "        inv_y = inv_y.reshape(inv_y.shape[0],1) \n",
    "        inv_yhat = inv_yhat.reshape(inv_yhat.shape[0],1) \n",
    "        res = numpy.concatenate([inv_y, inv_yhat], axis=1)\n",
    "        df = pd.DataFrame(res)\n",
    "        res = df.to_csv(\"ds_\" + month + \".csv\", index = False)\n",
    "    return rmse, mape,mae,r2, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(lag_vec = [7,14,21,28], units_vec = [2,4,8,16,32,64,128]):\n",
    "    results = numpy.zeros([4,3,len(lag_vec),len(units_vec)])\n",
    "    \n",
    "    for folds in range(0,3):\n",
    "        for i in range(0,len(lag_vec)):\n",
    "            data_LSTM_X, data_LSTM_Y = sequence_data_build(data, lag_vec[i])\n",
    "            totday = int(data_LSTM_X.shape[0]/20)\n",
    "#             print(totday)\n",
    "            m1 = [totday-152, totday-121, totday-91, ]\n",
    "            m2 = [m1[0]-31, m1[1]-31, m1[2]-30, ]\n",
    "            lag = lag_vec[i]\n",
    "            trainX, trainY, testX, testY= train_test_build(data_LSTM_X, data_LSTM_Y, m1[folds], m2[folds])\n",
    "            testYcopy=testY\n",
    "            for j in range(0, len(units_vec)):\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"fold: {0}, lag: {1}, units: {2}\".format(folds, lag_vec[i], units_vec[j]))\n",
    "                units = units_vec[j]\n",
    "                rmse, mape, mae, r2, his = model_build(trainX, trainY, testX, testY, units, EarlyStop=True) \n",
    "                results[0,folds,i,j] = rmse \n",
    "                results[2,folds,i,j], results[1,folds,i,j] = mae, mape\n",
    "                results[3,folds,i,j] = r2\n",
    "    return results        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 2\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 6s 189us/sample - loss: 0.1883 - val_loss: 0.1412\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1532 - val_loss: 0.1174\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1418 - val_loss: 0.1116\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1379 - val_loss: 0.1118\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1353 - val_loss: 0.1048\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1331 - val_loss: 0.1039\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1312 - val_loss: 0.1031\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1296 - val_loss: 0.1015\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1281 - val_loss: 0.0999\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1269 - val_loss: 0.1031\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1259 - val_loss: 0.1035\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1252 - val_loss: 0.1009\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1245 - val_loss: 0.0986\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1240 - val_loss: 0.0998\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1235 - val_loss: 0.0971\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1231 - val_loss: 0.0981\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1227 - val_loss: 0.1008\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1224 - val_loss: 0.0976\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1222 - val_loss: 0.0954\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1219 - val_loss: 0.0975\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1216 - val_loss: 0.0990\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1214 - val_loss: 0.0962\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1212 - val_loss: 0.0992\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1210 - val_loss: 0.0976\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1207 - val_loss: 0.0953\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1205 - val_loss: 0.0979\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1203 - val_loss: 0.0964\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1202 - val_loss: 0.0981\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1201 - val_loss: 0.1000\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1199 - val_loss: 0.0967\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1197 - val_loss: 0.0991\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1196 - val_loss: 0.1040\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1197 - val_loss: 0.0979\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1194 - val_loss: 0.0975\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1194 - val_loss: 0.0977\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1191 - val_loss: 0.0981\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1189 - val_loss: 0.0968\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1190 - val_loss: 0.0957\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1188 - val_loss: 0.0970\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1186 - val_loss: 0.0958\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1186 - val_loss: 0.1009\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1185 - val_loss: 0.0983\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1184 - val_loss: 0.0992\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1183 - val_loss: 0.0962\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1182 - val_loss: 0.1009\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1183 - val_loss: 0.1026\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1182 - val_loss: 0.0987\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1181 - val_loss: 0.0952\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1180 - val_loss: 0.0989\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1179 - val_loss: 0.1015\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1179 - val_loss: 0.1001\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1177 - val_loss: 0.0957\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1177 - val_loss: 0.0958\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1177 - val_loss: 0.0992\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1176 - val_loss: 0.0968\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1175 - val_loss: 0.0969\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1174 - val_loss: 0.0962\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1173 - val_loss: 0.0980\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 47us/sample - loss: 0.1173 - val_loss: 0.0971\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1172 - val_loss: 0.0968\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 1s 46us/sample - loss: 0.1172 - val_loss: 0.0981\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1172 - val_loss: 0.0970\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1170 - val_loss: 0.1027\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 47us/sample - loss: 0.1170 - val_loss: 0.0985\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1169 - val_loss: 0.0982\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1169 - val_loss: 0.0970\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1168 - val_loss: 0.0964\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1167 - val_loss: 0.1008\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1168 - val_loss: 0.0977\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1166 - val_loss: 0.0947\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1167 - val_loss: 0.0970\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1165 - val_loss: 0.0954\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1165 - val_loss: 0.0934\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1164 - val_loss: 0.0973\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1163 - val_loss: 0.0967\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.0964\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1163 - val_loss: 0.0974\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1162 - val_loss: 0.0950\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.0942\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1162 - val_loss: 0.0977\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1160 - val_loss: 0.1002\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1160 - val_loss: 0.1009\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1159 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1159 - val_loss: 0.0952\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1158 - val_loss: 0.1009\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1157 - val_loss: 0.0987\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1157 - val_loss: 0.0963\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1157 - val_loss: 0.0963\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1156 - val_loss: 0.0942\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1156 - val_loss: 0.0997\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1155 - val_loss: 0.0965\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1154 - val_loss: 0.0959\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1155 - val_loss: 0.0963\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1153 - val_loss: 0.0956\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1152 - val_loss: 0.0924\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1153 - val_loss: 0.0963\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1151 - val_loss: 0.0958\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1151 - val_loss: 0.0974\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1151 - val_loss: 0.0984\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1150 - val_loss: 0.0961\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 4\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 144us/sample - loss: 0.1794 - val_loss: 0.1210\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1394 - val_loss: 0.1077\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1298 - val_loss: 0.0981\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1261 - val_loss: 0.1005\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1239 - val_loss: 0.0945\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1225 - val_loss: 0.0991\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1214 - val_loss: 0.0987\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1208 - val_loss: 0.0953\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1203 - val_loss: 0.1035\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1199 - val_loss: 0.0980\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1196 - val_loss: 0.1024\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1191 - val_loss: 0.1039\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1188 - val_loss: 0.0984\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1188 - val_loss: 0.0963\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1187 - val_loss: 0.0970\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1186 - val_loss: 0.0968\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1184 - val_loss: 0.0987\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1181 - val_loss: 0.0984\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1180 - val_loss: 0.1009\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1181 - val_loss: 0.0978\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1177 - val_loss: 0.0990\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1177 - val_loss: 0.0949\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1175 - val_loss: 0.0974\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1175 - val_loss: 0.0952\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1174 - val_loss: 0.0961\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1173 - val_loss: 0.0972\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1172 - val_loss: 0.0927\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1172 - val_loss: 0.1020\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1171 - val_loss: 0.0999\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1170 - val_loss: 0.1011\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1169 - val_loss: 0.0956\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1167 - val_loss: 0.0985\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1166 - val_loss: 0.0966\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1166 - val_loss: 0.0947\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1165 - val_loss: 0.1003\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.0943\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.0968\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1162 - val_loss: 0.0999\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1160 - val_loss: 0.0933\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1159 - val_loss: 0.0943\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1158 - val_loss: 0.1008\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1156 - val_loss: 0.0984\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1154 - val_loss: 0.0925\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1155 - val_loss: 0.0943\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1154 - val_loss: 0.1048\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1152 - val_loss: 0.0958\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1151 - val_loss: 0.0989\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1149 - val_loss: 0.0946\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1146 - val_loss: 0.0944\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1145 - val_loss: 0.0969\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1145 - val_loss: 0.1003\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1142 - val_loss: 0.0957\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1140 - val_loss: 0.0934\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1141 - val_loss: 0.0946\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1138 - val_loss: 0.0927\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1135 - val_loss: 0.0931\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1136 - val_loss: 0.0913\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1133 - val_loss: 0.0945\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1130 - val_loss: 0.0933\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1128 - val_loss: 0.0901\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1127 - val_loss: 0.0916\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1125 - val_loss: 0.0945\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1121 - val_loss: 0.0963\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1119 - val_loss: 0.0926\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1116 - val_loss: 0.0917\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1116 - val_loss: 0.0932\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1111 - val_loss: 0.0915\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1108 - val_loss: 0.0902\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1105 - val_loss: 0.0849\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1103 - val_loss: 0.0880\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1101 - val_loss: 0.0904\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1099 - val_loss: 0.0845\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1097 - val_loss: 0.0831\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1094 - val_loss: 0.0867\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1093 - val_loss: 0.0875\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.1091 - val_loss: 0.0845\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1089 - val_loss: 0.0871\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1087 - val_loss: 0.0819\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1086 - val_loss: 0.0845\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1085 - val_loss: 0.0849\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1083 - val_loss: 0.0857\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.0869\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1079 - val_loss: 0.0823\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1078 - val_loss: 0.0790\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1077 - val_loss: 0.0900\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1076 - val_loss: 0.0821\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1073 - val_loss: 0.0813\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1073 - val_loss: 0.0830\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1071 - val_loss: 0.0804\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1070 - val_loss: 0.0852\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1069 - val_loss: 0.0833\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1068 - val_loss: 0.0825\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1066 - val_loss: 0.0788\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1063 - val_loss: 0.0789\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1062 - val_loss: 0.0772\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1062 - val_loss: 0.0792\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1059 - val_loss: 0.0808\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1058 - val_loss: 0.0809\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1058 - val_loss: 0.0792\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1056 - val_loss: 0.0774\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 8\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 146us/sample - loss: 0.1694 - val_loss: 0.1193\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1314 - val_loss: 0.1078\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1229 - val_loss: 0.0976\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1206 - val_loss: 0.0976\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1192 - val_loss: 0.0977\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1184 - val_loss: 0.1003\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1179 - val_loss: 0.1012\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1179 - val_loss: 0.0915\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1172 - val_loss: 0.1016\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1170 - val_loss: 0.0970\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1165 - val_loss: 0.1001\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1159 - val_loss: 0.1028\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1153 - val_loss: 0.0944\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1151 - val_loss: 0.0923\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1144 - val_loss: 0.0958\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1136 - val_loss: 0.0942\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1128 - val_loss: 0.0905\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1119 - val_loss: 0.0881\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1110 - val_loss: 0.0875\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1103 - val_loss: 0.0846\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1095 - val_loss: 0.0864\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1091 - val_loss: 0.0819\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1082 - val_loss: 0.0811\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1076 - val_loss: 0.0781\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1071 - val_loss: 0.0779\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1067 - val_loss: 0.0784\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1062 - val_loss: 0.0772\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1057 - val_loss: 0.0824\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1055 - val_loss: 0.0784\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1050 - val_loss: 0.0799\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1045 - val_loss: 0.0731\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1041 - val_loss: 0.0743\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1037 - val_loss: 0.0735\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1032 - val_loss: 0.0721\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0729\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1027 - val_loss: 0.0709\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1022 - val_loss: 0.0714\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1018 - val_loss: 0.0700\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1017 - val_loss: 0.0700\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1015 - val_loss: 0.0686\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1012 - val_loss: 0.0705\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1009 - val_loss: 0.0693\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1010 - val_loss: 0.0696\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1007 - val_loss: 0.0678\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1004 - val_loss: 0.0704\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.1003 - val_loss: 0.0685\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1002 - val_loss: 0.0701\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0998 - val_loss: 0.0666\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1000 - val_loss: 0.0671\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0996 - val_loss: 0.0691\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0998 - val_loss: 0.0666\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0995 - val_loss: 0.0664\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0993 - val_loss: 0.0654\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0993 - val_loss: 0.0694\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0992 - val_loss: 0.0687\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0990 - val_loss: 0.0652\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0992 - val_loss: 0.0667\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0664\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0989 - val_loss: 0.0686\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0987 - val_loss: 0.0663\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0987 - val_loss: 0.0672\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0988 - val_loss: 0.0673\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0984 - val_loss: 0.0669\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0984 - val_loss: 0.0660\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0982 - val_loss: 0.0662\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0983 - val_loss: 0.0656\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0981 - val_loss: 0.0676\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0981 - val_loss: 0.0656\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0979 - val_loss: 0.0654\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0980 - val_loss: 0.0644\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0667\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0667\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0652\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0975 - val_loss: 0.0655\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0975 - val_loss: 0.0662\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0975 - val_loss: 0.0663\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0973 - val_loss: 0.0680\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0973 - val_loss: 0.0659\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.0652\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0972 - val_loss: 0.0651\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0972 - val_loss: 0.0672\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0971 - val_loss: 0.0693\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0971 - val_loss: 0.0648\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0639\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0970 - val_loss: 0.0643\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0967 - val_loss: 0.0673\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0967 - val_loss: 0.0623\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0646\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0967 - val_loss: 0.0653\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0965 - val_loss: 0.0638\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0647\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0963 - val_loss: 0.0655\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0965 - val_loss: 0.0633\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0962 - val_loss: 0.0642\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0962 - val_loss: 0.0621\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0963 - val_loss: 0.0634\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0961 - val_loss: 0.0636\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0636\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0959 - val_loss: 0.0641\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0960 - val_loss: 0.0620\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 16\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 4s 137us/sample - loss: 0.1495 - val_loss: 0.1085\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1235 - val_loss: 0.1002\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1210 - val_loss: 0.1016\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1204 - val_loss: 0.1030\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1194 - val_loss: 0.1011\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1186 - val_loss: 0.1008\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1181 - val_loss: 0.1055\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1183 - val_loss: 0.0967\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1173 - val_loss: 0.1042\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1169 - val_loss: 0.0993\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1165 - val_loss: 0.1000\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1157 - val_loss: 0.0981\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1149 - val_loss: 0.0978\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1143 - val_loss: 0.0934\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1141 - val_loss: 0.0947\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1132 - val_loss: 0.0988\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1131 - val_loss: 0.0906\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1121 - val_loss: 0.0916\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1117 - val_loss: 0.0875\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1110 - val_loss: 0.0869\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1103 - val_loss: 0.0911\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1096 - val_loss: 0.0875\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.0831\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.0829\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1072 - val_loss: 0.0771\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1066 - val_loss: 0.0846\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1061 - val_loss: 0.0783\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1054 - val_loss: 0.0826\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1052 - val_loss: 0.0823\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.1047 - val_loss: 0.0789\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1042 - val_loss: 0.0776\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1039 - val_loss: 0.0777\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1033 - val_loss: 0.0739\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1030 - val_loss: 0.0743\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1028 - val_loss: 0.0747\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1027 - val_loss: 0.0753\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1022 - val_loss: 0.0760\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1019 - val_loss: 0.0732\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1019 - val_loss: 0.0744\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.1015 - val_loss: 0.0723\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1015 - val_loss: 0.0791\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1010 - val_loss: 0.0754\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1009 - val_loss: 0.0720\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1007 - val_loss: 0.0728\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1003 - val_loss: 0.0747\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1002 - val_loss: 0.0796\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1004 - val_loss: 0.0700\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0999 - val_loss: 0.0698\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0997 - val_loss: 0.0697\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0993 - val_loss: 0.0775\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0997 - val_loss: 0.0733\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0993 - val_loss: 0.0720\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0993 - val_loss: 0.0682\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0989 - val_loss: 0.0701\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0989 - val_loss: 0.0700\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0985 - val_loss: 0.0684\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0986 - val_loss: 0.0705\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0982 - val_loss: 0.0742\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0984 - val_loss: 0.0723\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0983 - val_loss: 0.0710\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0981 - val_loss: 0.0684\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0979 - val_loss: 0.0742\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0976 - val_loss: 0.0700\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0712\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0975 - val_loss: 0.0697\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0974 - val_loss: 0.0691\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0974 - val_loss: 0.0683\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0970 - val_loss: 0.0707\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0970 - val_loss: 0.0671\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0971 - val_loss: 0.0662\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0734\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0968 - val_loss: 0.0700\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0965 - val_loss: 0.0661\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0964 - val_loss: 0.0652\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0965 - val_loss: 0.0673\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0964 - val_loss: 0.0687\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0962 - val_loss: 0.0691\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0962 - val_loss: 0.0666\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0962 - val_loss: 0.0681\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0674\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0958 - val_loss: 0.0682\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0702\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0959 - val_loss: 0.0666\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0957 - val_loss: 0.0656\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0956 - val_loss: 0.0657\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0954 - val_loss: 0.0653\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0954 - val_loss: 0.0640\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 1s 46us/sample - loss: 0.0951 - val_loss: 0.0652\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 1s 44us/sample - loss: 0.0952 - val_loss: 0.0679\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0951 - val_loss: 0.0698\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.0951 - val_loss: 0.0648\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0951 - val_loss: 0.0639\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 48us/sample - loss: 0.0950 - val_loss: 0.0634\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0947 - val_loss: 0.0661\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0950 - val_loss: 0.0639\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0643\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0946 - val_loss: 0.0641\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0947 - val_loss: 0.0634\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0945 - val_loss: 0.0618\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0944 - val_loss: 0.0629\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 32\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 139us/sample - loss: 0.1485 - val_loss: 0.1040\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1218 - val_loss: 0.1056\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1202 - val_loss: 0.0984\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1201 - val_loss: 0.1036\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1194 - val_loss: 0.1039\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1188 - val_loss: 0.1000\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1182 - val_loss: 0.1022\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1187 - val_loss: 0.0929\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1176 - val_loss: 0.1046\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1169 - val_loss: 0.0987\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.1165 - val_loss: 0.0994\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1152 - val_loss: 0.0961\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1139 - val_loss: 0.0954\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1126 - val_loss: 0.0972\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1113 - val_loss: 0.0908\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1101 - val_loss: 0.0907\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1091 - val_loss: 0.0898\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1078 - val_loss: 0.0833\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1069 - val_loss: 0.0799\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1062 - val_loss: 0.0858\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1056 - val_loss: 0.0775\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1049 - val_loss: 0.0750\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1041 - val_loss: 0.0742\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1040 - val_loss: 0.0738\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1032 - val_loss: 0.0775\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1032 - val_loss: 0.0790\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1024 - val_loss: 0.0728\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1021 - val_loss: 0.0794\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1016 - val_loss: 0.0744\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1011 - val_loss: 0.0728\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1006 - val_loss: 0.0721\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1006 - val_loss: 0.0687\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1000 - val_loss: 0.0688\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0994 - val_loss: 0.0684\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0993 - val_loss: 0.0692\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0988 - val_loss: 0.0675\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0983 - val_loss: 0.0681\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0984 - val_loss: 0.0708\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0982 - val_loss: 0.0687\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0655\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0704\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0974 - val_loss: 0.0661\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0650\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0968 - val_loss: 0.0639\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0727\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0966 - val_loss: 0.0784\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0968 - val_loss: 0.0646\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0961 - val_loss: 0.0655\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0965 - val_loss: 0.0644\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0958 - val_loss: 0.0659\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0959 - val_loss: 0.0667\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0956 - val_loss: 0.0663\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0955 - val_loss: 0.0627\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0952 - val_loss: 0.0639\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0954 - val_loss: 0.0629\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0952 - val_loss: 0.0625\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.0951 - val_loss: 0.0657\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 61us/sample - loss: 0.0947 - val_loss: 0.0654\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0948 - val_loss: 0.0639\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.0693\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0945 - val_loss: 0.0628\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0942 - val_loss: 0.0638\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0941 - val_loss: 0.0609\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0942 - val_loss: 0.0611\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0938 - val_loss: 0.0619\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0938 - val_loss: 0.0629\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.0657\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0936 - val_loss: 0.0710\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0934 - val_loss: 0.0593\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0597\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0934 - val_loss: 0.0666\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0931 - val_loss: 0.0650\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0928 - val_loss: 0.0625\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0930 - val_loss: 0.0597\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0928 - val_loss: 0.0612\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0631\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0638\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0925 - val_loss: 0.0615\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0927 - val_loss: 0.0606\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0923 - val_loss: 0.0613\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0926 - val_loss: 0.0578\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0922 - val_loss: 0.0620\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0920 - val_loss: 0.0593\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0606\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0601\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0918 - val_loss: 0.0614\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0919 - val_loss: 0.0581\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0917 - val_loss: 0.0585\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0916 - val_loss: 0.0606\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0916 - val_loss: 0.0601\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0913 - val_loss: 0.0602\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0914 - val_loss: 0.0587\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0913 - val_loss: 0.0594\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0914 - val_loss: 0.0614\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0911 - val_loss: 0.0573\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0601\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0909 - val_loss: 0.0581\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0909 - val_loss: 0.0613\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0910 - val_loss: 0.0601\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0909 - val_loss: 0.0563\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 64\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 138us/sample - loss: 0.1415 - val_loss: 0.1212\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1219 - val_loss: 0.0999\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1208 - val_loss: 0.1059\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1200 - val_loss: 0.1043\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1192 - val_loss: 0.1112\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1193 - val_loss: 0.1000\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1190 - val_loss: 0.1019\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1185 - val_loss: 0.0883\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1184 - val_loss: 0.1069\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1174 - val_loss: 0.1027\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.1165 - val_loss: 0.1007\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1151 - val_loss: 0.0939\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1134 - val_loss: 0.0959\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1110 - val_loss: 0.0883\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1084 - val_loss: 0.0834\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1061 - val_loss: 0.0923\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0794\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1046 - val_loss: 0.0811\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0777\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1029 - val_loss: 0.0851\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1029 - val_loss: 0.0731\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1018 - val_loss: 0.0718\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1014 - val_loss: 0.0684\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1007 - val_loss: 0.0680\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0672\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0996 - val_loss: 0.0724\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0990 - val_loss: 0.0672\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0730\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0983 - val_loss: 0.0685\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0978 - val_loss: 0.0699\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0977 - val_loss: 0.0672\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0975 - val_loss: 0.0671\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0973 - val_loss: 0.0648\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 47us/sample - loss: 0.0967 - val_loss: 0.0651\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0966 - val_loss: 0.0658\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0963 - val_loss: 0.0643\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0963 - val_loss: 0.0644\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0643\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0653\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0953 - val_loss: 0.0665\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0954 - val_loss: 0.0658\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0952 - val_loss: 0.0637\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0952 - val_loss: 0.0621\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0948 - val_loss: 0.0612\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0944 - val_loss: 0.0650\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0944 - val_loss: 0.0609\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0944 - val_loss: 0.0614\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0938 - val_loss: 0.0623\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0941 - val_loss: 0.0625\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.0620\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0935 - val_loss: 0.0643\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0934 - val_loss: 0.0617\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0607\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0930 - val_loss: 0.0601\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0928 - val_loss: 0.0604\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0926 - val_loss: 0.0636\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0928 - val_loss: 0.0625\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0627\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0600\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0922 - val_loss: 0.0597\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0920 - val_loss: 0.0596\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0918 - val_loss: 0.0587\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0916 - val_loss: 0.0589\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0916 - val_loss: 0.0596\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0614\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0912 - val_loss: 0.0587\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0912 - val_loss: 0.0591\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0912 - val_loss: 0.0595\n",
      "Epoch 69/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0908 - val_loss: 0.0573\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0582\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0905 - val_loss: 0.0585\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0905 - val_loss: 0.0588\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0903 - val_loss: 0.0581\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0904 - val_loss: 0.0595\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0901 - val_loss: 0.0584\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0899 - val_loss: 0.0584\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0898 - val_loss: 0.0577\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0898 - val_loss: 0.0599\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0897 - val_loss: 0.0574\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0897 - val_loss: 0.0566\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0895 - val_loss: 0.0567\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0559\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.0578\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0893 - val_loss: 0.0583\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0892 - val_loss: 0.0583\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0890 - val_loss: 0.0591\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0888 - val_loss: 0.0566\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0886 - val_loss: 0.0563\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0887 - val_loss: 0.0577\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0885 - val_loss: 0.0575\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0884 - val_loss: 0.0565\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0883 - val_loss: 0.0560\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0884 - val_loss: 0.0570\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0883 - val_loss: 0.0580\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0880 - val_loss: 0.0575\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0883 - val_loss: 0.0583\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0879 - val_loss: 0.0583\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0876 - val_loss: 0.0588\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0876 - val_loss: 0.0593\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0877 - val_loss: 0.0551\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 7, units: 128\n",
      "Train on 32720 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32720/32720 [==============================] - 5s 141us/sample - loss: 0.1379 - val_loss: 0.1118\n",
      "Epoch 2/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1225 - val_loss: 0.0990\n",
      "Epoch 3/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1220 - val_loss: 0.1083\n",
      "Epoch 4/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1204 - val_loss: 0.1042\n",
      "Epoch 5/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1198 - val_loss: 0.1089\n",
      "Epoch 6/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1195 - val_loss: 0.1079\n",
      "Epoch 7/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1193 - val_loss: 0.1005\n",
      "Epoch 8/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.1170 - val_loss: 0.0885\n",
      "Epoch 9/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1160 - val_loss: 0.0976\n",
      "Epoch 10/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1142 - val_loss: 0.0938\n",
      "Epoch 11/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1117 - val_loss: 0.0846\n",
      "Epoch 12/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.1095 - val_loss: 0.0868\n",
      "Epoch 13/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1076 - val_loss: 0.0784\n",
      "Epoch 14/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.1059 - val_loss: 0.0777\n",
      "Epoch 15/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.1045 - val_loss: 0.0714\n",
      "Epoch 16/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1031 - val_loss: 0.0835\n",
      "Epoch 17/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1023 - val_loss: 0.0716\n",
      "Epoch 18/100\n",
      "32720/32720 [==============================] - 2s 60us/sample - loss: 0.1019 - val_loss: 0.0716\n",
      "Epoch 19/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.1010 - val_loss: 0.0729\n",
      "Epoch 20/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0723\n",
      "Epoch 21/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0997 - val_loss: 0.0690\n",
      "Epoch 22/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0988 - val_loss: 0.0674\n",
      "Epoch 23/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0981 - val_loss: 0.0631\n",
      "Epoch 24/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0979 - val_loss: 0.0634\n",
      "Epoch 25/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0972 - val_loss: 0.0699\n",
      "Epoch 26/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.0678\n",
      "Epoch 27/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0965 - val_loss: 0.0632\n",
      "Epoch 28/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0965 - val_loss: 0.0678\n",
      "Epoch 29/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0961 - val_loss: 0.0648\n",
      "Epoch 30/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0952 - val_loss: 0.0635\n",
      "Epoch 31/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0948 - val_loss: 0.0631\n",
      "Epoch 32/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0950 - val_loss: 0.0652\n",
      "Epoch 33/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0945 - val_loss: 0.0614\n",
      "Epoch 34/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0942 - val_loss: 0.0614\n",
      "Epoch 35/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0943 - val_loss: 0.0614\n",
      "Epoch 36/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0585\n",
      "Epoch 37/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0934 - val_loss: 0.0592\n",
      "Epoch 38/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0932 - val_loss: 0.0608\n",
      "Epoch 39/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0930 - val_loss: 0.0595\n",
      "Epoch 40/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0601\n",
      "Epoch 41/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0926 - val_loss: 0.0577\n",
      "Epoch 42/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0925 - val_loss: 0.0574\n",
      "Epoch 43/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0921 - val_loss: 0.0648\n",
      "Epoch 44/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0919 - val_loss: 0.0580\n",
      "Epoch 45/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0918 - val_loss: 0.0597\n",
      "Epoch 46/100\n",
      "32720/32720 [==============================] - 2s 52us/sample - loss: 0.0916 - val_loss: 0.0572\n",
      "Epoch 47/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0551\n",
      "Epoch 48/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0909 - val_loss: 0.0579\n",
      "Epoch 49/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0558\n",
      "Epoch 50/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0905 - val_loss: 0.0555\n",
      "Epoch 51/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0905 - val_loss: 0.0568\n",
      "Epoch 52/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0904 - val_loss: 0.0560\n",
      "Epoch 53/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.0562\n",
      "Epoch 54/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0898 - val_loss: 0.0570\n",
      "Epoch 55/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0901 - val_loss: 0.0544\n",
      "Epoch 56/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0896 - val_loss: 0.0555\n",
      "Epoch 57/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.0566\n",
      "Epoch 58/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0890 - val_loss: 0.0573\n",
      "Epoch 59/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0891 - val_loss: 0.0574\n",
      "Epoch 60/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0891 - val_loss: 0.0560\n",
      "Epoch 61/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0889 - val_loss: 0.0561\n",
      "Epoch 62/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0888 - val_loss: 0.0537\n",
      "Epoch 63/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0884 - val_loss: 0.0542\n",
      "Epoch 64/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0885 - val_loss: 0.0552\n",
      "Epoch 65/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0881 - val_loss: 0.0563\n",
      "Epoch 66/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0878 - val_loss: 0.0526\n",
      "Epoch 67/100\n",
      "32720/32720 [==============================] - 2s 48us/sample - loss: 0.0876 - val_loss: 0.0576\n",
      "Epoch 68/100\n",
      "32720/32720 [==============================] - 2s 49us/sample - loss: 0.0879 - val_loss: 0.0544\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0874 - val_loss: 0.0520\n",
      "Epoch 70/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0874 - val_loss: 0.0526\n",
      "Epoch 71/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0872 - val_loss: 0.0590\n",
      "Epoch 72/100\n",
      "32720/32720 [==============================] - 2s 58us/sample - loss: 0.0870 - val_loss: 0.0555\n",
      "Epoch 73/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0870 - val_loss: 0.0534\n",
      "Epoch 74/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0870 - val_loss: 0.0544\n",
      "Epoch 75/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0868 - val_loss: 0.0524\n",
      "Epoch 76/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0865 - val_loss: 0.0553\n",
      "Epoch 77/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0864 - val_loss: 0.0519\n",
      "Epoch 78/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0548\n",
      "Epoch 79/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0861 - val_loss: 0.0527\n",
      "Epoch 80/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0864 - val_loss: 0.0523\n",
      "Epoch 81/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0860 - val_loss: 0.0523\n",
      "Epoch 82/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0857 - val_loss: 0.0527\n",
      "Epoch 83/100\n",
      "32720/32720 [==============================] - 2s 53us/sample - loss: 0.0857 - val_loss: 0.0526\n",
      "Epoch 84/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0855 - val_loss: 0.0527\n",
      "Epoch 85/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0858 - val_loss: 0.0531\n",
      "Epoch 86/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0851 - val_loss: 0.0552\n",
      "Epoch 87/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0855 - val_loss: 0.0527\n",
      "Epoch 88/100\n",
      "32720/32720 [==============================] - 2s 55us/sample - loss: 0.0849 - val_loss: 0.0543\n",
      "Epoch 89/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0850 - val_loss: 0.0523\n",
      "Epoch 90/100\n",
      "32720/32720 [==============================] - 2s 51us/sample - loss: 0.0846 - val_loss: 0.0546\n",
      "Epoch 91/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0846 - val_loss: 0.0535\n",
      "Epoch 92/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0844 - val_loss: 0.0524\n",
      "Epoch 93/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0843 - val_loss: 0.0530\n",
      "Epoch 94/100\n",
      "32720/32720 [==============================] - 2s 59us/sample - loss: 0.0842 - val_loss: 0.0520\n",
      "Epoch 95/100\n",
      "32720/32720 [==============================] - 2s 57us/sample - loss: 0.0837 - val_loss: 0.0531\n",
      "Epoch 96/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0838 - val_loss: 0.0548\n",
      "Epoch 97/100\n",
      "32720/32720 [==============================] - 2s 50us/sample - loss: 0.0837 - val_loss: 0.0551\n",
      "Epoch 98/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0835 - val_loss: 0.0536\n",
      "Epoch 99/100\n",
      "32720/32720 [==============================] - 2s 54us/sample - loss: 0.0833 - val_loss: 0.0544\n",
      "Epoch 100/100\n",
      "32720/32720 [==============================] - 2s 56us/sample - loss: 0.0832 - val_loss: 0.0520\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 2\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 143us/sample - loss: 0.1846 - val_loss: 0.1459\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1544 - val_loss: 0.1331\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1453 - val_loss: 0.1234\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1384 - val_loss: 0.1074\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1318 - val_loss: 0.1003\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1273 - val_loss: 0.0982\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1244 - val_loss: 0.1010\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1225 - val_loss: 0.1032\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1215 - val_loss: 0.1003\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1202 - val_loss: 0.0988\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1194 - val_loss: 0.0980\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1188 - val_loss: 0.1015\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1185 - val_loss: 0.0953\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1179 - val_loss: 0.0974\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1174 - val_loss: 0.1006\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1170 - val_loss: 0.0988\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 46us/sample - loss: 0.1167 - val_loss: 0.1033\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1164 - val_loss: 0.0987\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.1161 - val_loss: 0.1011\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1156 - val_loss: 0.0962\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1154 - val_loss: 0.0980\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1150 - val_loss: 0.0969\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1147 - val_loss: 0.0987\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1144 - val_loss: 0.0997\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1141 - val_loss: 0.1005\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1139 - val_loss: 0.0979\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1136 - val_loss: 0.1009\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.1135 - val_loss: 0.0977\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1131 - val_loss: 0.0977\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1128 - val_loss: 0.0978\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1127 - val_loss: 0.0962\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1125 - val_loss: 0.0968\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1122 - val_loss: 0.0966\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1122 - val_loss: 0.0969\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1119 - val_loss: 0.0980\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1116 - val_loss: 0.0984\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1116 - val_loss: 0.0970\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1112 - val_loss: 0.0969\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1112 - val_loss: 0.0966\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1110 - val_loss: 0.0950\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1108 - val_loss: 0.0934\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1107 - val_loss: 0.0958\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1106 - val_loss: 0.0985\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1104 - val_loss: 0.1004\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1102 - val_loss: 0.1004\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1101 - val_loss: 0.0958\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1100 - val_loss: 0.0966\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1097 - val_loss: 0.0963\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1097 - val_loss: 0.0935\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1096 - val_loss: 0.0982\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1094 - val_loss: 0.0958\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1092 - val_loss: 0.0942\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1090 - val_loss: 0.0950\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1090 - val_loss: 0.0933\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1087 - val_loss: 0.0952\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1087 - val_loss: 0.0959\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1086 - val_loss: 0.0959\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1083 - val_loss: 0.0930\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.0951\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1080 - val_loss: 0.0945\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1081 - val_loss: 0.0927\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1079 - val_loss: 0.0938\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1080 - val_loss: 0.0912\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1076 - val_loss: 0.0939\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1077 - val_loss: 0.0949\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1075 - val_loss: 0.0915\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1074 - val_loss: 0.0891\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1075 - val_loss: 0.0913\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1072 - val_loss: 0.0909\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1072 - val_loss: 0.0909\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1074 - val_loss: 0.0897\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.0912\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.0894\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1068 - val_loss: 0.0923\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1068 - val_loss: 0.0920\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.0887\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1067 - val_loss: 0.0914\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1066 - val_loss: 0.0890\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1066 - val_loss: 0.0918\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1064 - val_loss: 0.0899\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1062 - val_loss: 0.0903\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1062 - val_loss: 0.0889\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1063 - val_loss: 0.0924\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1061 - val_loss: 0.0870\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1060 - val_loss: 0.0875\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 63us/sample - loss: 0.1061 - val_loss: 0.0881\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1058 - val_loss: 0.0892\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1058 - val_loss: 0.0855\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1057 - val_loss: 0.0877\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1055 - val_loss: 0.0870\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1057 - val_loss: 0.0872\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1055 - val_loss: 0.0869\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1055 - val_loss: 0.0895\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1053 - val_loss: 0.0886\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1053 - val_loss: 0.0896\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1053 - val_loss: 0.0917\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1054 - val_loss: 0.0873\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1051 - val_loss: 0.0885\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.1051 - val_loss: 0.0879\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.1052 - val_loss: 0.0849\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 4\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 150us/sample - loss: 0.1971 - val_loss: 0.1374\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1538 - val_loss: 0.1266\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1414 - val_loss: 0.1178\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1347 - val_loss: 0.1062\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1294 - val_loss: 0.1014\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1263 - val_loss: 0.0982\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1241 - val_loss: 0.1051\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1223 - val_loss: 0.1068\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1214 - val_loss: 0.1039\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1201 - val_loss: 0.0979\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1190 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1183 - val_loss: 0.0978\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1179 - val_loss: 0.0911\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1169 - val_loss: 0.0992\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1161 - val_loss: 0.0987\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1154 - val_loss: 0.0932\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1148 - val_loss: 0.0976\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1140 - val_loss: 0.0908\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1135 - val_loss: 0.0934\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1129 - val_loss: 0.0945\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1123 - val_loss: 0.0896\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1117 - val_loss: 0.0941\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1113 - val_loss: 0.0919\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1111 - val_loss: 0.0968\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1105 - val_loss: 0.0904\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.1101 - val_loss: 0.0906\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1097 - val_loss: 0.0918\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1095 - val_loss: 0.0923\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1091 - val_loss: 0.0893\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.0886\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.0899\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1078 - val_loss: 0.0870\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1073 - val_loss: 0.0888\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1070 - val_loss: 0.0866\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1063 - val_loss: 0.0881\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1058 - val_loss: 0.0872\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1056 - val_loss: 0.0856\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1051 - val_loss: 0.0824\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0811\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1045 - val_loss: 0.0810\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1043 - val_loss: 0.0794\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1043 - val_loss: 0.0819\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1039 - val_loss: 0.0821\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1036 - val_loss: 0.0836\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1033 - val_loss: 0.0842\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1032 - val_loss: 0.0859\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1030 - val_loss: 0.0803\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0804\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1027 - val_loss: 0.0771\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1025 - val_loss: 0.0826\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1024 - val_loss: 0.0773\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1022 - val_loss: 0.0768\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1022 - val_loss: 0.0830\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1020 - val_loss: 0.0757\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1019 - val_loss: 0.0778\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1019 - val_loss: 0.0811\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1017 - val_loss: 0.0777\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0732\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1016 - val_loss: 0.0792\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1013 - val_loss: 0.0763\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1012 - val_loss: 0.0787\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1013 - val_loss: 0.0790\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1011 - val_loss: 0.0743\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1010 - val_loss: 0.0751\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1009 - val_loss: 0.0779\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1008 - val_loss: 0.0747\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1009 - val_loss: 0.0731\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1006 - val_loss: 0.0765\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1006 - val_loss: 0.0742\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1005 - val_loss: 0.0760\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1005 - val_loss: 0.0733\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1005 - val_loss: 0.0746\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1003 - val_loss: 0.0725\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1002 - val_loss: 0.0760\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1002 - val_loss: 0.0759\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1003 - val_loss: 0.0745\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1002 - val_loss: 0.0759\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1000 - val_loss: 0.0730\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1002 - val_loss: 0.0739\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0999 - val_loss: 0.0716\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0998 - val_loss: 0.0720\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0997 - val_loss: 0.0744\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0997 - val_loss: 0.0730\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0996 - val_loss: 0.0726\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0719\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0731\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0994 - val_loss: 0.0738\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0994 - val_loss: 0.0703\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0731\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0992 - val_loss: 0.0707\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0715\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0990 - val_loss: 0.0743\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0993 - val_loss: 0.0717\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0991 - val_loss: 0.0728\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0989 - val_loss: 0.0724\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0990 - val_loss: 0.0724\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0991 - val_loss: 0.0712\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0716\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0722\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0989 - val_loss: 0.0703\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 8\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 143us/sample - loss: 0.1627 - val_loss: 0.1125\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1271 - val_loss: 0.0965\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1214 - val_loss: 0.1020\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1180 - val_loss: 0.0915\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1164 - val_loss: 0.0929\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1152 - val_loss: 0.0924\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1140 - val_loss: 0.0965\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1132 - val_loss: 0.0978\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1120 - val_loss: 0.0968\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1110 - val_loss: 0.0890\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1100 - val_loss: 0.0891\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1092 - val_loss: 0.0883\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1085 - val_loss: 0.0853\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1078 - val_loss: 0.0842\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1071 - val_loss: 0.0857\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1065 - val_loss: 0.0829\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1058 - val_loss: 0.0829\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1054 - val_loss: 0.0789\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0830\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1047 - val_loss: 0.0785\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1043 - val_loss: 0.0775\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1039 - val_loss: 0.0808\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1036 - val_loss: 0.0780\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0766\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1031 - val_loss: 0.0783\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1027 - val_loss: 0.0779\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1025 - val_loss: 0.0813\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1024 - val_loss: 0.0815\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 47us/sample - loss: 0.1021 - val_loss: 0.0756\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0745\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.1014 - val_loss: 0.0726\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1015 - val_loss: 0.0713\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1011 - val_loss: 0.0744\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1013 - val_loss: 0.0752\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1005 - val_loss: 0.0769\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1003 - val_loss: 0.0711\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1001 - val_loss: 0.0718\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1000 - val_loss: 0.0734\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0998 - val_loss: 0.0703\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0992 - val_loss: 0.0696\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0990 - val_loss: 0.0759\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0989 - val_loss: 0.0755\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0986 - val_loss: 0.0737\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0984 - val_loss: 0.0685\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0981 - val_loss: 0.0717\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0977 - val_loss: 0.0708\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0979 - val_loss: 0.0752\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0979 - val_loss: 0.0703\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0972 - val_loss: 0.0688\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0973 - val_loss: 0.0705\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0969 - val_loss: 0.0656\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0966 - val_loss: 0.0665\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0968 - val_loss: 0.0673\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0962 - val_loss: 0.0646\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0962 - val_loss: 0.0694\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0960 - val_loss: 0.0696\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0958 - val_loss: 0.0658\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0954 - val_loss: 0.0622\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0952 - val_loss: 0.0653\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0952 - val_loss: 0.0663\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0952 - val_loss: 0.0649\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0949 - val_loss: 0.0732\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0950 - val_loss: 0.0654\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0946 - val_loss: 0.0649\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0946 - val_loss: 0.0622\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0944 - val_loss: 0.0629\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0944 - val_loss: 0.0608\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0943 - val_loss: 0.0672\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0946 - val_loss: 0.0625\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0942 - val_loss: 0.0626\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0941 - val_loss: 0.0611\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0942 - val_loss: 0.0640\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0615\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0938 - val_loss: 0.0621\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0937 - val_loss: 0.0600\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0659\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0936 - val_loss: 0.0628\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0937 - val_loss: 0.0606\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0935 - val_loss: 0.0607\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0932 - val_loss: 0.0603\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0931 - val_loss: 0.0599\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0621\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0931 - val_loss: 0.0609\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0932 - val_loss: 0.0590\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0931 - val_loss: 0.0595\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0929 - val_loss: 0.0594\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0928 - val_loss: 0.0594\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0928 - val_loss: 0.0584\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0928 - val_loss: 0.0589\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0926 - val_loss: 0.0593\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0927 - val_loss: 0.0598\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0924 - val_loss: 0.0607\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0620\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0595\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0923 - val_loss: 0.0587\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0596\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0921 - val_loss: 0.0639\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0923 - val_loss: 0.0603\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0921 - val_loss: 0.0585\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0920 - val_loss: 0.0581\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 16\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 152us/sample - loss: 0.1537 - val_loss: 0.1107\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1221 - val_loss: 0.0922\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1186 - val_loss: 0.1084\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1169 - val_loss: 0.0927\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1158 - val_loss: 0.0921\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1148 - val_loss: 0.0933\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1138 - val_loss: 0.0962\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1130 - val_loss: 0.0952\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1121 - val_loss: 0.0932\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1116 - val_loss: 0.0925\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1104 - val_loss: 0.0924\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1094 - val_loss: 0.0875\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1092 - val_loss: 0.0866\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1077 - val_loss: 0.0863\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1066 - val_loss: 0.0802\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1055 - val_loss: 0.0823\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1047 - val_loss: 0.0808\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1041 - val_loss: 0.0807\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1036 - val_loss: 0.0831\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1031 - val_loss: 0.0799\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1025 - val_loss: 0.0730\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1021 - val_loss: 0.0779\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1015 - val_loss: 0.0753\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1010 - val_loss: 0.0788\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1006 - val_loss: 0.0752\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1005 - val_loss: 0.0788\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0998 - val_loss: 0.0773\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0999 - val_loss: 0.0787\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0991 - val_loss: 0.0680\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0991 - val_loss: 0.0694\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0984 - val_loss: 0.0691\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0982 - val_loss: 0.0682\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0979 - val_loss: 0.0692\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0979 - val_loss: 0.0667\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0971 - val_loss: 0.0707\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0969 - val_loss: 0.0693\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.0968 - val_loss: 0.0660\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.0965 - val_loss: 0.0682\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0963 - val_loss: 0.0662\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0959 - val_loss: 0.0647\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 1s 44us/sample - loss: 0.0956 - val_loss: 0.0685\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 1s 45us/sample - loss: 0.0956 - val_loss: 0.0716\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0950 - val_loss: 0.0698\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0949 - val_loss: 0.0651\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0634\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0942 - val_loss: 0.0676\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0943 - val_loss: 0.0725\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0943 - val_loss: 0.0668\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0936 - val_loss: 0.0660\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0936 - val_loss: 0.0650\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0934 - val_loss: 0.0654\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0624\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0931 - val_loss: 0.0639\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0632\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0929 - val_loss: 0.0654\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0928 - val_loss: 0.0639\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0925 - val_loss: 0.0646\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0923 - val_loss: 0.0613\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0918 - val_loss: 0.0634\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0919 - val_loss: 0.0640\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0919 - val_loss: 0.0635\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0917 - val_loss: 0.0700\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0915 - val_loss: 0.0614\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0912 - val_loss: 0.0645\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0591\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0913 - val_loss: 0.0604\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0600\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0907 - val_loss: 0.0610\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0612\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0906 - val_loss: 0.0669\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0905 - val_loss: 0.0591\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0607\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0904 - val_loss: 0.0606\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0903 - val_loss: 0.0614\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0904 - val_loss: 0.0615\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0903 - val_loss: 0.0595\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0902 - val_loss: 0.0588\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0900 - val_loss: 0.0580\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0897 - val_loss: 0.0578\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0896 - val_loss: 0.0602\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0602\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0896 - val_loss: 0.0583\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0896 - val_loss: 0.0578\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0895 - val_loss: 0.0571\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0895 - val_loss: 0.0582\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0894 - val_loss: 0.0584\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0892 - val_loss: 0.0576\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0893 - val_loss: 0.0572\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0894 - val_loss: 0.0581\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0891 - val_loss: 0.0585\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0892 - val_loss: 0.0573\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0890 - val_loss: 0.0573\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0888 - val_loss: 0.0575\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0887 - val_loss: 0.0568\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0886 - val_loss: 0.0596\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0886 - val_loss: 0.0576\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0887 - val_loss: 0.0627\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0887 - val_loss: 0.0581\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0885 - val_loss: 0.0569\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0884 - val_loss: 0.0566\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 32\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 151us/sample - loss: 0.1408 - val_loss: 0.1005\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1174 - val_loss: 0.1017\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1159 - val_loss: 0.1112\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1153 - val_loss: 0.0914\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1146 - val_loss: 0.0954\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1135 - val_loss: 0.0936\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1130 - val_loss: 0.0927\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1123 - val_loss: 0.1012\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.1118 - val_loss: 0.0938\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1114 - val_loss: 0.0880\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1108 - val_loss: 0.0957\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1100 - val_loss: 0.0899\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1110 - val_loss: 0.0878\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1092 - val_loss: 0.0870\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1081 - val_loss: 0.0895\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1073 - val_loss: 0.0868\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1061 - val_loss: 0.0863\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1059 - val_loss: 0.0832\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1049 - val_loss: 0.0842\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1039 - val_loss: 0.0762\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1030 - val_loss: 0.0756\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1024 - val_loss: 0.0768\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1012 - val_loss: 0.0794\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0827\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0997 - val_loss: 0.0753\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0987 - val_loss: 0.0677\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0982 - val_loss: 0.0763\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0985 - val_loss: 0.0774\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0974 - val_loss: 0.0677\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0969 - val_loss: 0.0654\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0971 - val_loss: 0.0672\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0966 - val_loss: 0.0666\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0960 - val_loss: 0.0672\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0655\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0954 - val_loss: 0.0653\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0949 - val_loss: 0.0641\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0948 - val_loss: 0.0668\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0949 - val_loss: 0.0620\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0941 - val_loss: 0.0640\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0941 - val_loss: 0.0619\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0934 - val_loss: 0.0634\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0935 - val_loss: 0.0662\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0930 - val_loss: 0.0645\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0926 - val_loss: 0.0630\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0928 - val_loss: 0.0615\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0921 - val_loss: 0.0613\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0922 - val_loss: 0.0681\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0921 - val_loss: 0.0637\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0915 - val_loss: 0.0609\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0914 - val_loss: 0.0592\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0914 - val_loss: 0.0616\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0596\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0910 - val_loss: 0.0583\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0906 - val_loss: 0.0607\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0912 - val_loss: 0.0647\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0905 - val_loss: 0.0570\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0904 - val_loss: 0.0588\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0903 - val_loss: 0.0593\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0901 - val_loss: 0.0618\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0899 - val_loss: 0.0590\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0898 - val_loss: 0.0587\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0898 - val_loss: 0.0677\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0899 - val_loss: 0.0593\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0894 - val_loss: 0.0595\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.0569\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0897 - val_loss: 0.0574\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.0891 - val_loss: 0.0588\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0890 - val_loss: 0.0578\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0887 - val_loss: 0.0616\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0889 - val_loss: 0.0609\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0886 - val_loss: 0.0566\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0887 - val_loss: 0.0582\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0886 - val_loss: 0.0556\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0883 - val_loss: 0.0631\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0885 - val_loss: 0.0626\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0885 - val_loss: 0.0573\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0886 - val_loss: 0.0540\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0879 - val_loss: 0.0552\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0878 - val_loss: 0.0555\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0876 - val_loss: 0.0550\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0874 - val_loss: 0.0609\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0878 - val_loss: 0.0551\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0877 - val_loss: 0.0549\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0875 - val_loss: 0.0563\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0876 - val_loss: 0.0530\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0876 - val_loss: 0.0555\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0871 - val_loss: 0.0556\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0868 - val_loss: 0.0537\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0872 - val_loss: 0.0532\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0869 - val_loss: 0.0543\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0870 - val_loss: 0.0544\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0869 - val_loss: 0.0527\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0866 - val_loss: 0.0553\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0865 - val_loss: 0.0566\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0866 - val_loss: 0.0560\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0864 - val_loss: 0.0547\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0863 - val_loss: 0.0548\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0868 - val_loss: 0.0543\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0864 - val_loss: 0.0541\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0862 - val_loss: 0.0542\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 64\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 151us/sample - loss: 0.1374 - val_loss: 0.0963\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.1172 - val_loss: 0.0988\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.1158 - val_loss: 0.1065\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1148 - val_loss: 0.0883\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1145 - val_loss: 0.0928\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1135 - val_loss: 0.0914\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1121 - val_loss: 0.0925\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1112 - val_loss: 0.0962\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1103 - val_loss: 0.0868\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1093 - val_loss: 0.0839\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1084 - val_loss: 0.0981\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1073 - val_loss: 0.0854\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1070 - val_loss: 0.0848\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1050 - val_loss: 0.0818\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.1038 - val_loss: 0.0883\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1028 - val_loss: 0.0740\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.1009 - val_loss: 0.0791\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1010 - val_loss: 0.0728\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0995 - val_loss: 0.0788\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0761\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0981 - val_loss: 0.0674\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0977 - val_loss: 0.0671\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0971 - val_loss: 0.0748\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0966 - val_loss: 0.0740\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0961 - val_loss: 0.0684\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0621\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0949 - val_loss: 0.0676\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0951 - val_loss: 0.0723\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0944 - val_loss: 0.0678\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0942 - val_loss: 0.0605\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0932 - val_loss: 0.0722\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0934 - val_loss: 0.0659\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0643\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0925 - val_loss: 0.0601\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0923 - val_loss: 0.0667\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0921 - val_loss: 0.0614\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0918 - val_loss: 0.0593\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0919 - val_loss: 0.0588\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0914 - val_loss: 0.0602\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0911 - val_loss: 0.0593\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0910 - val_loss: 0.0605\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0613\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0906 - val_loss: 0.0622\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0902 - val_loss: 0.0574\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0903 - val_loss: 0.0595\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.0575\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0899 - val_loss: 0.0605\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0899 - val_loss: 0.0601\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0894 - val_loss: 0.0623\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0895 - val_loss: 0.0576\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0891 - val_loss: 0.0563\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0892 - val_loss: 0.0608\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0888 - val_loss: 0.0565\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0886 - val_loss: 0.0570\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0888 - val_loss: 0.0567\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0885 - val_loss: 0.0561\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0884 - val_loss: 0.0567\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0884 - val_loss: 0.0545\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0877 - val_loss: 0.0552\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0576\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0877 - val_loss: 0.0567\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0877 - val_loss: 0.0612\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0876 - val_loss: 0.0583\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0871 - val_loss: 0.0569\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 47us/sample - loss: 0.0869 - val_loss: 0.0570\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 47us/sample - loss: 0.0871 - val_loss: 0.0539\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0864 - val_loss: 0.0574\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0867 - val_loss: 0.0605\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0867 - val_loss: 0.0586\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0584\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0861 - val_loss: 0.0549\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0858 - val_loss: 0.0590\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0858 - val_loss: 0.0581\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0858 - val_loss: 0.0628\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0857 - val_loss: 0.0572\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0858 - val_loss: 0.0579\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0853 - val_loss: 0.0532\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0851 - val_loss: 0.0523\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0852 - val_loss: 0.0549\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.0848 - val_loss: 0.0549\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0848 - val_loss: 0.0566\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0849 - val_loss: 0.0553\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0845 - val_loss: 0.0543\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0845 - val_loss: 0.0573\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0847 - val_loss: 0.0534\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0845 - val_loss: 0.0586\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0840 - val_loss: 0.0550\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0839 - val_loss: 0.0589\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0842 - val_loss: 0.0528\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0837 - val_loss: 0.0518\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0838 - val_loss: 0.0530\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0835 - val_loss: 0.0533\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0836 - val_loss: 0.0532\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0831 - val_loss: 0.0548\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0832 - val_loss: 0.0549\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0830 - val_loss: 0.0546\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0828 - val_loss: 0.0530\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0829 - val_loss: 0.0556\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0830 - val_loss: 0.0538\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0826 - val_loss: 0.0535\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 0, lag: 14, units: 128\n",
      "Train on 32580 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "32580/32580 [==============================] - 5s 142us/sample - loss: 0.1340 - val_loss: 0.0927\n",
      "Epoch 2/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.1181 - val_loss: 0.0967\n",
      "Epoch 3/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1170 - val_loss: 0.1087\n",
      "Epoch 4/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1163 - val_loss: 0.0880\n",
      "Epoch 5/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1160 - val_loss: 0.0937\n",
      "Epoch 6/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.1144 - val_loss: 0.1000\n",
      "Epoch 7/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1126 - val_loss: 0.0925\n",
      "Epoch 8/100\n",
      "32580/32580 [==============================] - 2s 61us/sample - loss: 0.1106 - val_loss: 0.0952\n",
      "Epoch 9/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1084 - val_loss: 0.0821\n",
      "Epoch 10/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.1072 - val_loss: 0.0806\n",
      "Epoch 11/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1053 - val_loss: 0.0835\n",
      "Epoch 12/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.1035 - val_loss: 0.0755\n",
      "Epoch 13/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.1017 - val_loss: 0.0802\n",
      "Epoch 14/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0732\n",
      "Epoch 15/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0995 - val_loss: 0.0760\n",
      "Epoch 16/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0650\n",
      "Epoch 17/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0964 - val_loss: 0.0793\n",
      "Epoch 18/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0957 - val_loss: 0.0650\n",
      "Epoch 19/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0951 - val_loss: 0.0669\n",
      "Epoch 20/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0950 - val_loss: 0.0615\n",
      "Epoch 21/100\n",
      "32580/32580 [==============================] - 2s 49us/sample - loss: 0.0944 - val_loss: 0.0610\n",
      "Epoch 22/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0935 - val_loss: 0.0633\n",
      "Epoch 23/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0700\n",
      "Epoch 24/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0933 - val_loss: 0.0640\n",
      "Epoch 25/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0598\n",
      "Epoch 26/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0925 - val_loss: 0.0580\n",
      "Epoch 27/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0921 - val_loss: 0.0646\n",
      "Epoch 28/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0919 - val_loss: 0.0649\n",
      "Epoch 29/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0915 - val_loss: 0.0622\n",
      "Epoch 30/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0620\n",
      "Epoch 31/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0912 - val_loss: 0.0627\n",
      "Epoch 32/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0911 - val_loss: 0.0612\n",
      "Epoch 33/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0905 - val_loss: 0.0591\n",
      "Epoch 34/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0902 - val_loss: 0.0566\n",
      "Epoch 35/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.0596\n",
      "Epoch 36/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0897 - val_loss: 0.0575\n",
      "Epoch 37/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0892 - val_loss: 0.0563\n",
      "Epoch 38/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0895 - val_loss: 0.0548\n",
      "Epoch 39/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0889 - val_loss: 0.0580\n",
      "Epoch 40/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0884 - val_loss: 0.0576\n",
      "Epoch 41/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0882 - val_loss: 0.0554\n",
      "Epoch 42/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0884 - val_loss: 0.0586\n",
      "Epoch 43/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0878 - val_loss: 0.0570\n",
      "Epoch 44/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0875 - val_loss: 0.0554\n",
      "Epoch 45/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0874 - val_loss: 0.0562\n",
      "Epoch 46/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0871 - val_loss: 0.0576\n",
      "Epoch 47/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0868 - val_loss: 0.0579\n",
      "Epoch 48/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0867 - val_loss: 0.0563\n",
      "Epoch 49/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0865 - val_loss: 0.0556\n",
      "Epoch 50/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0861 - val_loss: 0.0606\n",
      "Epoch 51/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0859 - val_loss: 0.0537\n",
      "Epoch 52/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0855 - val_loss: 0.0567\n",
      "Epoch 53/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0857 - val_loss: 0.0534\n",
      "Epoch 54/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0851 - val_loss: 0.0549\n",
      "Epoch 55/100\n",
      "32580/32580 [==============================] - 2s 60us/sample - loss: 0.0853 - val_loss: 0.0543\n",
      "Epoch 56/100\n",
      "32580/32580 [==============================] - 2s 62us/sample - loss: 0.0849 - val_loss: 0.0571\n",
      "Epoch 57/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0847 - val_loss: 0.0553\n",
      "Epoch 58/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0841 - val_loss: 0.0537\n",
      "Epoch 59/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0838 - val_loss: 0.0522\n",
      "Epoch 60/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0837 - val_loss: 0.0543\n",
      "Epoch 61/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0838 - val_loss: 0.0547\n",
      "Epoch 62/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0832 - val_loss: 0.0522\n",
      "Epoch 63/100\n",
      "32580/32580 [==============================] - 2s 53us/sample - loss: 0.0831 - val_loss: 0.0544\n",
      "Epoch 64/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0830 - val_loss: 0.0570\n",
      "Epoch 65/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0826 - val_loss: 0.0536\n",
      "Epoch 66/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0822 - val_loss: 0.0511\n",
      "Epoch 67/100\n",
      "32580/32580 [==============================] - 2s 47us/sample - loss: 0.0820 - val_loss: 0.0521\n",
      "Epoch 68/100\n",
      "32580/32580 [==============================] - 1s 44us/sample - loss: 0.0819 - val_loss: 0.0555\n",
      "Epoch 69/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0817 - val_loss: 0.0549\n",
      "Epoch 70/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0815 - val_loss: 0.0535\n",
      "Epoch 71/100\n",
      "32580/32580 [==============================] - 2s 51us/sample - loss: 0.0813 - val_loss: 0.0532\n",
      "Epoch 72/100\n",
      "32580/32580 [==============================] - 2s 52us/sample - loss: 0.0808 - val_loss: 0.0538\n",
      "Epoch 73/100\n",
      "32580/32580 [==============================] - 2s 50us/sample - loss: 0.0810 - val_loss: 0.0526\n",
      "Epoch 74/100\n",
      "32580/32580 [==============================] - 2s 48us/sample - loss: 0.0806 - val_loss: 0.0525\n",
      "Epoch 75/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0801 - val_loss: 0.0545\n",
      "Epoch 76/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0803 - val_loss: 0.0539\n",
      "Epoch 77/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0800 - val_loss: 0.0531\n",
      "Epoch 78/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0796 - val_loss: 0.0518\n",
      "Epoch 79/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0792 - val_loss: 0.0544\n",
      "Epoch 80/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0793 - val_loss: 0.0538\n",
      "Epoch 81/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0788 - val_loss: 0.0543\n",
      "Epoch 82/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0785 - val_loss: 0.0536\n",
      "Epoch 83/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0784 - val_loss: 0.0537\n",
      "Epoch 84/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0782 - val_loss: 0.0532\n",
      "Epoch 85/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0780 - val_loss: 0.0550\n",
      "Epoch 86/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0779 - val_loss: 0.0556\n",
      "Epoch 87/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0775 - val_loss: 0.0557\n",
      "Epoch 88/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0772 - val_loss: 0.0535\n",
      "Epoch 89/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0774 - val_loss: 0.0530\n",
      "Epoch 90/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0769 - val_loss: 0.0545\n",
      "Epoch 91/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0767 - val_loss: 0.0551\n",
      "Epoch 92/100\n",
      "32580/32580 [==============================] - 2s 56us/sample - loss: 0.0762 - val_loss: 0.0536\n",
      "Epoch 93/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0760 - val_loss: 0.0519\n",
      "Epoch 94/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0759 - val_loss: 0.0541\n",
      "Epoch 95/100\n",
      "32580/32580 [==============================] - 2s 58us/sample - loss: 0.0756 - val_loss: 0.0540\n",
      "Epoch 96/100\n",
      "32580/32580 [==============================] - 2s 57us/sample - loss: 0.0754 - val_loss: 0.0559\n",
      "Epoch 97/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0748 - val_loss: 0.0571\n",
      "Epoch 98/100\n",
      "32580/32580 [==============================] - 2s 59us/sample - loss: 0.0749 - val_loss: 0.0550\n",
      "Epoch 99/100\n",
      "32580/32580 [==============================] - 2s 55us/sample - loss: 0.0746 - val_loss: 0.0536\n",
      "Epoch 100/100\n",
      "32580/32580 [==============================] - 2s 54us/sample - loss: 0.0741 - val_loss: 0.0560\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 2\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 137us/sample - loss: 0.1856 - val_loss: 0.1476\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1567 - val_loss: 0.1220\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1432 - val_loss: 0.1139\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1365 - val_loss: 0.1130\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1325 - val_loss: 0.1122\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1300 - val_loss: 0.1073\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1283 - val_loss: 0.1076\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1270 - val_loss: 0.1103\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1260 - val_loss: 0.1083\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1251 - val_loss: 0.1110\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1244 - val_loss: 0.1088\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1237 - val_loss: 0.1098\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1231 - val_loss: 0.1091\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1224 - val_loss: 0.1085\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1218 - val_loss: 0.1068\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1210 - val_loss: 0.1068\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1203 - val_loss: 0.1064\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1198 - val_loss: 0.1034\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1192 - val_loss: 0.1058\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1188 - val_loss: 0.1024\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1185 - val_loss: 0.1032\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1182 - val_loss: 0.0998\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1180 - val_loss: 0.1058\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1178 - val_loss: 0.1035\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1174 - val_loss: 0.1059\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1173 - val_loss: 0.0998\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1171 - val_loss: 0.1020\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1169 - val_loss: 0.0992\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1168 - val_loss: 0.1001\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1165 - val_loss: 0.1026\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1164 - val_loss: 0.1033\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1163 - val_loss: 0.0996\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1160 - val_loss: 0.1038\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1160 - val_loss: 0.1007\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1159 - val_loss: 0.1009\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1158 - val_loss: 0.1008\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1156 - val_loss: 0.1024\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1154 - val_loss: 0.0979\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1155 - val_loss: 0.1023\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1153 - val_loss: 0.1004\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1151 - val_loss: 0.0986\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1149 - val_loss: 0.1046\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1149 - val_loss: 0.1012\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1147 - val_loss: 0.0993\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1145 - val_loss: 0.1002\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1143 - val_loss: 0.1004\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1141 - val_loss: 0.0996\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1138 - val_loss: 0.1000\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1138 - val_loss: 0.0999\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1136 - val_loss: 0.1017\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1135 - val_loss: 0.0982\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1133 - val_loss: 0.0987\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1130 - val_loss: 0.1012\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1129 - val_loss: 0.1015\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1130 - val_loss: 0.0989\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1126 - val_loss: 0.0959\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1124 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1123 - val_loss: 0.0995\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1121 - val_loss: 0.0943\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1121 - val_loss: 0.1024\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1118 - val_loss: 0.1013\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1118 - val_loss: 0.0967\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1116 - val_loss: 0.0980\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1114 - val_loss: 0.0949\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1114 - val_loss: 0.0998\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1113 - val_loss: 0.0988\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1112 - val_loss: 0.0928\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1110 - val_loss: 0.0959\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1111 - val_loss: 0.0939\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1108 - val_loss: 0.0910\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1108 - val_loss: 0.0996\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1107 - val_loss: 0.0954\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1107 - val_loss: 0.0934\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1107 - val_loss: 0.0912\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1105 - val_loss: 0.0933\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1104 - val_loss: 0.0931\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1101 - val_loss: 0.0926\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1102 - val_loss: 0.1005\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1101 - val_loss: 0.1078\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1099 - val_loss: 0.0920\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1098 - val_loss: 0.0945\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1097 - val_loss: 0.0891\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1096 - val_loss: 0.0910\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1094 - val_loss: 0.0924\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1095 - val_loss: 0.0984\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1092 - val_loss: 0.0947\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1092 - val_loss: 0.0931\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1091 - val_loss: 0.1036\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1092 - val_loss: 0.0910\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 64us/sample - loss: 0.1089 - val_loss: 0.0938\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1087 - val_loss: 0.0934\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1088 - val_loss: 0.0924\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1086 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1085 - val_loss: 0.0923\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1085 - val_loss: 0.0917\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1083 - val_loss: 0.0896\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1082 - val_loss: 0.0991\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1081 - val_loss: 0.0934\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1082 - val_loss: 0.0881\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1081 - val_loss: 0.0932\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 4\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 151us/sample - loss: 0.1740 - val_loss: 0.1141\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1339 - val_loss: 0.1061\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1261 - val_loss: 0.1081\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1231 - val_loss: 0.1078\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1213 - val_loss: 0.1005\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1202 - val_loss: 0.1034\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1194 - val_loss: 0.0980\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1189 - val_loss: 0.0981\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1185 - val_loss: 0.1021\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1180 - val_loss: 0.1030\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1177 - val_loss: 0.0997\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1175 - val_loss: 0.1076\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1171 - val_loss: 0.1021\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1167 - val_loss: 0.1065\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1164 - val_loss: 0.1057\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1162 - val_loss: 0.1002\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1160 - val_loss: 0.1018\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.1157 - val_loss: 0.1012\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1155 - val_loss: 0.1028\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.1153 - val_loss: 0.1058\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1150 - val_loss: 0.1014\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1149 - val_loss: 0.0986\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1148 - val_loss: 0.1004\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1145 - val_loss: 0.1036\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1141 - val_loss: 0.0999\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1141 - val_loss: 0.0979\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1137 - val_loss: 0.1032\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1135 - val_loss: 0.1074\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1136 - val_loss: 0.1053\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1134 - val_loss: 0.0998\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1129 - val_loss: 0.1058\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1127 - val_loss: 0.0955\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1126 - val_loss: 0.0996\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1126 - val_loss: 0.0977\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1122 - val_loss: 0.0935\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1123 - val_loss: 0.0970\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1119 - val_loss: 0.1077\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1119 - val_loss: 0.1037\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1116 - val_loss: 0.0947\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1114 - val_loss: 0.0985\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1110 - val_loss: 0.0947\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1109 - val_loss: 0.0944\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1107 - val_loss: 0.1011\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1104 - val_loss: 0.0970\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1103 - val_loss: 0.0962\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1100 - val_loss: 0.0964\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1098 - val_loss: 0.0951\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1094 - val_loss: 0.0964\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1094 - val_loss: 0.0963\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1091 - val_loss: 0.0925\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1090 - val_loss: 0.0966\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1086 - val_loss: 0.0907\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1084 - val_loss: 0.0937\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.0919\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.0946\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1079 - val_loss: 0.0940\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1077 - val_loss: 0.0908\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1074 - val_loss: 0.0936\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1070 - val_loss: 0.0892\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1070 - val_loss: 0.0901\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1068 - val_loss: 0.0920\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1064 - val_loss: 0.0918\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1063 - val_loss: 0.0890\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1060 - val_loss: 0.0899\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1057 - val_loss: 0.0902\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1058 - val_loss: 0.0880\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1054 - val_loss: 0.0863\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1052 - val_loss: 0.0885\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1051 - val_loss: 0.0854\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1049 - val_loss: 0.0841\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1048 - val_loss: 0.0899\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.1046 - val_loss: 0.0861\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1044 - val_loss: 0.0830\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1044 - val_loss: 0.0838\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1040 - val_loss: 0.0854\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1039 - val_loss: 0.0878\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1037 - val_loss: 0.0828\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1038 - val_loss: 0.0904\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1036 - val_loss: 0.0904\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1034 - val_loss: 0.0858\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0830\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1031 - val_loss: 0.0801\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1031 - val_loss: 0.0818\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1029 - val_loss: 0.0852\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1028 - val_loss: 0.0817\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1027 - val_loss: 0.0813\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1026 - val_loss: 0.0828\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1026 - val_loss: 0.0875\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1024 - val_loss: 0.0834\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1024 - val_loss: 0.0833\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1023 - val_loss: 0.0808\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1023 - val_loss: 0.0813\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1024 - val_loss: 0.0837\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1021 - val_loss: 0.0803\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1021 - val_loss: 0.0782\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1019 - val_loss: 0.0777\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1018 - val_loss: 0.0832\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1018 - val_loss: 0.0814\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1016 - val_loss: 0.0820\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1016 - val_loss: 0.0833\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 8\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 149us/sample - loss: 0.1639 - val_loss: 0.1128\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1288 - val_loss: 0.1060\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1229 - val_loss: 0.1103\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1197 - val_loss: 0.1022\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1178 - val_loss: 0.1041\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1161 - val_loss: 0.1065\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1154 - val_loss: 0.0983\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1146 - val_loss: 0.0972\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1138 - val_loss: 0.1007\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1131 - val_loss: 0.1033\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1123 - val_loss: 0.0998\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1117 - val_loss: 0.1022\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1108 - val_loss: 0.0975\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1099 - val_loss: 0.1012\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1093 - val_loss: 0.0945\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1088 - val_loss: 0.0928\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1080 - val_loss: 0.0937\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1075 - val_loss: 0.0907\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1071 - val_loss: 0.0929\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1067 - val_loss: 0.0970\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1063 - val_loss: 0.0916\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1060 - val_loss: 0.0859\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1058 - val_loss: 0.0892\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1054 - val_loss: 0.0897\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1050 - val_loss: 0.0852\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1050 - val_loss: 0.0858\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1047 - val_loss: 0.0841\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1043 - val_loss: 0.0879\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1042 - val_loss: 0.0874\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1038 - val_loss: 0.0837\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1035 - val_loss: 0.0955\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1035 - val_loss: 0.0838\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1030 - val_loss: 0.0842\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1031 - val_loss: 0.0805\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.1029 - val_loss: 0.0811\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1026 - val_loss: 0.0785\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1025 - val_loss: 0.0901\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1023 - val_loss: 0.0832\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1020 - val_loss: 0.0776\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 46us/sample - loss: 0.1018 - val_loss: 0.0824\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1015 - val_loss: 0.0830\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1014 - val_loss: 0.0827\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1014 - val_loss: 0.0793\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1011 - val_loss: 0.0849\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1010 - val_loss: 0.0807\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1007 - val_loss: 0.0783\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1006 - val_loss: 0.0766\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1005 - val_loss: 0.0828\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1003 - val_loss: 0.0787\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1001 - val_loss: 0.0795\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1000 - val_loss: 0.0820\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0999 - val_loss: 0.0750\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 63us/sample - loss: 0.0996 - val_loss: 0.0814\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0996 - val_loss: 0.0754\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.0995 - val_loss: 0.0785\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0993 - val_loss: 0.0822\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0992 - val_loss: 0.0800\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0990 - val_loss: 0.0725\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0989 - val_loss: 0.0728\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0988 - val_loss: 0.0817\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0987 - val_loss: 0.0797\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0987 - val_loss: 0.0768\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0985 - val_loss: 0.0771\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0983 - val_loss: 0.0749\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0982 - val_loss: 0.0768\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0983 - val_loss: 0.0746\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0979 - val_loss: 0.0772\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.0981 - val_loss: 0.0789\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0758\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0977 - val_loss: 0.0788\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0976 - val_loss: 0.0799\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0715\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0975 - val_loss: 0.0724\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0975 - val_loss: 0.0711\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0973 - val_loss: 0.0723\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0974 - val_loss: 0.0732\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.0703\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0972 - val_loss: 0.0765\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0970 - val_loss: 0.0742\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0968 - val_loss: 0.0714\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0701\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0968 - val_loss: 0.0697\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0966 - val_loss: 0.0739\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0966 - val_loss: 0.0706\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0735\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0964 - val_loss: 0.0793\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.0963 - val_loss: 0.0774\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0963 - val_loss: 0.0819\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0963 - val_loss: 0.0731\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.0962 - val_loss: 0.0769\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 47us/sample - loss: 0.0961 - val_loss: 0.0736\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.0961 - val_loss: 0.0751\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.0963 - val_loss: 0.0698\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0713\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0960 - val_loss: 0.0714\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0959 - val_loss: 0.0722\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0958 - val_loss: 0.0700\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0955 - val_loss: 0.0778\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0957 - val_loss: 0.0702\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0956 - val_loss: 0.0704\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 16\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 4s 134us/sample - loss: 0.1506 - val_loss: 0.1096\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1232 - val_loss: 0.1042\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1208 - val_loss: 0.1175\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1197 - val_loss: 0.1020\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1190 - val_loss: 0.1049\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1186 - val_loss: 0.1091\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1184 - val_loss: 0.1073\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1178 - val_loss: 0.0973\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1177 - val_loss: 0.1018\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1170 - val_loss: 0.1008\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.1096\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.0998\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1156 - val_loss: 0.1147\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1153 - val_loss: 0.1008\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1143 - val_loss: 0.1070\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1138 - val_loss: 0.1015\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1135 - val_loss: 0.1001\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1126 - val_loss: 0.0959\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1119 - val_loss: 0.0965\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1112 - val_loss: 0.1011\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1106 - val_loss: 0.0941\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1098 - val_loss: 0.0957\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1099 - val_loss: 0.0994\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.1030\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1077 - val_loss: 0.0919\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1073 - val_loss: 0.0973\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1067 - val_loss: 0.0928\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1066 - val_loss: 0.0923\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1059 - val_loss: 0.0920\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1054 - val_loss: 0.0845\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1050 - val_loss: 0.0981\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1043 - val_loss: 0.0860\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1041 - val_loss: 0.0853\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1040 - val_loss: 0.0864\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1036 - val_loss: 0.0836\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1035 - val_loss: 0.0831\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1028 - val_loss: 0.0925\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1030 - val_loss: 0.0873\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 61us/sample - loss: 0.1018 - val_loss: 0.0821\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.1021 - val_loss: 0.0795\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1014 - val_loss: 0.0813\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1010 - val_loss: 0.0840\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1008 - val_loss: 0.0852\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1008 - val_loss: 0.0818\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1003 - val_loss: 0.0864\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0999 - val_loss: 0.0839\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0846\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0995 - val_loss: 0.0845\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0776\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0988 - val_loss: 0.0807\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0991 - val_loss: 0.0802\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0984 - val_loss: 0.0807\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0982 - val_loss: 0.0760\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0982 - val_loss: 0.0732\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0980 - val_loss: 0.0808\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0979 - val_loss: 0.0724\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0981 - val_loss: 0.0767\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0974 - val_loss: 0.0766\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0974 - val_loss: 0.0734\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0970 - val_loss: 0.0846\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0971 - val_loss: 0.0828\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0972 - val_loss: 0.0735\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0968 - val_loss: 0.0719\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0761\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0965 - val_loss: 0.0706\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0965 - val_loss: 0.0706\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0963 - val_loss: 0.0747\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0962 - val_loss: 0.0758\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0961 - val_loss: 0.0734\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0961 - val_loss: 0.0712\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0960 - val_loss: 0.0816\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0960 - val_loss: 0.0705\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0959 - val_loss: 0.0693\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0958 - val_loss: 0.0761\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0956 - val_loss: 0.0775\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0957 - val_loss: 0.0714\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0954 - val_loss: 0.0698\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0956 - val_loss: 0.0752\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0954 - val_loss: 0.0759\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0952 - val_loss: 0.0699\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0952 - val_loss: 0.0694\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0952 - val_loss: 0.0688\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0953 - val_loss: 0.0726\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0950 - val_loss: 0.0693\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0716\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0950 - val_loss: 0.0732\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0947 - val_loss: 0.0677\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0947 - val_loss: 0.0782\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0714\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0946 - val_loss: 0.0763\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0946 - val_loss: 0.0664\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0666\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0683\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0945 - val_loss: 0.0733\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0945 - val_loss: 0.0693\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0941 - val_loss: 0.0695\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0944 - val_loss: 0.0709\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0940 - val_loss: 0.0677\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0943 - val_loss: 0.0685\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0944 - val_loss: 0.0687\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 32\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 140us/sample - loss: 0.1440 - val_loss: 0.0993\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1217 - val_loss: 0.1034\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1203 - val_loss: 0.1107\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1199 - val_loss: 0.1017\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.1193 - val_loss: 0.1091\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1187 - val_loss: 0.1110\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1186 - val_loss: 0.1056\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1180 - val_loss: 0.0973\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1175 - val_loss: 0.1029\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1166 - val_loss: 0.0998\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.1083\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1154 - val_loss: 0.1031\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1141 - val_loss: 0.1112\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1138 - val_loss: 0.1023\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1122 - val_loss: 0.0999\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1109 - val_loss: 0.0957\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.1100 - val_loss: 0.1049\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1090 - val_loss: 0.0933\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1080 - val_loss: 0.0941\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1073 - val_loss: 0.0974\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1058 - val_loss: 0.0907\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1055 - val_loss: 0.0870\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1046 - val_loss: 0.0902\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1034 - val_loss: 0.0906\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0862\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1027 - val_loss: 0.0926\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0926\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1014 - val_loss: 0.0885\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1009 - val_loss: 0.0947\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1007 - val_loss: 0.0821\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1004 - val_loss: 0.0872\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0801\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0906\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0990 - val_loss: 0.0800\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 46us/sample - loss: 0.0988 - val_loss: 0.0766\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.0982 - val_loss: 0.0746\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0984 - val_loss: 0.0906\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0978 - val_loss: 0.0798\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0973 - val_loss: 0.0734\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0975 - val_loss: 0.0779\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0971 - val_loss: 0.0757\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0968 - val_loss: 0.0750\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0970 - val_loss: 0.0753\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0968 - val_loss: 0.0740\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0963 - val_loss: 0.0830\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0960 - val_loss: 0.0771\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0958 - val_loss: 0.0759\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0956 - val_loss: 0.0829\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0775\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0956 - val_loss: 0.0748\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0952 - val_loss: 0.0773\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0953 - val_loss: 0.0813\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0949 - val_loss: 0.0727\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0949 - val_loss: 0.0703\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0951 - val_loss: 0.0829\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0746\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0949 - val_loss: 0.0728\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0946 - val_loss: 0.0727\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.0719\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0942 - val_loss: 0.0794\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0945 - val_loss: 0.0755\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0944 - val_loss: 0.0781\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0939 - val_loss: 0.0682\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0939 - val_loss: 0.0700\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0936 - val_loss: 0.0754\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0937 - val_loss: 0.0696\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0934 - val_loss: 0.0724\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0936 - val_loss: 0.0717\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0933 - val_loss: 0.0704\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0933 - val_loss: 0.0787\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0779\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0663\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0929 - val_loss: 0.0684\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0932 - val_loss: 0.0693\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0928 - val_loss: 0.0749\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0710\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0694\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0671\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0690\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0921 - val_loss: 0.0665\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0923 - val_loss: 0.0665\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0923 - val_loss: 0.0662\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0921 - val_loss: 0.0661\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0921 - val_loss: 0.0667\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0715\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0919 - val_loss: 0.0691\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0916 - val_loss: 0.0657\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0920 - val_loss: 0.0682\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0917 - val_loss: 0.0680\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0917 - val_loss: 0.0686\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0915 - val_loss: 0.0667\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0916 - val_loss: 0.0638\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0915 - val_loss: 0.0662\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0689\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0911 - val_loss: 0.0644\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0910 - val_loss: 0.0689\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0912 - val_loss: 0.0663\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0908 - val_loss: 0.0683\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0910 - val_loss: 0.0627\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0912 - val_loss: 0.0683\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 64\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 150us/sample - loss: 0.1431 - val_loss: 0.1044\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1211 - val_loss: 0.1111\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1204 - val_loss: 0.1118\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1206 - val_loss: 0.1071\n",
      "Epoch 5/100\n",
      "33340/33340 [==============================] - 2s 48us/sample - loss: 0.1194 - val_loss: 0.1102\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1186 - val_loss: 0.1229\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1182 - val_loss: 0.1088\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1176 - val_loss: 0.0980\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1163 - val_loss: 0.1018\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1135 - val_loss: 0.0966\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1113 - val_loss: 0.1022\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1107 - val_loss: 0.0953\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.0927\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1071 - val_loss: 0.0929\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1058 - val_loss: 0.0868\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1044 - val_loss: 0.0826\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1037 - val_loss: 0.0913\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1032 - val_loss: 0.0852\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1027 - val_loss: 0.0845\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1019 - val_loss: 0.0895\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1020 - val_loss: 0.0848\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1012 - val_loss: 0.0776\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1008 - val_loss: 0.0793\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1000 - val_loss: 0.0820\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0997 - val_loss: 0.0784\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1001 - val_loss: 0.0841\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0988 - val_loss: 0.0789\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0836\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0884\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0982 - val_loss: 0.0732\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0977 - val_loss: 0.0765\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0975 - val_loss: 0.0737\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0971 - val_loss: 0.0877\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0969 - val_loss: 0.0761\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0972 - val_loss: 0.0703\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0966 - val_loss: 0.0740\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0964 - val_loss: 0.0872\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0962 - val_loss: 0.0782\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0699\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0958 - val_loss: 0.0712\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0952 - val_loss: 0.0717\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0687\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0949 - val_loss: 0.0744\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0944 - val_loss: 0.0696\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0943 - val_loss: 0.0743\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0941 - val_loss: 0.0692\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0940 - val_loss: 0.0667\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0936 - val_loss: 0.0684\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0935 - val_loss: 0.0725\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0935 - val_loss: 0.0661\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0721\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0930 - val_loss: 0.0715\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0703\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0927 - val_loss: 0.0629\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0929 - val_loss: 0.0717\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0924 - val_loss: 0.0689\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0715\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0921 - val_loss: 0.0657\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0918 - val_loss: 0.0645\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0918 - val_loss: 0.0795\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0920 - val_loss: 0.0703\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0681\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0913 - val_loss: 0.0647\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0913 - val_loss: 0.0645\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0906 - val_loss: 0.0656\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0908 - val_loss: 0.0641\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0910 - val_loss: 0.0710\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0908 - val_loss: 0.0630\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0905 - val_loss: 0.0703\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0906 - val_loss: 0.0626\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0902 - val_loss: 0.0658\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.0607\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0899 - val_loss: 0.0620\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0901 - val_loss: 0.0634\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0898 - val_loss: 0.0669\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0894 - val_loss: 0.0649\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0895 - val_loss: 0.0629\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0895 - val_loss: 0.0616\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0892 - val_loss: 0.0659\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0890 - val_loss: 0.0652\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0891 - val_loss: 0.0637\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0890 - val_loss: 0.0627\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0888 - val_loss: 0.0595\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0889 - val_loss: 0.0677\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0887 - val_loss: 0.0646\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0886 - val_loss: 0.0610\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0886 - val_loss: 0.0601\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0886 - val_loss: 0.0616\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0881 - val_loss: 0.0624\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0881 - val_loss: 0.0657\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0884 - val_loss: 0.0616\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0882 - val_loss: 0.0591\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 60us/sample - loss: 0.0878 - val_loss: 0.0634\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0881 - val_loss: 0.0659\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0880 - val_loss: 0.0615\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0877 - val_loss: 0.0630\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0876 - val_loss: 0.0601\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0874 - val_loss: 0.0628\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0875 - val_loss: 0.0610\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0874 - val_loss: 0.0617\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 7, units: 128\n",
      "Train on 33340 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33340/33340 [==============================] - 5s 150us/sample - loss: 0.1373 - val_loss: 0.1074\n",
      "Epoch 2/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.1219 - val_loss: 0.1127\n",
      "Epoch 3/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1208 - val_loss: 0.1103\n",
      "Epoch 4/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1205 - val_loss: 0.1084\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33340/33340 [==============================] - 2s 46us/sample - loss: 0.1187 - val_loss: 0.1163\n",
      "Epoch 6/100\n",
      "33340/33340 [==============================] - 2s 47us/sample - loss: 0.1183 - val_loss: 0.1177\n",
      "Epoch 7/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1167 - val_loss: 0.0991\n",
      "Epoch 8/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.1154 - val_loss: 0.0951\n",
      "Epoch 9/100\n",
      "33340/33340 [==============================] - 2s 49us/sample - loss: 0.1130 - val_loss: 0.0963\n",
      "Epoch 10/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1110 - val_loss: 0.0927\n",
      "Epoch 11/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.1092 - val_loss: 0.0930\n",
      "Epoch 12/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.1074 - val_loss: 0.0869\n",
      "Epoch 13/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1048 - val_loss: 0.0863\n",
      "Epoch 14/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.1042 - val_loss: 0.1005\n",
      "Epoch 15/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1033 - val_loss: 0.0904\n",
      "Epoch 16/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.1027 - val_loss: 0.0769\n",
      "Epoch 17/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.1009 - val_loss: 0.0819\n",
      "Epoch 18/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.1003 - val_loss: 0.0804\n",
      "Epoch 19/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0991 - val_loss: 0.0795\n",
      "Epoch 20/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0984 - val_loss: 0.0892\n",
      "Epoch 21/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0979 - val_loss: 0.0756\n",
      "Epoch 22/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0972 - val_loss: 0.0707\n",
      "Epoch 23/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0967 - val_loss: 0.0730\n",
      "Epoch 24/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0958 - val_loss: 0.0742\n",
      "Epoch 25/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0954 - val_loss: 0.0748\n",
      "Epoch 26/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0955 - val_loss: 0.0703\n",
      "Epoch 27/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0949 - val_loss: 0.0712\n",
      "Epoch 28/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0949 - val_loss: 0.0728\n",
      "Epoch 29/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0947 - val_loss: 0.0768\n",
      "Epoch 30/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0941 - val_loss: 0.0655\n",
      "Epoch 31/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.0654\n",
      "Epoch 32/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0676\n",
      "Epoch 33/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0932 - val_loss: 0.0703\n",
      "Epoch 34/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0930 - val_loss: 0.0691\n",
      "Epoch 35/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0668\n",
      "Epoch 36/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0924 - val_loss: 0.0632\n",
      "Epoch 37/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0922 - val_loss: 0.0738\n",
      "Epoch 38/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0920 - val_loss: 0.0630\n",
      "Epoch 39/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0918 - val_loss: 0.0647\n",
      "Epoch 40/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0915 - val_loss: 0.0693\n",
      "Epoch 41/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0911 - val_loss: 0.0641\n",
      "Epoch 42/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0911 - val_loss: 0.0634\n",
      "Epoch 43/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0906 - val_loss: 0.0610\n",
      "Epoch 44/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0908 - val_loss: 0.0667\n",
      "Epoch 45/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0905 - val_loss: 0.0663\n",
      "Epoch 46/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0903 - val_loss: 0.0671\n",
      "Epoch 47/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0900 - val_loss: 0.0623\n",
      "Epoch 48/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0897 - val_loss: 0.0620\n",
      "Epoch 49/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0895 - val_loss: 0.0665\n",
      "Epoch 50/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0897 - val_loss: 0.0614\n",
      "Epoch 51/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0892 - val_loss: 0.0616\n",
      "Epoch 52/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0892 - val_loss: 0.0629\n",
      "Epoch 53/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0595\n",
      "Epoch 54/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0890 - val_loss: 0.0600\n",
      "Epoch 55/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0616\n",
      "Epoch 56/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0883 - val_loss: 0.0671\n",
      "Epoch 57/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0884 - val_loss: 0.0655\n",
      "Epoch 58/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0882 - val_loss: 0.0620\n",
      "Epoch 59/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0883 - val_loss: 0.0612\n",
      "Epoch 60/100\n",
      "33340/33340 [==============================] - 2s 58us/sample - loss: 0.0880 - val_loss: 0.0670\n",
      "Epoch 61/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0880 - val_loss: 0.0623\n",
      "Epoch 62/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0878 - val_loss: 0.0619\n",
      "Epoch 63/100\n",
      "33340/33340 [==============================] - 2s 59us/sample - loss: 0.0875 - val_loss: 0.0633\n",
      "Epoch 64/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0875 - val_loss: 0.0631\n",
      "Epoch 65/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0872 - val_loss: 0.0608\n",
      "Epoch 66/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0871 - val_loss: 0.0601\n",
      "Epoch 67/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0871 - val_loss: 0.0648\n",
      "Epoch 68/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0872 - val_loss: 0.0575\n",
      "Epoch 69/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0867 - val_loss: 0.0613\n",
      "Epoch 70/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0867 - val_loss: 0.0597\n",
      "Epoch 71/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0864 - val_loss: 0.0612\n",
      "Epoch 72/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0864 - val_loss: 0.0591\n",
      "Epoch 73/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0862 - val_loss: 0.0603\n",
      "Epoch 74/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0864 - val_loss: 0.0597\n",
      "Epoch 75/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0862 - val_loss: 0.0585\n",
      "Epoch 76/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0857 - val_loss: 0.0606\n",
      "Epoch 77/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0857 - val_loss: 0.0602\n",
      "Epoch 78/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0858 - val_loss: 0.0598\n",
      "Epoch 79/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0856 - val_loss: 0.0607\n",
      "Epoch 80/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0854 - val_loss: 0.0592\n",
      "Epoch 81/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0853 - val_loss: 0.0607\n",
      "Epoch 82/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0854 - val_loss: 0.0591\n",
      "Epoch 83/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0852 - val_loss: 0.0578\n",
      "Epoch 84/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0852 - val_loss: 0.0608\n",
      "Epoch 85/100\n",
      "33340/33340 [==============================] - 2s 53us/sample - loss: 0.0850 - val_loss: 0.0585\n",
      "Epoch 86/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0847 - val_loss: 0.0584\n",
      "Epoch 87/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0845 - val_loss: 0.0590\n",
      "Epoch 88/100\n",
      "33340/33340 [==============================] - 2s 56us/sample - loss: 0.0846 - val_loss: 0.0588\n",
      "Epoch 89/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0842 - val_loss: 0.0613\n",
      "Epoch 90/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0842 - val_loss: 0.0604\n",
      "Epoch 91/100\n",
      "33340/33340 [==============================] - 2s 50us/sample - loss: 0.0843 - val_loss: 0.0593\n",
      "Epoch 92/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0841 - val_loss: 0.0592\n",
      "Epoch 93/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0836 - val_loss: 0.0604\n",
      "Epoch 94/100\n",
      "33340/33340 [==============================] - 2s 57us/sample - loss: 0.0837 - val_loss: 0.0603\n",
      "Epoch 95/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0836 - val_loss: 0.0595\n",
      "Epoch 96/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0835 - val_loss: 0.0593\n",
      "Epoch 97/100\n",
      "33340/33340 [==============================] - 2s 55us/sample - loss: 0.0832 - val_loss: 0.0586\n",
      "Epoch 98/100\n",
      "33340/33340 [==============================] - 2s 51us/sample - loss: 0.0830 - val_loss: 0.0595\n",
      "Epoch 99/100\n",
      "33340/33340 [==============================] - 2s 52us/sample - loss: 0.0831 - val_loss: 0.0580\n",
      "Epoch 100/100\n",
      "33340/33340 [==============================] - 2s 54us/sample - loss: 0.0829 - val_loss: 0.0604\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 2\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 4s 135us/sample - loss: 0.1901 - val_loss: 0.1429\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1469 - val_loss: 0.1091\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1315 - val_loss: 0.1021\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1272 - val_loss: 0.1006\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1251 - val_loss: 0.1012\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1234 - val_loss: 0.1049\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1222 - val_loss: 0.0985\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1207 - val_loss: 0.0999\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1194 - val_loss: 0.0988\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1181 - val_loss: 0.0990\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1171 - val_loss: 0.0993\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1163 - val_loss: 0.0989\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1157 - val_loss: 0.1040\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1150 - val_loss: 0.1040\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1144 - val_loss: 0.1018\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1141 - val_loss: 0.0994\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1135 - val_loss: 0.0974\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1132 - val_loss: 0.1030\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1126 - val_loss: 0.1008\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1122 - val_loss: 0.1021\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1118 - val_loss: 0.1014\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1115 - val_loss: 0.0998\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1112 - val_loss: 0.0994\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1108 - val_loss: 0.0993\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1106 - val_loss: 0.1034\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1103 - val_loss: 0.0976\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1100 - val_loss: 0.0996\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1097 - val_loss: 0.1014\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1094 - val_loss: 0.1007\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1091 - val_loss: 0.0990\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1089 - val_loss: 0.0970\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1087 - val_loss: 0.0998\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1084 - val_loss: 0.0990\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1083 - val_loss: 0.0951\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1079 - val_loss: 0.1005\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1078 - val_loss: 0.0955\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1076 - val_loss: 0.0954\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1073 - val_loss: 0.0937\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 48us/sample - loss: 0.1072 - val_loss: 0.0936\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1071 - val_loss: 0.0944\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.1032\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1068 - val_loss: 0.0988\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1067 - val_loss: 0.0919\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1065 - val_loss: 0.0960\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1063 - val_loss: 0.0918\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1064 - val_loss: 0.0921\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1062 - val_loss: 0.0913\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1062 - val_loss: 0.0970\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1061 - val_loss: 0.0898\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1061 - val_loss: 0.0902\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.1059 - val_loss: 0.0927\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1060 - val_loss: 0.0955\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1057 - val_loss: 0.0963\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1056 - val_loss: 0.0909\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1055 - val_loss: 0.0935\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1056 - val_loss: 0.0970\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1054 - val_loss: 0.0942\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1056 - val_loss: 0.0872\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1055 - val_loss: 0.0900\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.1052 - val_loss: 0.0938\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1052 - val_loss: 0.0919\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1050 - val_loss: 0.0896\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1051 - val_loss: 0.0897\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1050 - val_loss: 0.0933\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.1048 - val_loss: 0.0937\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1048 - val_loss: 0.0879\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1047 - val_loss: 0.0873\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1047 - val_loss: 0.0894\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1047 - val_loss: 0.0882\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1046 - val_loss: 0.0871\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1045 - val_loss: 0.0862\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1045 - val_loss: 0.0910\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1045 - val_loss: 0.0893\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1044 - val_loss: 0.0883\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1043 - val_loss: 0.0888\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1043 - val_loss: 0.0900\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1042 - val_loss: 0.0924\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1043 - val_loss: 0.0890\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1041 - val_loss: 0.0885\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1041 - val_loss: 0.0864\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1041 - val_loss: 0.0892\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1039 - val_loss: 0.0868\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1039 - val_loss: 0.0872\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1040 - val_loss: 0.0877\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1041 - val_loss: 0.0886\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1038 - val_loss: 0.0899\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1038 - val_loss: 0.0876\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.1039 - val_loss: 0.0877\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1036 - val_loss: 0.0898\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1036 - val_loss: 0.0904\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1036 - val_loss: 0.0864\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1035 - val_loss: 0.0895\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1037 - val_loss: 0.0865\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1036 - val_loss: 0.0893\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1035 - val_loss: 0.0867\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1034 - val_loss: 0.0844\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1033 - val_loss: 0.0856\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1032 - val_loss: 0.0914\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1033 - val_loss: 0.0886\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1031 - val_loss: 0.0850\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 4\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 148us/sample - loss: 0.1963 - val_loss: 0.1314\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1554 - val_loss: 0.1237\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1447 - val_loss: 0.1190\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1345 - val_loss: 0.1109\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1254 - val_loss: 0.1021\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1212 - val_loss: 0.1111\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1190 - val_loss: 0.1016\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1177 - val_loss: 0.0982\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1167 - val_loss: 0.1033\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1159 - val_loss: 0.0985\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1152 - val_loss: 0.1041\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1144 - val_loss: 0.1047\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1139 - val_loss: 0.1071\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1135 - val_loss: 0.1052\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1127 - val_loss: 0.0975\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1122 - val_loss: 0.0989\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1117 - val_loss: 0.0968\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1112 - val_loss: 0.1026\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1107 - val_loss: 0.1030\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1105 - val_loss: 0.1003\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1101 - val_loss: 0.1009\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1100 - val_loss: 0.1014\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1094 - val_loss: 0.1057\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1088 - val_loss: 0.0982\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1085 - val_loss: 0.0980\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1081 - val_loss: 0.0949\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1079 - val_loss: 0.0944\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1076 - val_loss: 0.0928\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1073 - val_loss: 0.0935\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1068 - val_loss: 0.1004\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1066 - val_loss: 0.0927\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1062 - val_loss: 0.0931\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1060 - val_loss: 0.0982\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1059 - val_loss: 0.0875\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1055 - val_loss: 0.0954\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1053 - val_loss: 0.0941\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1050 - val_loss: 0.0928\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1049 - val_loss: 0.0891\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1046 - val_loss: 0.0918\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1041 - val_loss: 0.0917\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1040 - val_loss: 0.0932\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1038 - val_loss: 0.0933\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1036 - val_loss: 0.0893\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1033 - val_loss: 0.0917\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1035 - val_loss: 0.0844\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1032 - val_loss: 0.0878\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1029 - val_loss: 0.0865\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1027 - val_loss: 0.0869\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.1027 - val_loss: 0.0824\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1025 - val_loss: 0.0848\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1024 - val_loss: 0.0871\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1023 - val_loss: 0.0885\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1021 - val_loss: 0.0903\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1019 - val_loss: 0.0882\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1022 - val_loss: 0.0885\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1019 - val_loss: 0.0852\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1016 - val_loss: 0.0959\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1017 - val_loss: 0.0846\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1014 - val_loss: 0.0833\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1011 - val_loss: 0.0853\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1012 - val_loss: 0.0887\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1008 - val_loss: 0.0836\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1009 - val_loss: 0.0841\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1007 - val_loss: 0.0919\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1007 - val_loss: 0.0814\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1004 - val_loss: 0.0852\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1004 - val_loss: 0.0876\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1000 - val_loss: 0.0789\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1003 - val_loss: 0.0788\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0836\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0998 - val_loss: 0.0822\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0997 - val_loss: 0.0879\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0999 - val_loss: 0.0879\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0997 - val_loss: 0.0842\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0995 - val_loss: 0.0802\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0850\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0992 - val_loss: 0.0852\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0787\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0989 - val_loss: 0.0788\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0990 - val_loss: 0.0772\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0817\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0986 - val_loss: 0.0796\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0987 - val_loss: 0.0799\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0775\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0985 - val_loss: 0.0795\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0984 - val_loss: 0.0799\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0983 - val_loss: 0.0791\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0983 - val_loss: 0.0818\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0983 - val_loss: 0.0825\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0980 - val_loss: 0.0827\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0979 - val_loss: 0.0790\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0978 - val_loss: 0.0769\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0978 - val_loss: 0.0758\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0977 - val_loss: 0.0750\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0976 - val_loss: 0.0774\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0976 - val_loss: 0.0753\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0975 - val_loss: 0.0767\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0973 - val_loss: 0.0806\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0974 - val_loss: 0.0851\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0972 - val_loss: 0.0758\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 8\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 4s 135us/sample - loss: 0.1608 - val_loss: 0.1101\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1260 - val_loss: 0.1081\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.1188 - val_loss: 0.0958\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1164 - val_loss: 0.0948\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1145 - val_loss: 0.1011\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1127 - val_loss: 0.1083\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1113 - val_loss: 0.0981\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1101 - val_loss: 0.0976\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1087 - val_loss: 0.1007\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1072 - val_loss: 0.0900\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1062 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0968\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1042 - val_loss: 0.0910\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1034 - val_loss: 0.0967\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1027 - val_loss: 0.0832\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1025 - val_loss: 0.0834\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1018 - val_loss: 0.0802\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1015 - val_loss: 0.0802\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1012 - val_loss: 0.0853\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1009 - val_loss: 0.0822\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1009 - val_loss: 0.0833\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1006 - val_loss: 0.0814\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1005 - val_loss: 0.0854\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0798\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0997 - val_loss: 0.0807\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0997 - val_loss: 0.0790\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0995 - val_loss: 0.0785\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0995 - val_loss: 0.0777\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0992 - val_loss: 0.0787\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0805\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0989 - val_loss: 0.0797\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0987 - val_loss: 0.0790\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.0984 - val_loss: 0.0820\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.0985 - val_loss: 0.0749\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0985 - val_loss: 0.0853\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 47us/sample - loss: 0.0983 - val_loss: 0.0808\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0981 - val_loss: 0.0784\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0979 - val_loss: 0.0782\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 46us/sample - loss: 0.0981 - val_loss: 0.0822\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0977 - val_loss: 0.0758\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0974 - val_loss: 0.0791\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.0806\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0973 - val_loss: 0.0779\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0970 - val_loss: 0.0785\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0971 - val_loss: 0.0787\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0970 - val_loss: 0.0817\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0970 - val_loss: 0.0752\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0790\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0968 - val_loss: 0.0725\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0967 - val_loss: 0.0776\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0964 - val_loss: 0.0752\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0963 - val_loss: 0.0771\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0964 - val_loss: 0.0771\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0961 - val_loss: 0.0795\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0965 - val_loss: 0.0799\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0963 - val_loss: 0.0735\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0960 - val_loss: 0.0813\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0736\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0958 - val_loss: 0.0768\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0958 - val_loss: 0.0774\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0957 - val_loss: 0.0756\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0954 - val_loss: 0.0713\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0956 - val_loss: 0.0731\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0954 - val_loss: 0.0789\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0953 - val_loss: 0.0722\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0952 - val_loss: 0.0761\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0951 - val_loss: 0.0771\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 47us/sample - loss: 0.0950 - val_loss: 0.0729\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0950 - val_loss: 0.0700\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 46us/sample - loss: 0.0949 - val_loss: 0.0776\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.0948 - val_loss: 0.0741\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0947 - val_loss: 0.0731\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0948 - val_loss: 0.0838\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0947 - val_loss: 0.0716\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0736\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0943 - val_loss: 0.0740\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0945 - val_loss: 0.0766\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 47us/sample - loss: 0.0944 - val_loss: 0.0725\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0942 - val_loss: 0.0717\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0942 - val_loss: 0.0749\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0941 - val_loss: 0.0768\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0939 - val_loss: 0.0735\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 45us/sample - loss: 0.0940 - val_loss: 0.0739\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.0938 - val_loss: 0.0703\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.0939 - val_loss: 0.0737\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0937 - val_loss: 0.0709\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0936 - val_loss: 0.0712\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0937 - val_loss: 0.0727\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0935 - val_loss: 0.0745\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0934 - val_loss: 0.0720\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0933 - val_loss: 0.0730\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0726\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0932 - val_loss: 0.0696\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0932 - val_loss: 0.0690\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0706\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0930 - val_loss: 0.0710\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0686\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0928 - val_loss: 0.0717\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0928 - val_loss: 0.0723\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0926 - val_loss: 0.0703\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 16\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 4s 132us/sample - loss: 0.1490 - val_loss: 0.0954\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 46us/sample - loss: 0.1178 - val_loss: 0.1173\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 46us/sample - loss: 0.1161 - val_loss: 0.0951\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.1147 - val_loss: 0.1020\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.1138 - val_loss: 0.1035\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 1s 42us/sample - loss: 0.1128 - val_loss: 0.1061\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 1s 45us/sample - loss: 0.1120 - val_loss: 0.0974\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 45us/sample - loss: 0.1114 - val_loss: 0.1093\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1112 - val_loss: 0.1115\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1105 - val_loss: 0.1022\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1099 - val_loss: 0.1057\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1091 - val_loss: 0.1048\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1088 - val_loss: 0.0993\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1081 - val_loss: 0.1058\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1077 - val_loss: 0.0982\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1070 - val_loss: 0.1005\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 48us/sample - loss: 0.1059 - val_loss: 0.0940\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1058 - val_loss: 0.0910\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1049 - val_loss: 0.0979\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1039 - val_loss: 0.0912\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1033 - val_loss: 0.0925\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1022 - val_loss: 0.0931\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1014 - val_loss: 0.0877\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1006 - val_loss: 0.0849\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0852\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0987 - val_loss: 0.0890\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0985 - val_loss: 0.0841\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0978 - val_loss: 0.0859\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0979 - val_loss: 0.0838\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0970 - val_loss: 0.0807\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0965 - val_loss: 0.0737\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0963 - val_loss: 0.0749\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0761\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0954 - val_loss: 0.0711\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0956 - val_loss: 0.0775\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0957 - val_loss: 0.0766\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0950 - val_loss: 0.0745\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0733\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.0758\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0946 - val_loss: 0.0738\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0944 - val_loss: 0.0746\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0941 - val_loss: 0.0774\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0942 - val_loss: 0.0788\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0739\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0937 - val_loss: 0.0715\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0936 - val_loss: 0.0797\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0939 - val_loss: 0.0730\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0717\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0932 - val_loss: 0.0759\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0935 - val_loss: 0.0739\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0795\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0755\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0929 - val_loss: 0.0792\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0785\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0929 - val_loss: 0.0802\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0926 - val_loss: 0.0686\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0924 - val_loss: 0.0695\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0730\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0920 - val_loss: 0.0715\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0919 - val_loss: 0.0731\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0919 - val_loss: 0.0728\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0916 - val_loss: 0.0688\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0921 - val_loss: 0.0697\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0918 - val_loss: 0.0749\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0916 - val_loss: 0.0736\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0914 - val_loss: 0.0711\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0914 - val_loss: 0.0741\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0914 - val_loss: 0.0711\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0693\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0911 - val_loss: 0.0686\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0909 - val_loss: 0.0672\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0910 - val_loss: 0.0700\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0909 - val_loss: 0.0730\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0908 - val_loss: 0.0680\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0916 - val_loss: 0.0696\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0906 - val_loss: 0.0694\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0907 - val_loss: 0.0699\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0906 - val_loss: 0.0734\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0905 - val_loss: 0.0678\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0903 - val_loss: 0.0783\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0905 - val_loss: 0.0719\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0903 - val_loss: 0.0702\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 48us/sample - loss: 0.0904 - val_loss: 0.0694\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0901 - val_loss: 0.0697\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 45us/sample - loss: 0.0901 - val_loss: 0.0685\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.0899 - val_loss: 0.0665\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0900 - val_loss: 0.0699\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0901 - val_loss: 0.0674\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0899 - val_loss: 0.0677\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0897 - val_loss: 0.0701\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0896 - val_loss: 0.0661\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0894 - val_loss: 0.0663\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0897 - val_loss: 0.0680\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0895 - val_loss: 0.0645\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0900 - val_loss: 0.0704\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0893 - val_loss: 0.0667\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0894 - val_loss: 0.0662\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0893 - val_loss: 0.0773\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0895 - val_loss: 0.0667\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0892 - val_loss: 0.0662\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 32\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 147us/sample - loss: 0.1363 - val_loss: 0.1036\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1172 - val_loss: 0.1154\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1157 - val_loss: 0.1039\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1144 - val_loss: 0.1068\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1131 - val_loss: 0.0984\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.1125 - val_loss: 0.1072\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1117 - val_loss: 0.0973\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1104 - val_loss: 0.1114\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1096 - val_loss: 0.0999\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1084 - val_loss: 0.0976\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1073 - val_loss: 0.1029\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1068 - val_loss: 0.1018\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1065 - val_loss: 0.1051\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1051 - val_loss: 0.0979\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1044 - val_loss: 0.0839\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1032 - val_loss: 0.0881\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1017 - val_loss: 0.0840\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1019 - val_loss: 0.0806\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.1000 - val_loss: 0.0858\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0998 - val_loss: 0.0853\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0989 - val_loss: 0.0830\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0987 - val_loss: 0.0822\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0975 - val_loss: 0.0819\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0971 - val_loss: 0.0873\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0957 - val_loss: 0.0761\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0952 - val_loss: 0.0764\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0954 - val_loss: 0.0714\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0951 - val_loss: 0.0804\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0948 - val_loss: 0.0685\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0938 - val_loss: 0.0699\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0935 - val_loss: 0.0679\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0935 - val_loss: 0.0734\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0933 - val_loss: 0.0707\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0930 - val_loss: 0.0691\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0675\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0928 - val_loss: 0.0675\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0924 - val_loss: 0.0704\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0921 - val_loss: 0.0701\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0920 - val_loss: 0.0674\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0919 - val_loss: 0.0679\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0914 - val_loss: 0.0739\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0913 - val_loss: 0.0730\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0914 - val_loss: 0.0694\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0912 - val_loss: 0.0661\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0909 - val_loss: 0.0656\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0907 - val_loss: 0.0691\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0912 - val_loss: 0.0658\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0907 - val_loss: 0.0648\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0905 - val_loss: 0.0682\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0906 - val_loss: 0.0659\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0902 - val_loss: 0.0678\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0903 - val_loss: 0.0677\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0903 - val_loss: 0.0733\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0898 - val_loss: 0.0699\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0903 - val_loss: 0.0735\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0897 - val_loss: 0.0643\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0896 - val_loss: 0.0665\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0896 - val_loss: 0.0730\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0891 - val_loss: 0.0625\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0893 - val_loss: 0.0723\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0895 - val_loss: 0.0650\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0891 - val_loss: 0.0638\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0892 - val_loss: 0.0631\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0888 - val_loss: 0.0669\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0888 - val_loss: 0.0646\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0886 - val_loss: 0.0635\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0641\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0886 - val_loss: 0.0631\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0886 - val_loss: 0.0627\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0884 - val_loss: 0.0628\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0883 - val_loss: 0.0613\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0884 - val_loss: 0.0611\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0882 - val_loss: 0.0661\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0880 - val_loss: 0.0660\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0660\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0878 - val_loss: 0.0634\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0881 - val_loss: 0.0662\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0878 - val_loss: 0.0649\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0876 - val_loss: 0.0645\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0876 - val_loss: 0.0608\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0644\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0876 - val_loss: 0.0639\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0872 - val_loss: 0.0660\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0871 - val_loss: 0.0657\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0877 - val_loss: 0.0614\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.0624\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.0617\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0876 - val_loss: 0.0632\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0871 - val_loss: 0.0684\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0868 - val_loss: 0.0624\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0867 - val_loss: 0.0609\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0865 - val_loss: 0.0616\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0867 - val_loss: 0.0624\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0866 - val_loss: 0.0616\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0869 - val_loss: 0.0648\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0865 - val_loss: 0.0662\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0864 - val_loss: 0.0666\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0862 - val_loss: 0.0659\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0861 - val_loss: 0.0661\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0863 - val_loss: 0.0624\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 64\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 4s 135us/sample - loss: 0.1339 - val_loss: 0.1026\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1183 - val_loss: 0.1122\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1161 - val_loss: 0.1038\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1150 - val_loss: 0.1001\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1140 - val_loss: 0.1069\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1133 - val_loss: 0.1069\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1129 - val_loss: 0.1024\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1115 - val_loss: 0.1069\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.1101 - val_loss: 0.1087\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.1093 - val_loss: 0.1019\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 45us/sample - loss: 0.1072 - val_loss: 0.0994\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1060 - val_loss: 0.1069\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.1050 - val_loss: 0.1056\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1031 - val_loss: 0.0985\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.1022 - val_loss: 0.0840\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1010 - val_loss: 0.0852\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0991 - val_loss: 0.0914\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0991 - val_loss: 0.0823\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0822\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0973 - val_loss: 0.0829\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0972 - val_loss: 0.0776\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0958 - val_loss: 0.0799\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0957 - val_loss: 0.0866\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0951 - val_loss: 0.0868\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0945 - val_loss: 0.0797\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0939 - val_loss: 0.0733\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0936 - val_loss: 0.0722\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.0936 - val_loss: 0.0724\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0934 - val_loss: 0.0671\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0924 - val_loss: 0.0726\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0678\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0922 - val_loss: 0.0705\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0918 - val_loss: 0.0698\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0917 - val_loss: 0.0688\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0911 - val_loss: 0.0711\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0914 - val_loss: 0.0643\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0906 - val_loss: 0.0674\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0903 - val_loss: 0.0717\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0903 - val_loss: 0.0643\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0898 - val_loss: 0.0627\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0896 - val_loss: 0.0692\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0894 - val_loss: 0.0718\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0895 - val_loss: 0.0640\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0894 - val_loss: 0.0716\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0889 - val_loss: 0.0626\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0889 - val_loss: 0.0679\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0884 - val_loss: 0.0642\n",
      "Epoch 48/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0887 - val_loss: 0.0635\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0881 - val_loss: 0.0649\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0878 - val_loss: 0.0670\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0879 - val_loss: 0.0673\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0875 - val_loss: 0.0692\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0874 - val_loss: 0.0705\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0874 - val_loss: 0.0645\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0875 - val_loss: 0.0661\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0872 - val_loss: 0.0629\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.0631\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0868 - val_loss: 0.0707\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0865 - val_loss: 0.0590\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 1s 45us/sample - loss: 0.0866 - val_loss: 0.0639\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 1s 44us/sample - loss: 0.0864 - val_loss: 0.0650\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0861 - val_loss: 0.0633\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 48us/sample - loss: 0.0865 - val_loss: 0.0607\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 50us/sample - loss: 0.0859 - val_loss: 0.0629\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0861 - val_loss: 0.0595\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0858 - val_loss: 0.0638\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0856 - val_loss: 0.0706\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0857 - val_loss: 0.0608\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0855 - val_loss: 0.0616\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0853 - val_loss: 0.0604\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0853 - val_loss: 0.0632\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.0589\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0854 - val_loss: 0.0622\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0851 - val_loss: 0.0632\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0848 - val_loss: 0.0620\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0846 - val_loss: 0.0613\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0845 - val_loss: 0.0655\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0846 - val_loss: 0.0646\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0842 - val_loss: 0.0629\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0844 - val_loss: 0.0610\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0847 - val_loss: 0.0624\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0842 - val_loss: 0.0648\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0841 - val_loss: 0.0624\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0840 - val_loss: 0.0601\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0838 - val_loss: 0.0609\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0835 - val_loss: 0.0592\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0836 - val_loss: 0.0590\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0836 - val_loss: 0.0684\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0833 - val_loss: 0.0618\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0833 - val_loss: 0.0618\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0833 - val_loss: 0.0594\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0828 - val_loss: 0.0597\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0828 - val_loss: 0.0595\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0829 - val_loss: 0.0595\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0830 - val_loss: 0.0602\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0826 - val_loss: 0.0606\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0828 - val_loss: 0.0628\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0828 - val_loss: 0.0633\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0824 - val_loss: 0.0638\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.0614\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 1, lag: 14, units: 128\n",
      "Train on 33200 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "33200/33200 [==============================] - 5s 152us/sample - loss: 0.1333 - val_loss: 0.1032\n",
      "Epoch 2/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1178 - val_loss: 0.1169\n",
      "Epoch 3/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1162 - val_loss: 0.1055\n",
      "Epoch 4/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.1148 - val_loss: 0.1015\n",
      "Epoch 5/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1146 - val_loss: 0.1140\n",
      "Epoch 6/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.1127 - val_loss: 0.1020\n",
      "Epoch 7/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1110 - val_loss: 0.1073\n",
      "Epoch 8/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1090 - val_loss: 0.0997\n",
      "Epoch 9/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.1071 - val_loss: 0.1013\n",
      "Epoch 10/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1057 - val_loss: 0.0864\n",
      "Epoch 11/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.1038 - val_loss: 0.0883\n",
      "Epoch 12/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1023 - val_loss: 0.0843\n",
      "Epoch 13/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.1007 - val_loss: 0.0889\n",
      "Epoch 14/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0993 - val_loss: 0.0908\n",
      "Epoch 15/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0977 - val_loss: 0.0731\n",
      "Epoch 16/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0968 - val_loss: 0.0714\n",
      "Epoch 17/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0957 - val_loss: 0.0750\n",
      "Epoch 18/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0952 - val_loss: 0.0809\n",
      "Epoch 19/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0943 - val_loss: 0.0701\n",
      "Epoch 20/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0944 - val_loss: 0.0640\n",
      "Epoch 21/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0936 - val_loss: 0.0733\n",
      "Epoch 22/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0933 - val_loss: 0.0719\n",
      "Epoch 23/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0931 - val_loss: 0.0783\n",
      "Epoch 24/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0697\n",
      "Epoch 25/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0922 - val_loss: 0.0706\n",
      "Epoch 26/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0919 - val_loss: 0.0656\n",
      "Epoch 27/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0917 - val_loss: 0.0684\n",
      "Epoch 28/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0914 - val_loss: 0.0682\n",
      "Epoch 29/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0913 - val_loss: 0.0654\n",
      "Epoch 30/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0910 - val_loss: 0.0672\n",
      "Epoch 31/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0905 - val_loss: 0.0649\n",
      "Epoch 32/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0900 - val_loss: 0.0643\n",
      "Epoch 33/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0899 - val_loss: 0.0667\n",
      "Epoch 34/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0897 - val_loss: 0.0621\n",
      "Epoch 35/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0897 - val_loss: 0.0644\n",
      "Epoch 36/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0890 - val_loss: 0.0621\n",
      "Epoch 37/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0885 - val_loss: 0.0644\n",
      "Epoch 38/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0884 - val_loss: 0.0660\n",
      "Epoch 39/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0882 - val_loss: 0.0668\n",
      "Epoch 40/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0880 - val_loss: 0.0597\n",
      "Epoch 41/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0876 - val_loss: 0.0631\n",
      "Epoch 42/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0873 - val_loss: 0.0661\n",
      "Epoch 43/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0871 - val_loss: 0.0654\n",
      "Epoch 44/100\n",
      "33200/33200 [==============================] - 2s 61us/sample - loss: 0.0868 - val_loss: 0.0629\n",
      "Epoch 45/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0861 - val_loss: 0.0614\n",
      "Epoch 46/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0864 - val_loss: 0.0696\n",
      "Epoch 47/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0858 - val_loss: 0.0617\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0855 - val_loss: 0.0607\n",
      "Epoch 49/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0850 - val_loss: 0.0633\n",
      "Epoch 50/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0850 - val_loss: 0.0632\n",
      "Epoch 51/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0848 - val_loss: 0.0616\n",
      "Epoch 52/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0844 - val_loss: 0.0647\n",
      "Epoch 53/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0841 - val_loss: 0.0616\n",
      "Epoch 54/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0838 - val_loss: 0.0614\n",
      "Epoch 55/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0837 - val_loss: 0.0639\n",
      "Epoch 56/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0834 - val_loss: 0.0658\n",
      "Epoch 57/100\n",
      "33200/33200 [==============================] - 2s 52us/sample - loss: 0.0833 - val_loss: 0.0606\n",
      "Epoch 58/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0827 - val_loss: 0.0631\n",
      "Epoch 59/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0826 - val_loss: 0.0617\n",
      "Epoch 60/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0822 - val_loss: 0.0601\n",
      "Epoch 61/100\n",
      "33200/33200 [==============================] - 2s 53us/sample - loss: 0.0822 - val_loss: 0.0603\n",
      "Epoch 62/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0820 - val_loss: 0.0615\n",
      "Epoch 63/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0817 - val_loss: 0.0609\n",
      "Epoch 64/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0818 - val_loss: 0.0617\n",
      "Epoch 65/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0815 - val_loss: 0.0602\n",
      "Epoch 66/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0811 - val_loss: 0.0599\n",
      "Epoch 67/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0809 - val_loss: 0.0642\n",
      "Epoch 68/100\n",
      "33200/33200 [==============================] - 2s 60us/sample - loss: 0.0806 - val_loss: 0.0604\n",
      "Epoch 69/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0804 - val_loss: 0.0596\n",
      "Epoch 70/100\n",
      "33200/33200 [==============================] - 2s 54us/sample - loss: 0.0800 - val_loss: 0.0598\n",
      "Epoch 71/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0802 - val_loss: 0.0593\n",
      "Epoch 72/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0795 - val_loss: 0.0659\n",
      "Epoch 73/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0798 - val_loss: 0.0654\n",
      "Epoch 74/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0796 - val_loss: 0.0599\n",
      "Epoch 75/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0789 - val_loss: 0.0592\n",
      "Epoch 76/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0790 - val_loss: 0.0595\n",
      "Epoch 77/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0786 - val_loss: 0.0584\n",
      "Epoch 78/100\n",
      "33200/33200 [==============================] - 2s 55us/sample - loss: 0.0788 - val_loss: 0.0627\n",
      "Epoch 79/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0781 - val_loss: 0.0630\n",
      "Epoch 80/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0779 - val_loss: 0.0604\n",
      "Epoch 81/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0779 - val_loss: 0.0592\n",
      "Epoch 82/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0776 - val_loss: 0.0618\n",
      "Epoch 83/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0771 - val_loss: 0.0617\n",
      "Epoch 84/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0770 - val_loss: 0.0615\n",
      "Epoch 85/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0769 - val_loss: 0.0629\n",
      "Epoch 86/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0764 - val_loss: 0.0611\n",
      "Epoch 87/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0763 - val_loss: 0.0594\n",
      "Epoch 88/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0762 - val_loss: 0.0622\n",
      "Epoch 89/100\n",
      "33200/33200 [==============================] - 2s 59us/sample - loss: 0.0755 - val_loss: 0.0608\n",
      "Epoch 90/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0755 - val_loss: 0.0626\n",
      "Epoch 91/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0753 - val_loss: 0.0593\n",
      "Epoch 92/100\n",
      "33200/33200 [==============================] - 2s 51us/sample - loss: 0.0748 - val_loss: 0.0613\n",
      "Epoch 93/100\n",
      "33200/33200 [==============================] - 2s 49us/sample - loss: 0.0746 - val_loss: 0.0619\n",
      "Epoch 94/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0743 - val_loss: 0.0597\n",
      "Epoch 95/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0739 - val_loss: 0.0606\n",
      "Epoch 96/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0738 - val_loss: 0.0616\n",
      "Epoch 97/100\n",
      "33200/33200 [==============================] - 2s 58us/sample - loss: 0.0736 - val_loss: 0.0641\n",
      "Epoch 98/100\n",
      "33200/33200 [==============================] - 2s 56us/sample - loss: 0.0736 - val_loss: 0.0607\n",
      "Epoch 99/100\n",
      "33200/33200 [==============================] - 2s 57us/sample - loss: 0.0729 - val_loss: 0.0618\n",
      "Epoch 100/100\n",
      "33200/33200 [==============================] - 2s 48us/sample - loss: 0.0726 - val_loss: 0.0604\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 2\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 137us/sample - loss: 0.1826 - val_loss: 0.1566\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1457 - val_loss: 0.1275\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1345 - val_loss: 0.1219\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 45us/sample - loss: 0.1296 - val_loss: 0.1202\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 44us/sample - loss: 0.1267 - val_loss: 0.1199\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1249 - val_loss: 0.1185\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 46us/sample - loss: 0.1239 - val_loss: 0.1170\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 45us/sample - loss: 0.1231 - val_loss: 0.1174\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1226 - val_loss: 0.1156\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1221 - val_loss: 0.1174\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 48us/sample - loss: 0.1216 - val_loss: 0.1151\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1212 - val_loss: 0.1145\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1209 - val_loss: 0.1150\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 3s 74us/sample - loss: 0.1206 - val_loss: 0.1149\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1204 - val_loss: 0.1150\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1201 - val_loss: 0.1161\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1199 - val_loss: 0.1148\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1197 - val_loss: 0.1144\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 1s 44us/sample - loss: 0.1195 - val_loss: 0.1150\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1193 - val_loss: 0.1136\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1191 - val_loss: 0.1145\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 45us/sample - loss: 0.1192 - val_loss: 0.1133\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1187 - val_loss: 0.1140\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1187 - val_loss: 0.1124\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1185 - val_loss: 0.1124\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1184 - val_loss: 0.1126\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1181 - val_loss: 0.1131\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1181 - val_loss: 0.1128\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1180 - val_loss: 0.1145\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 46us/sample - loss: 0.1178 - val_loss: 0.1124\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1176 - val_loss: 0.1127\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1175 - val_loss: 0.1133\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1174 - val_loss: 0.1119\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1174 - val_loss: 0.1122\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.1173 - val_loss: 0.1114\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1171 - val_loss: 0.1134\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1170 - val_loss: 0.1125\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1168 - val_loss: 0.1114\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1167 - val_loss: 0.1117\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1168 - val_loss: 0.1112\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1166 - val_loss: 0.1110\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1165 - val_loss: 0.1133\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1164 - val_loss: 0.1123\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1164 - val_loss: 0.1106\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1162 - val_loss: 0.1106\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.1105\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1161 - val_loss: 0.1109\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1160 - val_loss: 0.1103\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1159 - val_loss: 0.1104\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1159 - val_loss: 0.1107\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1158 - val_loss: 0.1105\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1159 - val_loss: 0.1109\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1157 - val_loss: 0.1096\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1157 - val_loss: 0.1111\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1155 - val_loss: 0.1106\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1155 - val_loss: 0.1097\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1154 - val_loss: 0.1109\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1154 - val_loss: 0.1078\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1153 - val_loss: 0.1094\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1153 - val_loss: 0.1103\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1153 - val_loss: 0.1093\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1152 - val_loss: 0.1099\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1150 - val_loss: 0.1101\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1151 - val_loss: 0.1096\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1150 - val_loss: 0.1099\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1150 - val_loss: 0.1095\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1149 - val_loss: 0.1145\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1148 - val_loss: 0.1099\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1149 - val_loss: 0.1094\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1148 - val_loss: 0.1095\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1147 - val_loss: 0.1102\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1146 - val_loss: 0.1103\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1146 - val_loss: 0.1093\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1146 - val_loss: 0.1094\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1146 - val_loss: 0.1099\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1145 - val_loss: 0.1099\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1144 - val_loss: 0.1086\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1144 - val_loss: 0.1085\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1143 - val_loss: 0.1116\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1143 - val_loss: 0.1083\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1143 - val_loss: 0.1090\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1142 - val_loss: 0.1107\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1141 - val_loss: 0.1082\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1142 - val_loss: 0.1090\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1140 - val_loss: 0.1081\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1141 - val_loss: 0.1094\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1141 - val_loss: 0.1091\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1140 - val_loss: 0.1111\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1140 - val_loss: 0.1092\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1141 - val_loss: 0.1076\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1139 - val_loss: 0.1080\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1138 - val_loss: 0.1098\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1139 - val_loss: 0.1093\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1137 - val_loss: 0.1117\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1137 - val_loss: 0.1091\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1137 - val_loss: 0.1094\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1137 - val_loss: 0.1098\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1136 - val_loss: 0.1082\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1135 - val_loss: 0.1100\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1135 - val_loss: 0.1083\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 4\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 133us/sample - loss: 0.1794 - val_loss: 0.1495\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1394 - val_loss: 0.1188\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1265 - val_loss: 0.1157\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1221 - val_loss: 0.1178\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1202 - val_loss: 0.1150\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1190 - val_loss: 0.1133\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1180 - val_loss: 0.1115\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1173 - val_loss: 0.1113\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1167 - val_loss: 0.1123\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1159 - val_loss: 0.1134\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1154 - val_loss: 0.1095\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1149 - val_loss: 0.1071\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1147 - val_loss: 0.1073\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1143 - val_loss: 0.1094\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1141 - val_loss: 0.1091\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1137 - val_loss: 0.1085\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1133 - val_loss: 0.1072\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1130 - val_loss: 0.1096\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1128 - val_loss: 0.1088\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1125 - val_loss: 0.1056\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1123 - val_loss: 0.1090\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1122 - val_loss: 0.1082\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1117 - val_loss: 0.1059\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1117 - val_loss: 0.1048\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1114 - val_loss: 0.1057\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1111 - val_loss: 0.1055\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1108 - val_loss: 0.1054\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1107 - val_loss: 0.1062\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1105 - val_loss: 0.1088\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1104 - val_loss: 0.1042\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1102 - val_loss: 0.1049\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1100 - val_loss: 0.1073\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1099 - val_loss: 0.1038\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1098 - val_loss: 0.1054\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1100 - val_loss: 0.1020\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1095 - val_loss: 0.1113\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1092 - val_loss: 0.1044\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1090 - val_loss: 0.1048\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1090 - val_loss: 0.1045\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1089 - val_loss: 0.1032\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1087 - val_loss: 0.1029\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1085 - val_loss: 0.1029\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1085 - val_loss: 0.1035\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1083 - val_loss: 0.1026\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1082 - val_loss: 0.1004\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1081 - val_loss: 0.1033\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1080 - val_loss: 0.1008\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1079 - val_loss: 0.1007\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1079 - val_loss: 0.1037\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1078 - val_loss: 0.1009\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1076 - val_loss: 0.1005\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1077 - val_loss: 0.1002\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1074 - val_loss: 0.0993\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1074 - val_loss: 0.0998\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1072 - val_loss: 0.0989\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1072 - val_loss: 0.1003\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1071 - val_loss: 0.1030\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1070 - val_loss: 0.0993\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1068 - val_loss: 0.1034\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1067 - val_loss: 0.1003\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1069 - val_loss: 0.1009\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1067 - val_loss: 0.1003\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1066 - val_loss: 0.1001\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1065 - val_loss: 0.0995\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1064 - val_loss: 0.0991\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1065 - val_loss: 0.1003\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1062 - val_loss: 0.1018\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1061 - val_loss: 0.0999\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1061 - val_loss: 0.0975\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1063 - val_loss: 0.0995\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1060 - val_loss: 0.0992\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1061 - val_loss: 0.0989\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1059 - val_loss: 0.0991\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1058 - val_loss: 0.0974\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1057 - val_loss: 0.0970\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1058 - val_loss: 0.0997\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1056 - val_loss: 0.0986\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 48us/sample - loss: 0.1056 - val_loss: 0.0992\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1055 - val_loss: 0.1005\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1053 - val_loss: 0.0979\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1056 - val_loss: 0.0963\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.1053 - val_loss: 0.0972\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 48us/sample - loss: 0.1052 - val_loss: 0.0986\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1053 - val_loss: 0.0973\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1051 - val_loss: 0.0953\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1051 - val_loss: 0.0993\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1050 - val_loss: 0.0975\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1050 - val_loss: 0.0993\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1049 - val_loss: 0.0966\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1050 - val_loss: 0.0937\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1050 - val_loss: 0.0975\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1046 - val_loss: 0.0956\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1048 - val_loss: 0.0967\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1046 - val_loss: 0.0983\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1046 - val_loss: 0.1019\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1046 - val_loss: 0.0972\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1046 - val_loss: 0.0985\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1045 - val_loss: 0.0956\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1044 - val_loss: 0.0983\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1043 - val_loss: 0.0963\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 8\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 149us/sample - loss: 0.1708 - val_loss: 0.1364\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1319 - val_loss: 0.1151\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1212 - val_loss: 0.1130\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1191 - val_loss: 0.1204\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1180 - val_loss: 0.1142\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1175 - val_loss: 0.1173\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1177 - val_loss: 0.1107\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1172 - val_loss: 0.1105\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1167 - val_loss: 0.1100\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1165 - val_loss: 0.1148\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1163 - val_loss: 0.1137\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1158 - val_loss: 0.1094\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1158 - val_loss: 0.1092\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1155 - val_loss: 0.1138\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1153 - val_loss: 0.1101\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1149 - val_loss: 0.1089\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1150 - val_loss: 0.1102\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1147 - val_loss: 0.1141\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1146 - val_loss: 0.1131\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1143 - val_loss: 0.1083\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1140 - val_loss: 0.1110\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1138 - val_loss: 0.1103\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1137 - val_loss: 0.1051\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1135 - val_loss: 0.1054\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1133 - val_loss: 0.1066\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1132 - val_loss: 0.1058\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1129 - val_loss: 0.1066\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1129 - val_loss: 0.1054\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1125 - val_loss: 0.1047\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1123 - val_loss: 0.1034\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1119 - val_loss: 0.1036\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1118 - val_loss: 0.1077\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1115 - val_loss: 0.1113\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1111 - val_loss: 0.1025\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1112 - val_loss: 0.1009\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1105 - val_loss: 0.1054\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1100 - val_loss: 0.1081\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1097 - val_loss: 0.1010\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1091 - val_loss: 0.1017\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1087 - val_loss: 0.1046\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1087 - val_loss: 0.1040\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1084 - val_loss: 0.0987\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1079 - val_loss: 0.1047\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1074 - val_loss: 0.1022\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1072 - val_loss: 0.1002\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1070 - val_loss: 0.1019\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1064 - val_loss: 0.1028\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1064 - val_loss: 0.1003\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1061 - val_loss: 0.1026\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1060 - val_loss: 0.1002\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1053 - val_loss: 0.0987\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1054 - val_loss: 0.0995\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1052 - val_loss: 0.0981\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1050 - val_loss: 0.0993\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1047 - val_loss: 0.0976\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1045 - val_loss: 0.0983\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1042 - val_loss: 0.0984\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1041 - val_loss: 0.0953\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1037 - val_loss: 0.1012\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1036 - val_loss: 0.0966\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1036 - val_loss: 0.1004\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1032 - val_loss: 0.0955\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0977\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1030 - val_loss: 0.0944\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1027 - val_loss: 0.0952\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1027 - val_loss: 0.0950\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1026 - val_loss: 0.0952\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1022 - val_loss: 0.0968\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1022 - val_loss: 0.0946\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1019 - val_loss: 0.0969\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1017 - val_loss: 0.0970\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0960\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1017 - val_loss: 0.0958\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1013 - val_loss: 0.0923\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1010 - val_loss: 0.0927\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1010 - val_loss: 0.0977\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1010 - val_loss: 0.0980\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1006 - val_loss: 0.0967\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1007 - val_loss: 0.0922\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1003 - val_loss: 0.0917\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1004 - val_loss: 0.0940\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1002 - val_loss: 0.0917\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1001 - val_loss: 0.0908\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0999 - val_loss: 0.0911\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0995 - val_loss: 0.0900\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0994 - val_loss: 0.0904\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0994 - val_loss: 0.0904\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0908\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0991 - val_loss: 0.0926\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0993 - val_loss: 0.0898\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0896\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0988 - val_loss: 0.0912\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0987 - val_loss: 0.0891\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0989 - val_loss: 0.0907\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0987 - val_loss: 0.0912\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0983 - val_loss: 0.0895\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0985 - val_loss: 0.0891\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0986 - val_loss: 0.0893\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0980 - val_loss: 0.0986\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0982 - val_loss: 0.0905\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 16\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 135us/sample - loss: 0.1575 - val_loss: 0.1187\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1218 - val_loss: 0.1143\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1193 - val_loss: 0.1122\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1184 - val_loss: 0.1138\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1175 - val_loss: 0.1095\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1170 - val_loss: 0.1161\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1166 - val_loss: 0.1088\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1160 - val_loss: 0.1069\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1155 - val_loss: 0.1086\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1149 - val_loss: 0.1110\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1144 - val_loss: 0.1079\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1135 - val_loss: 0.1070\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1131 - val_loss: 0.1049\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1121 - val_loss: 0.1106\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1111 - val_loss: 0.1084\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1101 - val_loss: 0.1040\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1091 - val_loss: 0.1065\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1081 - val_loss: 0.1094\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1075 - val_loss: 0.1037\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1066 - val_loss: 0.1074\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1059 - val_loss: 0.1033\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1058 - val_loss: 0.1044\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1050 - val_loss: 0.0983\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1049 - val_loss: 0.0981\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.1040 - val_loss: 0.1010\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1038 - val_loss: 0.1023\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1035 - val_loss: 0.1001\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1032 - val_loss: 0.1029\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1027 - val_loss: 0.1015\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1024 - val_loss: 0.0988\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1019 - val_loss: 0.1021\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1019 - val_loss: 0.0994\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1013 - val_loss: 0.0992\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1009 - val_loss: 0.0958\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1008 - val_loss: 0.0928\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1005 - val_loss: 0.0959\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0999 - val_loss: 0.0939\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0996 - val_loss: 0.0958\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0994 - val_loss: 0.0944\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0990 - val_loss: 0.0918\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0990 - val_loss: 0.0919\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0985 - val_loss: 0.0922\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0985 - val_loss: 0.0918\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0982 - val_loss: 0.0937\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0979 - val_loss: 0.0901\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0976 - val_loss: 0.0913\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0974 - val_loss: 0.0907\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0976 - val_loss: 0.0898\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0972 - val_loss: 0.0898\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0970 - val_loss: 0.0910\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0968 - val_loss: 0.0905\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0966 - val_loss: 0.0902\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0966 - val_loss: 0.0895\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 48us/sample - loss: 0.0965 - val_loss: 0.0910\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0963 - val_loss: 0.0895\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0961 - val_loss: 0.0915\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0963 - val_loss: 0.0910\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0960 - val_loss: 0.0892\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0955 - val_loss: 0.0908\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0955 - val_loss: 0.0904\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0954 - val_loss: 0.0900\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0955 - val_loss: 0.0890\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0952 - val_loss: 0.0944\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0951 - val_loss: 0.0893\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0948 - val_loss: 0.0882\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0948 - val_loss: 0.0906\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0947 - val_loss: 0.0902\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0945 - val_loss: 0.0877\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0946 - val_loss: 0.0886\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0947 - val_loss: 0.0881\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0944 - val_loss: 0.0871\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0944 - val_loss: 0.0886\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0943 - val_loss: 0.0870\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0941 - val_loss: 0.0877\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.0940 - val_loss: 0.0862\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0939 - val_loss: 0.0904\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0938 - val_loss: 0.0892\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0939 - val_loss: 0.0850\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0936 - val_loss: 0.0849\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0935 - val_loss: 0.0847\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0934 - val_loss: 0.0863\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0933 - val_loss: 0.0854\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0857\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0934 - val_loss: 0.0862\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0929 - val_loss: 0.0857\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0932 - val_loss: 0.0839\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0930 - val_loss: 0.0845\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0928 - val_loss: 0.0868\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0928 - val_loss: 0.0884\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0931 - val_loss: 0.0847\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0927 - val_loss: 0.0821\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0929 - val_loss: 0.0849\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0925 - val_loss: 0.0843\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0820\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0925 - val_loss: 0.0846\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0925 - val_loss: 0.0861\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0924 - val_loss: 0.0867\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0922 - val_loss: 0.0835\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0998\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0923 - val_loss: 0.0838\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 32\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 146us/sample - loss: 0.1455 - val_loss: 0.1130\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1213 - val_loss: 0.1138\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1199 - val_loss: 0.1134\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1190 - val_loss: 0.1115\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1186 - val_loss: 0.1117\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1182 - val_loss: 0.1174\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1179 - val_loss: 0.1119\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1177 - val_loss: 0.1092\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1171 - val_loss: 0.1129\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1164 - val_loss: 0.1175\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1163 - val_loss: 0.1101\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1152 - val_loss: 0.1093\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1149 - val_loss: 0.1063\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1144 - val_loss: 0.1157\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1136 - val_loss: 0.1124\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1127 - val_loss: 0.1056\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1117 - val_loss: 0.1079\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1103 - val_loss: 0.1111\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1088 - val_loss: 0.1019\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1073 - val_loss: 0.1040\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1068 - val_loss: 0.1000\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1064 - val_loss: 0.1017\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1054 - val_loss: 0.0965\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1051 - val_loss: 0.0958\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1047 - val_loss: 0.0976\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1041 - val_loss: 0.0999\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1036 - val_loss: 0.0979\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1031 - val_loss: 0.1006\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1026 - val_loss: 0.0946\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1018 - val_loss: 0.0926\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1013 - val_loss: 0.0940\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1010 - val_loss: 0.0923\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.1007 - val_loss: 0.0975\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1000 - val_loss: 0.0932\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0998 - val_loss: 0.0942\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0994 - val_loss: 0.0921\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0988 - val_loss: 0.0946\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0987 - val_loss: 0.0928\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0982 - val_loss: 0.0928\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0975 - val_loss: 0.0928\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0975 - val_loss: 0.0939\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0976 - val_loss: 0.0902\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0970 - val_loss: 0.0886\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.0969 - val_loss: 0.0920\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0968 - val_loss: 0.0882\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0965 - val_loss: 0.0908\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.0960 - val_loss: 0.0926\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0959 - val_loss: 0.0906\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0958 - val_loss: 0.0912\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0957 - val_loss: 0.0886\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0953 - val_loss: 0.0900\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0952 - val_loss: 0.0889\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0950 - val_loss: 0.0875\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0948 - val_loss: 0.0902\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0951 - val_loss: 0.0900\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0945 - val_loss: 0.0893\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.0946 - val_loss: 0.0893\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0944 - val_loss: 0.0884\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0941 - val_loss: 0.0888\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0941 - val_loss: 0.0881\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0942 - val_loss: 0.0867\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0937 - val_loss: 0.0944\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0937 - val_loss: 0.0874\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0932 - val_loss: 0.0856\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0932 - val_loss: 0.0894\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0906\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0932 - val_loss: 0.0858\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0933 - val_loss: 0.0873\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0881\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0926 - val_loss: 0.0879\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0853\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0930 - val_loss: 0.0865\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0925 - val_loss: 0.0897\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0836\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0924 - val_loss: 0.0866\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0924 - val_loss: 0.0918\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0855\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0923 - val_loss: 0.0841\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0918 - val_loss: 0.0842\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0862\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0917 - val_loss: 0.0819\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0916 - val_loss: 0.0845\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0915 - val_loss: 0.0874\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0865\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0917 - val_loss: 0.0848\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0912 - val_loss: 0.0844\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0914 - val_loss: 0.0842\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0911 - val_loss: 0.0880\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0911 - val_loss: 0.0877\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0910 - val_loss: 0.0811\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0908 - val_loss: 0.0883\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0856\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0835\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0908 - val_loss: 0.0891\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0905 - val_loss: 0.0840\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0905 - val_loss: 0.0889\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0904 - val_loss: 0.0832\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0904 - val_loss: 0.0906\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0903 - val_loss: 0.0861\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 64\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 136us/sample - loss: 0.1414 - val_loss: 0.1125\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 48us/sample - loss: 0.1220 - val_loss: 0.1127\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.1205 - val_loss: 0.1146\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.1197 - val_loss: 0.1121\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1191 - val_loss: 0.1119\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1185 - val_loss: 0.1213\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1184 - val_loss: 0.1106\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1176 - val_loss: 0.1126\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.1127\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1144 - val_loss: 0.1122\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1131 - val_loss: 0.1062\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1107 - val_loss: 0.1107\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.1035\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1067 - val_loss: 0.1057\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1060 - val_loss: 0.1033\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.1047 - val_loss: 0.1051\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1038 - val_loss: 0.1079\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1032 - val_loss: 0.1018\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1022 - val_loss: 0.1015\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1022 - val_loss: 0.0946\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.1005 - val_loss: 0.0939\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.1002 - val_loss: 0.0942\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0997 - val_loss: 0.0954\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0991 - val_loss: 0.0910\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0984 - val_loss: 0.0933\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0981 - val_loss: 0.1013\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0977 - val_loss: 0.0910\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0976 - val_loss: 0.0924\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0969 - val_loss: 0.0931\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0966 - val_loss: 0.0943\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0964 - val_loss: 0.0898\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0963 - val_loss: 0.0917\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0963 - val_loss: 0.0936\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0958 - val_loss: 0.0880\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.0868\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0957 - val_loss: 0.0902\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0949 - val_loss: 0.0878\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0947 - val_loss: 0.0876\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0946 - val_loss: 0.0901\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0943 - val_loss: 0.0873\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0940 - val_loss: 0.0892\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0941 - val_loss: 0.0908\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0936 - val_loss: 0.0861\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0934 - val_loss: 0.0861\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0931 - val_loss: 0.0842\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0931 - val_loss: 0.0826\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0865\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0928 - val_loss: 0.0817\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0923 - val_loss: 0.0853\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0924 - val_loss: 0.0837\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0920 - val_loss: 0.0867\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0920 - val_loss: 0.0871\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0915 - val_loss: 0.0831\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0916 - val_loss: 0.0873\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0920 - val_loss: 0.0882\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0888\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0910 - val_loss: 0.0869\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0911 - val_loss: 0.0854\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0907 - val_loss: 0.0854\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0906 - val_loss: 0.0855\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0903 - val_loss: 0.0853\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0909 - val_loss: 0.0836\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 49us/sample - loss: 0.0902 - val_loss: 0.0918\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0898 - val_loss: 0.0818\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0899 - val_loss: 0.0849\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0897 - val_loss: 0.0837\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0896 - val_loss: 0.0855\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0896 - val_loss: 0.0800\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0896 - val_loss: 0.0798\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0893 - val_loss: 0.0882\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0891 - val_loss: 0.0849\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0894 - val_loss: 0.0823\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0891 - val_loss: 0.0832\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0842\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0888 - val_loss: 0.0805\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0886 - val_loss: 0.0827\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0882 - val_loss: 0.0897\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0886 - val_loss: 0.0822\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0885 - val_loss: 0.0822\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0883 - val_loss: 0.0798\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0880 - val_loss: 0.0817\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0881 - val_loss: 0.0813\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0879 - val_loss: 0.0784\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0880 - val_loss: 0.0848\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0879 - val_loss: 0.0805\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0877 - val_loss: 0.0820\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0876 - val_loss: 0.0812\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0875 - val_loss: 0.0812\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0876 - val_loss: 0.0880\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0874 - val_loss: 0.0856\n",
      "Epoch 91/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0875 - val_loss: 0.0785\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0873 - val_loss: 0.0889\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0875 - val_loss: 0.0858\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.0777\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0871 - val_loss: 0.0792\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0871 - val_loss: 0.0804\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0870 - val_loss: 0.0838\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0867 - val_loss: 0.0787\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0867 - val_loss: 0.0847\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0866 - val_loss: 0.0820\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 7, units: 128\n",
      "Train on 33960 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33960/33960 [==============================] - 5s 148us/sample - loss: 0.1388 - val_loss: 0.1135\n",
      "Epoch 2/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1228 - val_loss: 0.1193\n",
      "Epoch 3/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1207 - val_loss: 0.1128\n",
      "Epoch 4/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1199 - val_loss: 0.1143\n",
      "Epoch 5/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1192 - val_loss: 0.1119\n",
      "Epoch 6/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1190 - val_loss: 0.1239\n",
      "Epoch 7/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1178 - val_loss: 0.1150\n",
      "Epoch 8/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1163 - val_loss: 0.1117\n",
      "Epoch 9/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1150 - val_loss: 0.1114\n",
      "Epoch 10/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1125 - val_loss: 0.1052\n",
      "Epoch 11/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1107 - val_loss: 0.1066\n",
      "Epoch 12/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1085 - val_loss: 0.0995\n",
      "Epoch 13/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1058 - val_loss: 0.0969\n",
      "Epoch 14/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.1044 - val_loss: 0.1005\n",
      "Epoch 15/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.1032 - val_loss: 0.0971\n",
      "Epoch 16/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.1014 - val_loss: 0.0973\n",
      "Epoch 17/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.1012 - val_loss: 0.1067\n",
      "Epoch 18/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.1004 - val_loss: 0.0926\n",
      "Epoch 19/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0992 - val_loss: 0.0939\n",
      "Epoch 20/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0982 - val_loss: 0.0901\n",
      "Epoch 21/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0976 - val_loss: 0.0906\n",
      "Epoch 22/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0973 - val_loss: 0.0892\n",
      "Epoch 23/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0967 - val_loss: 0.0936\n",
      "Epoch 24/100\n",
      "33960/33960 [==============================] - 2s 60us/sample - loss: 0.0969 - val_loss: 0.0901\n",
      "Epoch 25/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0962 - val_loss: 0.0900\n",
      "Epoch 26/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0954 - val_loss: 0.0957\n",
      "Epoch 27/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0954 - val_loss: 0.0958\n",
      "Epoch 28/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0951 - val_loss: 0.0876\n",
      "Epoch 29/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0946 - val_loss: 0.0868\n",
      "Epoch 30/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0944 - val_loss: 0.0869\n",
      "Epoch 31/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0936 - val_loss: 0.0837\n",
      "Epoch 32/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0882\n",
      "Epoch 33/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0933 - val_loss: 0.0906\n",
      "Epoch 34/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0933 - val_loss: 0.0848\n",
      "Epoch 35/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0928 - val_loss: 0.0844\n",
      "Epoch 36/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0922 - val_loss: 0.0921\n",
      "Epoch 37/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0920 - val_loss: 0.0833\n",
      "Epoch 38/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0919 - val_loss: 0.0832\n",
      "Epoch 39/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0917 - val_loss: 0.0921\n",
      "Epoch 40/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0915 - val_loss: 0.0839\n",
      "Epoch 41/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0914 - val_loss: 0.0869\n",
      "Epoch 42/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0910 - val_loss: 0.0895\n",
      "Epoch 43/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0910 - val_loss: 0.0856\n",
      "Epoch 44/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0907 - val_loss: 0.0840\n",
      "Epoch 45/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0905 - val_loss: 0.0815\n",
      "Epoch 46/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0905 - val_loss: 0.0797\n",
      "Epoch 47/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0901 - val_loss: 0.0865\n",
      "Epoch 48/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0899 - val_loss: 0.0787\n",
      "Epoch 49/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0896 - val_loss: 0.0786\n",
      "Epoch 50/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0896 - val_loss: 0.0853\n",
      "Epoch 51/100\n",
      "33960/33960 [==============================] - 2s 51us/sample - loss: 0.0895 - val_loss: 0.0813\n",
      "Epoch 52/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0892 - val_loss: 0.0866\n",
      "Epoch 53/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0890 - val_loss: 0.0790\n",
      "Epoch 54/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0888 - val_loss: 0.0810\n",
      "Epoch 55/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0893 - val_loss: 0.0891\n",
      "Epoch 56/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0888 - val_loss: 0.0895\n",
      "Epoch 57/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0887 - val_loss: 0.0822\n",
      "Epoch 58/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0885 - val_loss: 0.0796\n",
      "Epoch 59/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0882 - val_loss: 0.0872\n",
      "Epoch 60/100\n",
      "33960/33960 [==============================] - 2s 50us/sample - loss: 0.0879 - val_loss: 0.0870\n",
      "Epoch 61/100\n",
      "33960/33960 [==============================] - 2s 47us/sample - loss: 0.0878 - val_loss: 0.0812\n",
      "Epoch 62/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0802\n",
      "Epoch 63/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0878 - val_loss: 0.0844\n",
      "Epoch 64/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0875 - val_loss: 0.0836\n",
      "Epoch 65/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0873 - val_loss: 0.0834\n",
      "Epoch 66/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0872 - val_loss: 0.0831\n",
      "Epoch 67/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0870 - val_loss: 0.0880\n",
      "Epoch 68/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0869 - val_loss: 0.0772\n",
      "Epoch 69/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0867 - val_loss: 0.0800\n",
      "Epoch 70/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0865 - val_loss: 0.0840\n",
      "Epoch 71/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0862 - val_loss: 0.0791\n",
      "Epoch 72/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0863 - val_loss: 0.0818\n",
      "Epoch 73/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0861 - val_loss: 0.0803\n",
      "Epoch 74/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0861 - val_loss: 0.0826\n",
      "Epoch 75/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0857 - val_loss: 0.0794\n",
      "Epoch 76/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0857 - val_loss: 0.0829\n",
      "Epoch 77/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0855 - val_loss: 0.0889\n",
      "Epoch 78/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.0834\n",
      "Epoch 79/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.0798\n",
      "Epoch 80/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0855 - val_loss: 0.0786\n",
      "Epoch 81/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0850 - val_loss: 0.0797\n",
      "Epoch 82/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0849 - val_loss: 0.0829\n",
      "Epoch 83/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0847 - val_loss: 0.0790\n",
      "Epoch 84/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0848 - val_loss: 0.0912\n",
      "Epoch 85/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0848 - val_loss: 0.0806\n",
      "Epoch 86/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0844 - val_loss: 0.0829\n",
      "Epoch 87/100\n",
      "33960/33960 [==============================] - 2s 58us/sample - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 88/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0841 - val_loss: 0.0784\n",
      "Epoch 89/100\n",
      "33960/33960 [==============================] - 2s 52us/sample - loss: 0.0841 - val_loss: 0.0854\n",
      "Epoch 90/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0838 - val_loss: 0.0832\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0836 - val_loss: 0.0798\n",
      "Epoch 92/100\n",
      "33960/33960 [==============================] - 2s 55us/sample - loss: 0.0836 - val_loss: 0.0887\n",
      "Epoch 93/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0832 - val_loss: 0.0835\n",
      "Epoch 94/100\n",
      "33960/33960 [==============================] - 2s 53us/sample - loss: 0.0831 - val_loss: 0.0776\n",
      "Epoch 95/100\n",
      "33960/33960 [==============================] - 2s 57us/sample - loss: 0.0831 - val_loss: 0.0773\n",
      "Epoch 96/100\n",
      "33960/33960 [==============================] - 2s 56us/sample - loss: 0.0831 - val_loss: 0.0845\n",
      "Epoch 97/100\n",
      "33960/33960 [==============================] - 2s 59us/sample - loss: 0.0826 - val_loss: 0.0841\n",
      "Epoch 98/100\n",
      "33960/33960 [==============================] - 2s 61us/sample - loss: 0.0824 - val_loss: 0.0784\n",
      "Epoch 99/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.0822\n",
      "Epoch 100/100\n",
      "33960/33960 [==============================] - 2s 54us/sample - loss: 0.0824 - val_loss: 0.0804\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 2\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 136us/sample - loss: 0.1764 - val_loss: 0.1411\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1406 - val_loss: 0.1311\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1318 - val_loss: 0.1216\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1272 - val_loss: 0.1176\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1248 - val_loss: 0.1174\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1228 - val_loss: 0.1155\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1212 - val_loss: 0.1158\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1199 - val_loss: 0.1123\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1189 - val_loss: 0.1115\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1179 - val_loss: 0.1101\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1172 - val_loss: 0.1099\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1163 - val_loss: 0.1103\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1157 - val_loss: 0.1094\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1151 - val_loss: 0.1083\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1146 - val_loss: 0.1087\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1142 - val_loss: 0.1088\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1138 - val_loss: 0.1085\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1135 - val_loss: 0.1073\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1133 - val_loss: 0.1072\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1131 - val_loss: 0.1080\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1128 - val_loss: 0.1076\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1126 - val_loss: 0.1061\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1123 - val_loss: 0.1083\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1123 - val_loss: 0.1087\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1121 - val_loss: 0.1080\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1120 - val_loss: 0.1066\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1118 - val_loss: 0.1071\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1116 - val_loss: 0.1073\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1115 - val_loss: 0.1067\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1114 - val_loss: 0.1074\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1113 - val_loss: 0.1063\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1112 - val_loss: 0.1071\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1111 - val_loss: 0.1063\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1110 - val_loss: 0.1073\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1109 - val_loss: 0.1060\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1109 - val_loss: 0.1060\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1107 - val_loss: 0.1067\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1107 - val_loss: 0.1063\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1105 - val_loss: 0.1067\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1104 - val_loss: 0.1060\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1104 - val_loss: 0.1041\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1103 - val_loss: 0.1061\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1104 - val_loss: 0.1063\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1102 - val_loss: 0.1049\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1101 - val_loss: 0.1066\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1100 - val_loss: 0.1065\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1101 - val_loss: 0.1048\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1100 - val_loss: 0.1049\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1100 - val_loss: 0.1046\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1097 - val_loss: 0.1048\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1097 - val_loss: 0.1043\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1096 - val_loss: 0.1084\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1097 - val_loss: 0.1044\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1095 - val_loss: 0.1067\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1095 - val_loss: 0.1040\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1096 - val_loss: 0.1053\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1094 - val_loss: 0.1052\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1094 - val_loss: 0.1044\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1092 - val_loss: 0.1045\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1093 - val_loss: 0.1035\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1093 - val_loss: 0.1043\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1093 - val_loss: 0.1039\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1091 - val_loss: 0.1052\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1092 - val_loss: 0.1041\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1090 - val_loss: 0.1045\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1091 - val_loss: 0.1047\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1090 - val_loss: 0.1038\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1090 - val_loss: 0.1034\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1089 - val_loss: 0.1044\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1089 - val_loss: 0.1037\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1088 - val_loss: 0.1027\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1088 - val_loss: 0.1039\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1088 - val_loss: 0.1040\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1087 - val_loss: 0.1022\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1086 - val_loss: 0.1028\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.1036\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1086 - val_loss: 0.1029\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1085 - val_loss: 0.1036\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1084 - val_loss: 0.1028\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1084 - val_loss: 0.1039\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1084 - val_loss: 0.1034\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1083 - val_loss: 0.1031\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1084 - val_loss: 0.1025\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1084 - val_loss: 0.1030\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1083 - val_loss: 0.1040\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1082 - val_loss: 0.1032\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1082 - val_loss: 0.1031\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1082 - val_loss: 0.1031\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1082 - val_loss: 0.1048\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1081 - val_loss: 0.1026\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1080 - val_loss: 0.1037\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1081 - val_loss: 0.1038\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1080 - val_loss: 0.1022\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1080 - val_loss: 0.1025\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1080 - val_loss: 0.1036\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1080 - val_loss: 0.1023\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.1080 - val_loss: 0.1027\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1079 - val_loss: 0.1035\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1078 - val_loss: 0.1025\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1078 - val_loss: 0.1029\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 4\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 151us/sample - loss: 0.1619 - val_loss: 0.1255\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1305 - val_loss: 0.1203\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1249 - val_loss: 0.1146\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1217 - val_loss: 0.1122\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1198 - val_loss: 0.1178\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1179 - val_loss: 0.1127\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1168 - val_loss: 0.1128\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.1160 - val_loss: 0.1091\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1150 - val_loss: 0.1063\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1140 - val_loss: 0.1067\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1132 - val_loss: 0.1070\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1125 - val_loss: 0.1057\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.1119 - val_loss: 0.1067\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 45us/sample - loss: 0.1115 - val_loss: 0.1097\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 1s 44us/sample - loss: 0.1108 - val_loss: 0.1041\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.1104 - val_loss: 0.1051\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.1100 - val_loss: 0.1033\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.1095 - val_loss: 0.1027\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.1093 - val_loss: 0.1067\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1089 - val_loss: 0.1041\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1085 - val_loss: 0.1078\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1083 - val_loss: 0.1022\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1082 - val_loss: 0.1033\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1081 - val_loss: 0.1052\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1078 - val_loss: 0.1023\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1076 - val_loss: 0.1010\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1075 - val_loss: 0.1023\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.1074 - val_loss: 0.1065\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.1070 - val_loss: 0.1011\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1069 - val_loss: 0.1041\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1067 - val_loss: 0.1051\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1067 - val_loss: 0.1034\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1067 - val_loss: 0.1011\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1064 - val_loss: 0.1013\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1061 - val_loss: 0.1013\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1061 - val_loss: 0.0991\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1058 - val_loss: 0.1021\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1057 - val_loss: 0.1009\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1056 - val_loss: 0.1025\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1056 - val_loss: 0.1050\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1057 - val_loss: 0.1005\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1053 - val_loss: 0.1007\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1052 - val_loss: 0.0998\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1049 - val_loss: 0.0983\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1049 - val_loss: 0.0994\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1048 - val_loss: 0.0991\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 61us/sample - loss: 0.1047 - val_loss: 0.1018\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1044 - val_loss: 0.0983\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1048 - val_loss: 0.0970\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1041 - val_loss: 0.1001\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1039 - val_loss: 0.0986\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1038 - val_loss: 0.1024\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1038 - val_loss: 0.0987\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1037 - val_loss: 0.1034\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0975\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1034 - val_loss: 0.0973\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.1030 - val_loss: 0.0987\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1030 - val_loss: 0.0966\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1029 - val_loss: 0.0984\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1028 - val_loss: 0.0981\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1030 - val_loss: 0.0964\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1026 - val_loss: 0.0973\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1026 - val_loss: 0.0999\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1023 - val_loss: 0.0964\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1021 - val_loss: 0.0971\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1021 - val_loss: 0.0952\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1018 - val_loss: 0.0968\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1016 - val_loss: 0.0960\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1016 - val_loss: 0.0954\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1017 - val_loss: 0.0951\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1015 - val_loss: 0.0948\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1014 - val_loss: 0.0948\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1012 - val_loss: 0.0938\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1011 - val_loss: 0.0981\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1012 - val_loss: 0.1005\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1009 - val_loss: 0.0927\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1008 - val_loss: 0.0945\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1005 - val_loss: 0.0984\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1005 - val_loss: 0.0935\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1006 - val_loss: 0.0917\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1003 - val_loss: 0.0948\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1003 - val_loss: 0.0945\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1000 - val_loss: 0.0955\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1002 - val_loss: 0.0924\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0999 - val_loss: 0.0929\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0996 - val_loss: 0.0949\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0995 - val_loss: 0.0908\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0995 - val_loss: 0.0953\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0993 - val_loss: 0.0925\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0908\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0992 - val_loss: 0.0903\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0992 - val_loss: 0.0901\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0988 - val_loss: 0.0908\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0990 - val_loss: 0.0911\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0991 - val_loss: 0.0905\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0986 - val_loss: 0.0911\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0987 - val_loss: 0.0935\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0913\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0984 - val_loss: 0.0883\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0984 - val_loss: 0.0916\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 8\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 136us/sample - loss: 0.1625 - val_loss: 0.1254\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1263 - val_loss: 0.1108\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1194 - val_loss: 0.1061\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1163 - val_loss: 0.1053\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1149 - val_loss: 0.1081\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1132 - val_loss: 0.1100\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1128 - val_loss: 0.1040\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1118 - val_loss: 0.1030\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1110 - val_loss: 0.1032\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1105 - val_loss: 0.1012\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1098 - val_loss: 0.1019\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1093 - val_loss: 0.1003\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1086 - val_loss: 0.1013\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1080 - val_loss: 0.1027\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1072 - val_loss: 0.0999\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1064 - val_loss: 0.1000\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1058 - val_loss: 0.1001\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1054 - val_loss: 0.0990\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1049 - val_loss: 0.1003\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1044 - val_loss: 0.1041\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1039 - val_loss: 0.0995\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1035 - val_loss: 0.0983\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1032 - val_loss: 0.0972\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1027 - val_loss: 0.0976\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1024 - val_loss: 0.0984\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1020 - val_loss: 0.0972\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1018 - val_loss: 0.0968\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.1014 - val_loss: 0.0973\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1011 - val_loss: 0.0956\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1010 - val_loss: 0.0965\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1009 - val_loss: 0.0968\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1004 - val_loss: 0.0962\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1004 - val_loss: 0.0949\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1001 - val_loss: 0.0935\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0997 - val_loss: 0.0938\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0995 - val_loss: 0.0952\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0994 - val_loss: 0.0961\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0991 - val_loss: 0.0940\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0990 - val_loss: 0.0955\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0987 - val_loss: 0.0940\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0985 - val_loss: 0.0914\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0983 - val_loss: 0.0924\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0983 - val_loss: 0.0922\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0980 - val_loss: 0.0908\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0978 - val_loss: 0.0919\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0979 - val_loss: 0.0921\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0976 - val_loss: 0.0917\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0975 - val_loss: 0.0903\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0976 - val_loss: 0.0897\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0969 - val_loss: 0.0919\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0969 - val_loss: 0.0925\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0967 - val_loss: 0.0941\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0966 - val_loss: 0.0896\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0964 - val_loss: 0.0919\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0962 - val_loss: 0.0905\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0963 - val_loss: 0.0896\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0960 - val_loss: 0.0902\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0960 - val_loss: 0.0883\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0957 - val_loss: 0.0878\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0956 - val_loss: 0.0877\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0955 - val_loss: 0.0884\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0953 - val_loss: 0.0879\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0952 - val_loss: 0.0890\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0951 - val_loss: 0.0878\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0948 - val_loss: 0.0872\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0948 - val_loss: 0.0873\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0946 - val_loss: 0.0882\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0944 - val_loss: 0.0864\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0945 - val_loss: 0.0879\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0943 - val_loss: 0.0861\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0940 - val_loss: 0.0855\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0941 - val_loss: 0.0876\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0939 - val_loss: 0.0874\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0938 - val_loss: 0.0885\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0937 - val_loss: 0.0899\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.0859\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0934 - val_loss: 0.0858\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0933 - val_loss: 0.0877\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0932 - val_loss: 0.0847\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0931 - val_loss: 0.0855\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0929 - val_loss: 0.0872\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0849\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0928 - val_loss: 0.0858\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0928 - val_loss: 0.0860\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0926 - val_loss: 0.0880\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0924 - val_loss: 0.0857\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0923 - val_loss: 0.0847\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0922 - val_loss: 0.0861\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0921 - val_loss: 0.0852\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0921 - val_loss: 0.0852\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0921 - val_loss: 0.0840\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0865\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0917 - val_loss: 0.0846\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0918 - val_loss: 0.0845\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0918 - val_loss: 0.0870\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0915 - val_loss: 0.0842\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0880\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0849\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0913 - val_loss: 0.0819\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0884\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 16\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 134us/sample - loss: 0.1432 - val_loss: 0.1123\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1202 - val_loss: 0.1102\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1171 - val_loss: 0.1077\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1151 - val_loss: 0.1099\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1137 - val_loss: 0.1074\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1128 - val_loss: 0.1057\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1121 - val_loss: 0.1125\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1113 - val_loss: 0.1065\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1100 - val_loss: 0.1047\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1094 - val_loss: 0.0994\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1085 - val_loss: 0.1005\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1073 - val_loss: 0.1049\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1066 - val_loss: 0.0991\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1054 - val_loss: 0.0977\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1037 - val_loss: 0.0973\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1031 - val_loss: 0.0993\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.1017 - val_loss: 0.0952\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1010 - val_loss: 0.0954\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1007 - val_loss: 0.0954\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1006 - val_loss: 0.0935\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0998 - val_loss: 0.0931\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0989 - val_loss: 0.0911\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0997 - val_loss: 0.0936\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0981 - val_loss: 0.0909\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0975 - val_loss: 0.0911\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0977 - val_loss: 0.0895\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0975 - val_loss: 0.0908\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0970 - val_loss: 0.0910\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0965 - val_loss: 0.0891\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0963 - val_loss: 0.0893\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0962 - val_loss: 0.0892\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0957 - val_loss: 0.0896\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0961 - val_loss: 0.0932\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0958 - val_loss: 0.0886\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0952 - val_loss: 0.0899\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0951 - val_loss: 0.0962\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0950 - val_loss: 0.0910\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0947 - val_loss: 0.0888\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0948 - val_loss: 0.0885\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0946 - val_loss: 0.0874\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0942 - val_loss: 0.0871\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0942 - val_loss: 0.0883\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0937 - val_loss: 0.0893\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0938 - val_loss: 0.0890\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0937 - val_loss: 0.0886\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0936 - val_loss: 0.0890\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.0908\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0933 - val_loss: 0.0864\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0932 - val_loss: 0.0884\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0866\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0931 - val_loss: 0.0911\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0859\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0923 - val_loss: 0.0875\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0927 - val_loss: 0.0873\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0921 - val_loss: 0.0897\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0919 - val_loss: 0.0892\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0922 - val_loss: 0.0889\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0921 - val_loss: 0.0849\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0918 - val_loss: 0.0874\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0918 - val_loss: 0.0890\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0921 - val_loss: 0.0904\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0915 - val_loss: 0.0884\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0917 - val_loss: 0.0897\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0912 - val_loss: 0.0891\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0911 - val_loss: 0.0872\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0916 - val_loss: 0.0878\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0913 - val_loss: 0.0872\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0911 - val_loss: 0.0866\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0913 - val_loss: 0.0859\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0908 - val_loss: 0.0877\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0908 - val_loss: 0.0872\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0911 - val_loss: 0.0869\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0909 - val_loss: 0.0870\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0907 - val_loss: 0.0895\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0904 - val_loss: 0.0855\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0903 - val_loss: 0.0869\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0903 - val_loss: 0.0837\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0902 - val_loss: 0.0884\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0902 - val_loss: 0.0869\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0904 - val_loss: 0.0852\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0900 - val_loss: 0.0896\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0900 - val_loss: 0.0841\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0900 - val_loss: 0.0869\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0899 - val_loss: 0.0851\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0897 - val_loss: 0.0853\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0898 - val_loss: 0.0854\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0897 - val_loss: 0.0863\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0896 - val_loss: 0.0843\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0894 - val_loss: 0.0852\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0897 - val_loss: 0.0864\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0895 - val_loss: 0.0876\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.0878\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0891 - val_loss: 0.0842\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0895 - val_loss: 0.0901\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0893 - val_loss: 0.0870\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0889 - val_loss: 0.0853\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0890 - val_loss: 0.0865\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0889 - val_loss: 0.0868\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0888 - val_loss: 0.0836\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0852\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 32\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 4s 133us/sample - loss: 0.1401 - val_loss: 0.1074\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1167 - val_loss: 0.1070\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1155 - val_loss: 0.1072\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1145 - val_loss: 0.1085\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1131 - val_loss: 0.1042\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1124 - val_loss: 0.1027\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1118 - val_loss: 0.1122\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1113 - val_loss: 0.1053\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1100 - val_loss: 0.1035\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1087 - val_loss: 0.0985\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1078 - val_loss: 0.0995\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1061 - val_loss: 0.1019\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.1046 - val_loss: 0.0975\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1034 - val_loss: 0.0965\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1022 - val_loss: 0.0954\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1014 - val_loss: 0.1017\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.1001 - val_loss: 0.0938\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0998 - val_loss: 0.0955\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0991 - val_loss: 0.0953\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0986 - val_loss: 0.0945\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0979 - val_loss: 0.0945\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0975 - val_loss: 0.0932\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0977 - val_loss: 0.0941\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0962 - val_loss: 0.0939\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0958 - val_loss: 0.0919\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0953 - val_loss: 0.0902\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0953 - val_loss: 0.0919\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0948 - val_loss: 0.0877\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0943 - val_loss: 0.0921\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0941 - val_loss: 0.0895\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0938 - val_loss: 0.0907\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 49us/sample - loss: 0.0935 - val_loss: 0.0872\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 46us/sample - loss: 0.0937 - val_loss: 0.0885\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0936 - val_loss: 0.0883\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.0927 - val_loss: 0.0859\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 1s 44us/sample - loss: 0.0926 - val_loss: 0.0882\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.0925 - val_loss: 0.0906\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0920 - val_loss: 0.0849\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0883\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0917 - val_loss: 0.0877\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0921 - val_loss: 0.0892\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0914 - val_loss: 0.0882\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0915 - val_loss: 0.0882\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0911 - val_loss: 0.0869\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0913 - val_loss: 0.0869\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0907 - val_loss: 0.0848\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0906 - val_loss: 0.0903\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0905 - val_loss: 0.0862\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0903 - val_loss: 0.0885\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0900 - val_loss: 0.0865\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0899 - val_loss: 0.0844\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0898 - val_loss: 0.0879\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0896 - val_loss: 0.0890\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0894 - val_loss: 0.0873\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0893 - val_loss: 0.0915\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0892 - val_loss: 0.0836\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0889 - val_loss: 0.0886\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0891 - val_loss: 0.0823\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0886 - val_loss: 0.0908\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0891 - val_loss: 0.0868\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0887 - val_loss: 0.0879\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0885 - val_loss: 0.0817\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0888 - val_loss: 0.0834\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0882 - val_loss: 0.0873\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0881 - val_loss: 0.0837\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0880 - val_loss: 0.0878\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0856\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0878 - val_loss: 0.0836\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0876 - val_loss: 0.0845\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0876 - val_loss: 0.0809\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0875 - val_loss: 0.0841\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0873 - val_loss: 0.0864\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0872 - val_loss: 0.0821\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0872 - val_loss: 0.0900\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.0851\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0868 - val_loss: 0.0833\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0871 - val_loss: 0.0808\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0868 - val_loss: 0.0860\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0866 - val_loss: 0.0878\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0866 - val_loss: 0.0870\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0866 - val_loss: 0.0888\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0865 - val_loss: 0.0851\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0820\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0864 - val_loss: 0.0841\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0862 - val_loss: 0.0827\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0797\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0860 - val_loss: 0.0902\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0859 - val_loss: 0.0855\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0857 - val_loss: 0.0883\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0858 - val_loss: 0.0813\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0857 - val_loss: 0.0835\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0855 - val_loss: 0.0816\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0853 - val_loss: 0.0814\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0855 - val_loss: 0.0869\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0853 - val_loss: 0.0894\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0852 - val_loss: 0.0798\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0851 - val_loss: 0.0835\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0848 - val_loss: 0.0823\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0850 - val_loss: 0.0803\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0849 - val_loss: 0.0822\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 64\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 134us/sample - loss: 0.1337 - val_loss: 0.1129\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1172 - val_loss: 0.1058\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1159 - val_loss: 0.1079\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1151 - val_loss: 0.1156\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1140 - val_loss: 0.1050\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1129 - val_loss: 0.1030\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1124 - val_loss: 0.1159\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1115 - val_loss: 0.1074\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1098 - val_loss: 0.1030\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1080 - val_loss: 0.0969\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1060 - val_loss: 0.0985\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.1043 - val_loss: 0.0967\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.1026 - val_loss: 0.1006\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1012 - val_loss: 0.0949\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.0999 - val_loss: 0.0898\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 1s 44us/sample - loss: 0.0987 - val_loss: 0.0925\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0976 - val_loss: 0.0901\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0968 - val_loss: 0.0871\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.0962 - val_loss: 0.0854\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 49us/sample - loss: 0.0954 - val_loss: 0.0867\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.0952 - val_loss: 0.0875\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 49us/sample - loss: 0.0944 - val_loss: 0.0866\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 46us/sample - loss: 0.0945 - val_loss: 0.0885\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 47us/sample - loss: 0.0937 - val_loss: 0.0906\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0933 - val_loss: 0.0844\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0926 - val_loss: 0.0822\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0923 - val_loss: 0.0893\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0917 - val_loss: 0.0848\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0914 - val_loss: 0.0791\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0911 - val_loss: 0.0846\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0910 - val_loss: 0.0794\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0908 - val_loss: 0.0807\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0910 - val_loss: 0.0809\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0896 - val_loss: 0.0814\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0897 - val_loss: 0.0867\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0892 - val_loss: 0.0887\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0890 - val_loss: 0.0836\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0886 - val_loss: 0.0826\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0887 - val_loss: 0.0821\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0880 - val_loss: 0.0810\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0881 - val_loss: 0.0823\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0879 - val_loss: 0.0804\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0880 - val_loss: 0.0787\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0876 - val_loss: 0.0806\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0874 - val_loss: 0.0869\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0872 - val_loss: 0.0805\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0871 - val_loss: 0.0789\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0866 - val_loss: 0.0812\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0867 - val_loss: 0.0799\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0866 - val_loss: 0.0877\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0863 - val_loss: 0.0845\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0861 - val_loss: 0.0850\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0858 - val_loss: 0.0828\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0858 - val_loss: 0.0764\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0856 - val_loss: 0.0805\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.0795\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0853 - val_loss: 0.0838\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0853 - val_loss: 0.0759\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0855 - val_loss: 0.0764\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0847 - val_loss: 0.0752\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0850 - val_loss: 0.0792\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0847 - val_loss: 0.0777\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0848 - val_loss: 0.0781\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0846 - val_loss: 0.0770\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0843 - val_loss: 0.0762\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0842 - val_loss: 0.0782\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0843 - val_loss: 0.0790\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0842 - val_loss: 0.0776\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 50us/sample - loss: 0.0838 - val_loss: 0.0789\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0839 - val_loss: 0.0788\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0837 - val_loss: 0.0791\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0837 - val_loss: 0.0794\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0834 - val_loss: 0.0793\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.0834 - val_loss: 0.0774\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 48us/sample - loss: 0.0831 - val_loss: 0.0775\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 1s 43us/sample - loss: 0.0832 - val_loss: 0.0813\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0830 - val_loss: 0.0808\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0831 - val_loss: 0.0771\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0830 - val_loss: 0.0801\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0828 - val_loss: 0.0743\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0827 - val_loss: 0.0799\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0826 - val_loss: 0.0824\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.0777\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0824 - val_loss: 0.0753\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0822 - val_loss: 0.0790\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0822 - val_loss: 0.0777\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0821 - val_loss: 0.0775\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0820 - val_loss: 0.0735\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0820 - val_loss: 0.0847\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0820 - val_loss: 0.0772\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0816 - val_loss: 0.0785\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0817 - val_loss: 0.0770\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0816 - val_loss: 0.0763\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0813 - val_loss: 0.0758\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0814 - val_loss: 0.0788\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0810 - val_loss: 0.0798\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0812 - val_loss: 0.0803\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0812 - val_loss: 0.0778\n",
      " \n",
      " \n",
      " \n",
      "------------------------------------------------\n",
      "fold: 2, lag: 14, units: 128\n",
      "Train on 33820 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "33820/33820 [==============================] - 5s 133us/sample - loss: 0.1330 - val_loss: 0.1151\n",
      "Epoch 2/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1172 - val_loss: 0.1064\n",
      "Epoch 3/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1162 - val_loss: 0.1132\n",
      "Epoch 4/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1153 - val_loss: 0.1178\n",
      "Epoch 5/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1143 - val_loss: 0.1042\n",
      "Epoch 6/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.1128 - val_loss: 0.1035\n",
      "Epoch 7/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.1126 - val_loss: 0.1197\n",
      "Epoch 8/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1104 - val_loss: 0.1104\n",
      "Epoch 9/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1081 - val_loss: 0.1001\n",
      "Epoch 10/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.1054 - val_loss: 0.0939\n",
      "Epoch 11/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.1033 - val_loss: 0.1009\n",
      "Epoch 12/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.1013 - val_loss: 0.0960\n",
      "Epoch 13/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0999 - val_loss: 0.0959\n",
      "Epoch 14/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0979 - val_loss: 0.0888\n",
      "Epoch 15/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0964 - val_loss: 0.0870\n",
      "Epoch 16/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0954 - val_loss: 0.0903\n",
      "Epoch 17/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0949 - val_loss: 0.0850\n",
      "Epoch 18/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0940 - val_loss: 0.0896\n",
      "Epoch 19/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0934 - val_loss: 0.0826\n",
      "Epoch 20/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0937 - val_loss: 0.0892\n",
      "Epoch 21/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0927 - val_loss: 0.0923\n",
      "Epoch 22/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0924 - val_loss: 0.0834\n",
      "Epoch 23/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0923 - val_loss: 0.0887\n",
      "Epoch 24/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0916 - val_loss: 0.0934\n",
      "Epoch 25/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0914 - val_loss: 0.0860\n",
      "Epoch 26/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0907 - val_loss: 0.0813\n",
      "Epoch 27/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0907 - val_loss: 0.0867\n",
      "Epoch 28/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0902 - val_loss: 0.0924\n",
      "Epoch 29/100\n",
      "33820/33820 [==============================] - 2s 51us/sample - loss: 0.0897 - val_loss: 0.0820\n",
      "Epoch 30/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0895 - val_loss: 0.0803\n",
      "Epoch 31/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0894 - val_loss: 0.0827\n",
      "Epoch 32/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0892 - val_loss: 0.0803\n",
      "Epoch 33/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0886 - val_loss: 0.0799\n",
      "Epoch 34/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0887 - val_loss: 0.0812\n",
      "Epoch 35/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0879 - val_loss: 0.0799\n",
      "Epoch 36/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0880 - val_loss: 0.0790\n",
      "Epoch 37/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0876 - val_loss: 0.0846\n",
      "Epoch 38/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0874 - val_loss: 0.0799\n",
      "Epoch 39/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0872 - val_loss: 0.0943\n",
      "Epoch 40/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0870 - val_loss: 0.0798\n",
      "Epoch 41/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0865 - val_loss: 0.0793\n",
      "Epoch 42/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0791\n",
      "Epoch 43/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0860 - val_loss: 0.0866\n",
      "Epoch 44/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0860 - val_loss: 0.0789\n",
      "Epoch 45/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0860 - val_loss: 0.0761\n",
      "Epoch 46/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.0790\n",
      "Epoch 47/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0853 - val_loss: 0.0872\n",
      "Epoch 48/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0849 - val_loss: 0.0765\n",
      "Epoch 49/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0848 - val_loss: 0.0783\n",
      "Epoch 50/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0846 - val_loss: 0.0774\n",
      "Epoch 51/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0845 - val_loss: 0.0788\n",
      "Epoch 52/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0840 - val_loss: 0.0848\n",
      "Epoch 53/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0840 - val_loss: 0.0756\n",
      "Epoch 54/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 55/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0832 - val_loss: 0.0742\n",
      "Epoch 56/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0833 - val_loss: 0.0770\n",
      "Epoch 57/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0831 - val_loss: 0.0764\n",
      "Epoch 58/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0827 - val_loss: 0.0768\n",
      "Epoch 59/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.0785\n",
      "Epoch 60/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0823 - val_loss: 0.0764\n",
      "Epoch 61/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0822 - val_loss: 0.0788\n",
      "Epoch 62/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0821 - val_loss: 0.0747\n",
      "Epoch 63/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0818 - val_loss: 0.0769\n",
      "Epoch 64/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0815 - val_loss: 0.0766\n",
      "Epoch 65/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0814 - val_loss: 0.0752\n",
      "Epoch 66/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0812 - val_loss: 0.0777\n",
      "Epoch 67/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0808 - val_loss: 0.0742\n",
      "Epoch 68/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0806 - val_loss: 0.0749\n",
      "Epoch 69/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0806 - val_loss: 0.0777\n",
      "Epoch 70/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0803 - val_loss: 0.0731\n",
      "Epoch 71/100\n",
      "33820/33820 [==============================] - 2s 52us/sample - loss: 0.0803 - val_loss: 0.0793\n",
      "Epoch 72/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0803 - val_loss: 0.0759\n",
      "Epoch 73/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0796 - val_loss: 0.0746\n",
      "Epoch 74/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0796 - val_loss: 0.0772\n",
      "Epoch 75/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0794 - val_loss: 0.0758\n",
      "Epoch 76/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0793 - val_loss: 0.0802\n",
      "Epoch 77/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0789 - val_loss: 0.0778\n",
      "Epoch 78/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0788 - val_loss: 0.0786\n",
      "Epoch 79/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0784 - val_loss: 0.0747\n",
      "Epoch 80/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0785 - val_loss: 0.0770\n",
      "Epoch 81/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0781 - val_loss: 0.0777\n",
      "Epoch 82/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0777 - val_loss: 0.0760\n",
      "Epoch 83/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0777 - val_loss: 0.0758\n",
      "Epoch 84/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0776 - val_loss: 0.0816\n",
      "Epoch 85/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0772 - val_loss: 0.0826\n",
      "Epoch 86/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0771 - val_loss: 0.0744\n",
      "Epoch 87/100\n",
      "33820/33820 [==============================] - 2s 54us/sample - loss: 0.0768 - val_loss: 0.0813\n",
      "Epoch 88/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0768 - val_loss: 0.0769\n",
      "Epoch 89/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0763 - val_loss: 0.0756\n",
      "Epoch 90/100\n",
      "33820/33820 [==============================] - 2s 60us/sample - loss: 0.0765 - val_loss: 0.0762\n",
      "Epoch 91/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0759 - val_loss: 0.0775\n",
      "Epoch 92/100\n",
      "33820/33820 [==============================] - 2s 53us/sample - loss: 0.0757 - val_loss: 0.0779\n",
      "Epoch 93/100\n",
      "33820/33820 [==============================] - 2s 59us/sample - loss: 0.0754 - val_loss: 0.0770\n",
      "Epoch 94/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0756 - val_loss: 0.0788\n",
      "Epoch 95/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0751 - val_loss: 0.0775\n",
      "Epoch 96/100\n",
      "33820/33820 [==============================] - 2s 58us/sample - loss: 0.0748 - val_loss: 0.0741\n",
      "Epoch 97/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0743 - val_loss: 0.0783\n",
      "Epoch 98/100\n",
      "33820/33820 [==============================] - 2s 56us/sample - loss: 0.0742 - val_loss: 0.0792\n",
      "Epoch 99/100\n",
      "33820/33820 [==============================] - 2s 55us/sample - loss: 0.0741 - val_loss: 0.0775\n",
      "Epoch 100/100\n",
      "33820/33820 [==============================] - 2s 57us/sample - loss: 0.0737 - val_loss: 0.0774\n"
     ]
    }
   ],
   "source": [
    "lag_vec = [7,14]\n",
    "units_vec = [2,4,8,16,32,64,128]\n",
    "results = cross_validation(lag_vec, units_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4822.76705007 3886.20675797 3111.28132285 3157.25823226 2826.67229004\n",
      "   2764.52763042 2611.16679176]\n",
      "  [4257.75325455 3528.09024304 2913.71925009 2841.22830614 2717.85612557\n",
      "   2682.39862533 2808.82141586]]\n",
      "\n",
      " [[4678.02613447 4181.37986706 3534.93085977 3447.41044882 3426.39722388\n",
      "   3093.95271705 3029.11980729]\n",
      "  [4266.86248228 3804.19091127 3528.35159755 3323.83518185 3133.21773406\n",
      "   3079.14930184 3032.95928089]]\n",
      "\n",
      " [[5436.67670614 4833.58008423 4539.20640544 4207.19189982 4320.75024089\n",
      "   4116.90658244 4032.79200846]\n",
      "  [5162.39343099 4597.20228841 4433.76703735 4274.6470166  4126.7024117\n",
      "   3906.3002592  3881.55881083]]]\n",
      "14 64\n"
     ]
    }
   ],
   "source": [
    "MAE = results[2,:]\n",
    "print(MAE)\n",
    "MAE = numpy.sum(MAE, axis=0)\n",
    "ind = numpy.unravel_index(numpy.argmin(MAE, axis=None), MAE.shape)\n",
    "\n",
    "lag = lag_vec[ind[0]]\n",
    "units = units_vec[ind[1]]\n",
    "print(lag,units)\n",
    "\n",
    "# units = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34400 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "34400/34400 [==============================] - 5s 134us/sample - loss: 0.1356 - val_loss: 0.1439\n",
      "Epoch 2/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.1172 - val_loss: 0.1467\n",
      "Epoch 3/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.1154 - val_loss: 0.1507\n",
      "Epoch 4/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.1148 - val_loss: 0.1488\n",
      "Epoch 5/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.1140 - val_loss: 0.1507\n",
      "Epoch 6/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.1132 - val_loss: 0.1500\n",
      "Epoch 7/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.1121 - val_loss: 0.1586\n",
      "Epoch 8/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.1122 - val_loss: 0.1581\n",
      "Epoch 9/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.1102 - val_loss: 0.1576\n",
      "Epoch 10/100\n",
      "34400/34400 [==============================] - 2s 57us/sample - loss: 0.1090 - val_loss: 0.1555\n",
      "Epoch 11/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.1071 - val_loss: 0.1589\n",
      "Epoch 12/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.1061 - val_loss: 0.1606\n",
      "Epoch 13/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.1036 - val_loss: 0.1591\n",
      "Epoch 14/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.1015 - val_loss: 0.1629\n",
      "Epoch 15/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.1001 - val_loss: 0.1600\n",
      "Epoch 16/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0990 - val_loss: 0.1587\n",
      "Epoch 17/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.0974 - val_loss: 0.1566\n",
      "Epoch 18/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0972 - val_loss: 0.1558\n",
      "Epoch 19/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.0956 - val_loss: 0.1541\n",
      "Epoch 20/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0947 - val_loss: 0.1547\n",
      "Epoch 21/100\n",
      "34400/34400 [==============================] - 2s 60us/sample - loss: 0.0944 - val_loss: 0.1534\n",
      "Epoch 22/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0935 - val_loss: 0.1535\n",
      "Epoch 23/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.0933 - val_loss: 0.1588\n",
      "Epoch 24/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0930 - val_loss: 0.1538\n",
      "Epoch 25/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0922 - val_loss: 0.1543\n",
      "Epoch 26/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0919 - val_loss: 0.1562\n",
      "Epoch 27/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0920 - val_loss: 0.1518\n",
      "Epoch 28/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0919 - val_loss: 0.1553\n",
      "Epoch 29/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0917 - val_loss: 0.1534\n",
      "Epoch 30/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0910 - val_loss: 0.1558\n",
      "Epoch 31/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0909 - val_loss: 0.1509\n",
      "Epoch 32/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0906 - val_loss: 0.1572\n",
      "Epoch 33/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0905 - val_loss: 0.1525\n",
      "Epoch 34/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0903 - val_loss: 0.1541\n",
      "Epoch 35/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0898 - val_loss: 0.1564\n",
      "Epoch 36/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0898 - val_loss: 0.1540\n",
      "Epoch 37/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.1555\n",
      "Epoch 38/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0893 - val_loss: 0.1541\n",
      "Epoch 39/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.0889 - val_loss: 0.1549\n",
      "Epoch 40/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0893 - val_loss: 0.1533\n",
      "Epoch 41/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0885 - val_loss: 0.1539\n",
      "Epoch 42/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0887 - val_loss: 0.1533\n",
      "Epoch 43/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0881 - val_loss: 0.1511\n",
      "Epoch 44/100\n",
      "34400/34400 [==============================] - 2s 59us/sample - loss: 0.0883 - val_loss: 0.1526\n",
      "Epoch 45/100\n",
      "34400/34400 [==============================] - 2s 59us/sample - loss: 0.0882 - val_loss: 0.1536\n",
      "Epoch 46/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0877 - val_loss: 0.1559\n",
      "Epoch 47/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0875 - val_loss: 0.1536\n",
      "Epoch 48/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0875 - val_loss: 0.1517\n",
      "Epoch 49/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0871 - val_loss: 0.1495\n",
      "Epoch 50/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0870 - val_loss: 0.1517\n",
      "Epoch 51/100\n",
      "34400/34400 [==============================] - 2s 49us/sample - loss: 0.0868 - val_loss: 0.1553\n",
      "Epoch 52/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0868 - val_loss: 0.1535\n",
      "Epoch 53/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0865 - val_loss: 0.1548\n",
      "Epoch 54/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0860 - val_loss: 0.1552\n",
      "Epoch 55/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0865 - val_loss: 0.1545\n",
      "Epoch 56/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0863 - val_loss: 0.1526\n",
      "Epoch 57/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0859 - val_loss: 0.1550\n",
      "Epoch 58/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0858 - val_loss: 0.1538\n",
      "Epoch 59/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0857 - val_loss: 0.1552\n",
      "Epoch 60/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0853 - val_loss: 0.1559\n",
      "Epoch 61/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0852 - val_loss: 0.1547\n",
      "Epoch 62/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0852 - val_loss: 0.1572\n",
      "Epoch 63/100\n",
      "34400/34400 [==============================] - 2s 57us/sample - loss: 0.0851 - val_loss: 0.1555\n",
      "Epoch 64/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0851 - val_loss: 0.1530\n",
      "Epoch 65/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0847 - val_loss: 0.1558\n",
      "Epoch 66/100\n",
      "34400/34400 [==============================] - 2s 57us/sample - loss: 0.0848 - val_loss: 0.1552\n",
      "Epoch 67/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0843 - val_loss: 0.1574\n",
      "Epoch 68/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0845 - val_loss: 0.1585\n",
      "Epoch 69/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0846 - val_loss: 0.1537\n",
      "Epoch 70/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0843 - val_loss: 0.1577\n",
      "Epoch 71/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0843 - val_loss: 0.1562\n",
      "Epoch 72/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0840 - val_loss: 0.1558\n",
      "Epoch 73/100\n",
      "34400/34400 [==============================] - 2s 57us/sample - loss: 0.0839 - val_loss: 0.1605\n",
      "Epoch 74/100\n",
      "34400/34400 [==============================] - 2s 56us/sample - loss: 0.0838 - val_loss: 0.1585\n",
      "Epoch 75/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0838 - val_loss: 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0836 - val_loss: 0.1577\n",
      "Epoch 77/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0836 - val_loss: 0.1585\n",
      "Epoch 78/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0836 - val_loss: 0.1585\n",
      "Epoch 79/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0832 - val_loss: 0.1587\n",
      "Epoch 80/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0831 - val_loss: 0.1572\n",
      "Epoch 81/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0836 - val_loss: 0.1569\n",
      "Epoch 82/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0831 - val_loss: 0.1573\n",
      "Epoch 83/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0827 - val_loss: 0.1548\n",
      "Epoch 84/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0828 - val_loss: 0.1583\n",
      "Epoch 85/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0830 - val_loss: 0.1564\n",
      "Epoch 86/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0825 - val_loss: 0.1595\n",
      "Epoch 87/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0825 - val_loss: 0.1561\n",
      "Epoch 88/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0823 - val_loss: 0.1601\n",
      "Epoch 89/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0823 - val_loss: 0.1561\n",
      "Epoch 90/100\n",
      "34400/34400 [==============================] - 2s 55us/sample - loss: 0.0826 - val_loss: 0.1571\n",
      "Epoch 91/100\n",
      "34400/34400 [==============================] - 2s 59us/sample - loss: 0.0824 - val_loss: 0.1566\n",
      "Epoch 92/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0819 - val_loss: 0.1575\n",
      "Epoch 93/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0818 - val_loss: 0.1583\n",
      "Epoch 94/100\n",
      "34400/34400 [==============================] - 2s 54us/sample - loss: 0.0818 - val_loss: 0.1602\n",
      "Epoch 95/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0816 - val_loss: 0.1587\n",
      "Epoch 96/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0820 - val_loss: 0.1571\n",
      "Epoch 97/100\n",
      "34400/34400 [==============================] - 2s 53us/sample - loss: 0.0817 - val_loss: 0.1555\n",
      "Epoch 98/100\n",
      "34400/34400 [==============================] - 2s 52us/sample - loss: 0.0815 - val_loss: 0.1588\n",
      "Epoch 99/100\n",
      "34400/34400 [==============================] - 2s 51us/sample - loss: 0.0813 - val_loss: 0.1575\n",
      "Epoch 100/100\n",
      "34400/34400 [==============================] - 2s 58us/sample - loss: 0.0811 - val_loss: 0.1589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 12487.1416015625\n",
      "MAPE: 0.21560324525064883\n",
      "MAE: 7971.335346837198\n",
      "R2 score: 0.18305023430627576\n",
      " \n",
      " \n",
      "---------------------------------------------------\n",
      "Train on 35020 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "35020/35020 [==============================] - 5s 152us/sample - loss: 0.1349 - val_loss: 0.1345\n",
      "Epoch 2/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.1186 - val_loss: 0.1349\n",
      "Epoch 3/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.1161 - val_loss: 0.1352\n",
      "Epoch 4/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.1156 - val_loss: 0.1375\n",
      "Epoch 5/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.1141 - val_loss: 0.1429\n",
      "Epoch 6/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.1135 - val_loss: 0.1566\n",
      "Epoch 7/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.1126 - val_loss: 0.1446\n",
      "Epoch 8/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.1115 - val_loss: 0.1551\n",
      "Epoch 9/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.1104 - val_loss: 0.1583\n",
      "Epoch 10/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.1084 - val_loss: 0.1555\n",
      "Epoch 11/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.1065 - val_loss: 0.1581\n",
      "Epoch 12/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.1052 - val_loss: 0.1550\n",
      "Epoch 13/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.1040 - val_loss: 0.1580\n",
      "Epoch 14/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.1016 - val_loss: 0.1654\n",
      "Epoch 15/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.1001 - val_loss: 0.1589\n",
      "Epoch 16/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0988 - val_loss: 0.1629\n",
      "Epoch 17/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0981 - val_loss: 0.1543\n",
      "Epoch 18/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0974 - val_loss: 0.1580\n",
      "Epoch 19/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.0964 - val_loss: 0.1581\n",
      "Epoch 20/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0960 - val_loss: 0.1489\n",
      "Epoch 21/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0953 - val_loss: 0.1643\n",
      "Epoch 22/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0943 - val_loss: 0.1602\n",
      "Epoch 23/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0942 - val_loss: 0.1510\n",
      "Epoch 24/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0938 - val_loss: 0.1592\n",
      "Epoch 25/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0933 - val_loss: 0.1462\n",
      "Epoch 26/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0937 - val_loss: 0.1540\n",
      "Epoch 27/100\n",
      "35020/35020 [==============================] - 2s 47us/sample - loss: 0.0923 - val_loss: 0.1606\n",
      "Epoch 28/100\n",
      "35020/35020 [==============================] - 2s 48us/sample - loss: 0.0920 - val_loss: 0.1570\n",
      "Epoch 29/100\n",
      "35020/35020 [==============================] - 2s 49us/sample - loss: 0.0924 - val_loss: 0.1598\n",
      "Epoch 30/100\n",
      "35020/35020 [==============================] - 2s 49us/sample - loss: 0.0919 - val_loss: 0.1518\n",
      "Epoch 31/100\n",
      "35020/35020 [==============================] - 2s 49us/sample - loss: 0.0914 - val_loss: 0.1711\n",
      "Epoch 32/100\n",
      "35020/35020 [==============================] - 2s 45us/sample - loss: 0.0913 - val_loss: 0.1632\n",
      "Epoch 33/100\n",
      "35020/35020 [==============================] - 2s 50us/sample - loss: 0.0908 - val_loss: 0.1628\n",
      "Epoch 34/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0905 - val_loss: 0.1689\n",
      "Epoch 35/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0903 - val_loss: 0.1591\n",
      "Epoch 36/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.1706\n",
      "Epoch 37/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0897 - val_loss: 0.1668\n",
      "Epoch 38/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0897 - val_loss: 0.1696\n",
      "Epoch 39/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0893 - val_loss: 0.1727\n",
      "Epoch 40/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0890 - val_loss: 0.1657\n",
      "Epoch 41/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0889 - val_loss: 0.1565\n",
      "Epoch 42/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0888 - val_loss: 0.1698\n",
      "Epoch 43/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0887 - val_loss: 0.1704\n",
      "Epoch 44/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0883 - val_loss: 0.1596\n",
      "Epoch 45/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0882 - val_loss: 0.1652\n",
      "Epoch 46/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0882 - val_loss: 0.1711\n",
      "Epoch 47/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0879 - val_loss: 0.1638\n",
      "Epoch 48/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0877 - val_loss: 0.1771\n",
      "Epoch 49/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0876 - val_loss: 0.1703\n",
      "Epoch 50/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0872 - val_loss: 0.1713\n",
      "Epoch 51/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0874 - val_loss: 0.1805\n",
      "Epoch 52/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0871 - val_loss: 0.1807\n",
      "Epoch 53/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0868 - val_loss: 0.1722\n",
      "Epoch 54/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0870 - val_loss: 0.1635\n",
      "Epoch 55/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0866 - val_loss: 0.1761\n",
      "Epoch 56/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0865 - val_loss: 0.1845\n",
      "Epoch 57/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.0863 - val_loss: 0.1750\n",
      "Epoch 58/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0861 - val_loss: 0.1758\n",
      "Epoch 59/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0859 - val_loss: 0.1770\n",
      "Epoch 60/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.0859 - val_loss: 0.1756\n",
      "Epoch 61/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.0859 - val_loss: 0.1669\n",
      "Epoch 62/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0854 - val_loss: 0.1719\n",
      "Epoch 63/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0855 - val_loss: 0.1775\n",
      "Epoch 64/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0853 - val_loss: 0.1894\n",
      "Epoch 65/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0852 - val_loss: 0.1757\n",
      "Epoch 66/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0848 - val_loss: 0.1796\n",
      "Epoch 67/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0850 - val_loss: 0.1777\n",
      "Epoch 68/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0846 - val_loss: 0.1764\n",
      "Epoch 69/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0846 - val_loss: 0.1894\n",
      "Epoch 70/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0844 - val_loss: 0.1786\n",
      "Epoch 71/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0845 - val_loss: 0.1818\n",
      "Epoch 72/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0843 - val_loss: 0.1730\n",
      "Epoch 73/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0841 - val_loss: 0.1726\n",
      "Epoch 74/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0839 - val_loss: 0.1839\n",
      "Epoch 75/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0838 - val_loss: 0.1767\n",
      "Epoch 76/100\n",
      "35020/35020 [==============================] - 2s 50us/sample - loss: 0.0838 - val_loss: 0.1839\n",
      "Epoch 77/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0837 - val_loss: 0.1697\n",
      "Epoch 78/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0837 - val_loss: 0.1766\n",
      "Epoch 79/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0835 - val_loss: 0.1704\n",
      "Epoch 80/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0832 - val_loss: 0.1716\n",
      "Epoch 81/100\n",
      "35020/35020 [==============================] - 2s 56us/sample - loss: 0.0833 - val_loss: 0.1801\n",
      "Epoch 82/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0833 - val_loss: 0.1792\n",
      "Epoch 83/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0832 - val_loss: 0.1777\n",
      "Epoch 84/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0828 - val_loss: 0.1757\n",
      "Epoch 85/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.1728\n",
      "Epoch 86/100\n",
      "35020/35020 [==============================] - 2s 55us/sample - loss: 0.0827 - val_loss: 0.1771\n",
      "Epoch 87/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0823 - val_loss: 0.1788\n",
      "Epoch 88/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0825 - val_loss: 0.1836\n",
      "Epoch 89/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0825 - val_loss: 0.1800\n",
      "Epoch 90/100\n",
      "35020/35020 [==============================] - 2s 49us/sample - loss: 0.0821 - val_loss: 0.1809\n",
      "Epoch 91/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0819 - val_loss: 0.1735\n",
      "Epoch 92/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0820 - val_loss: 0.1776\n",
      "Epoch 93/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0821 - val_loss: 0.1727\n",
      "Epoch 94/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0819 - val_loss: 0.1678\n",
      "Epoch 95/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0818 - val_loss: 0.1869\n",
      "Epoch 96/100\n",
      "35020/35020 [==============================] - 2s 52us/sample - loss: 0.0818 - val_loss: 0.1795\n",
      "Epoch 97/100\n",
      "35020/35020 [==============================] - 2s 54us/sample - loss: 0.0814 - val_loss: 0.1747\n",
      "Epoch 98/100\n",
      "35020/35020 [==============================] - 2s 50us/sample - loss: 0.0814 - val_loss: 0.1800\n",
      "Epoch 99/100\n",
      "35020/35020 [==============================] - 2s 53us/sample - loss: 0.0814 - val_loss: 0.1887\n",
      "Epoch 100/100\n",
      "35020/35020 [==============================] - 2s 51us/sample - loss: 0.0812 - val_loss: 0.1933\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 14111.8310546875\n",
      "MAPE: 0.8090802180253862\n",
      "MAE: 9697.569332682291\n",
      "R2 score: -1.6440939324426225\n",
      " \n",
      " \n",
      "---------------------------------------------------\n",
      "Train on 35620 samples, validate on 620 samples\n",
      "Epoch 1/100\n",
      "35620/35620 [==============================] - 5s 132us/sample - loss: 0.1326 - val_loss: 0.0815\n",
      "Epoch 2/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.1180 - val_loss: 0.0809\n",
      "Epoch 3/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1160 - val_loss: 0.0809\n",
      "Epoch 4/100\n",
      "35620/35620 [==============================] - 2s 50us/sample - loss: 0.1158 - val_loss: 0.0814\n",
      "Epoch 5/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.1149 - val_loss: 0.0797\n",
      "Epoch 6/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.1134 - val_loss: 0.0804\n",
      "Epoch 7/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1123 - val_loss: 0.0797\n",
      "Epoch 8/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1115 - val_loss: 0.0782\n",
      "Epoch 9/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1095 - val_loss: 0.0779\n",
      "Epoch 10/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1087 - val_loss: 0.0827\n",
      "Epoch 11/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.1082 - val_loss: 0.0788\n",
      "Epoch 12/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.1063 - val_loss: 0.0796\n",
      "Epoch 13/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.1049 - val_loss: 0.0783\n",
      "Epoch 14/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.1034 - val_loss: 0.0764\n",
      "Epoch 15/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.1018 - val_loss: 0.0745\n",
      "Epoch 16/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.1009 - val_loss: 0.0733\n",
      "Epoch 17/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0990 - val_loss: 0.0711\n",
      "Epoch 18/100\n",
      "35620/35620 [==============================] - 2s 50us/sample - loss: 0.0980 - val_loss: 0.0744\n",
      "Epoch 19/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0978 - val_loss: 0.0720\n",
      "Epoch 20/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0965 - val_loss: 0.0715\n",
      "Epoch 21/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0961 - val_loss: 0.0707\n",
      "Epoch 22/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0954 - val_loss: 0.0710\n",
      "Epoch 23/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0954 - val_loss: 0.0712\n",
      "Epoch 24/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0941 - val_loss: 0.0731\n",
      "Epoch 25/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0941 - val_loss: 0.0713\n",
      "Epoch 26/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0934 - val_loss: 0.0709\n",
      "Epoch 27/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0930 - val_loss: 0.0735\n",
      "Epoch 28/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0926 - val_loss: 0.0710\n",
      "Epoch 29/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0925 - val_loss: 0.0706\n",
      "Epoch 30/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0920 - val_loss: 0.0705\n",
      "Epoch 31/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0919 - val_loss: 0.0734\n",
      "Epoch 32/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0915 - val_loss: 0.0712\n",
      "Epoch 33/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0914 - val_loss: 0.0724\n",
      "Epoch 34/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0911 - val_loss: 0.0704\n",
      "Epoch 35/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0906 - val_loss: 0.0720\n",
      "Epoch 36/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0905 - val_loss: 0.0715\n",
      "Epoch 37/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0903 - val_loss: 0.0701\n",
      "Epoch 38/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0900 - val_loss: 0.0721\n",
      "Epoch 39/100\n",
      "35620/35620 [==============================] - 2s 49us/sample - loss: 0.0901 - val_loss: 0.0729\n",
      "Epoch 40/100\n",
      "35620/35620 [==============================] - 2s 45us/sample - loss: 0.0901 - val_loss: 0.0702\n",
      "Epoch 41/100\n",
      "35620/35620 [==============================] - 2s 46us/sample - loss: 0.0896 - val_loss: 0.0745\n",
      "Epoch 42/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0898 - val_loss: 0.0706\n",
      "Epoch 43/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0890 - val_loss: 0.0710\n",
      "Epoch 44/100\n",
      "35620/35620 [==============================] - 2s 58us/sample - loss: 0.0893 - val_loss: 0.0720\n",
      "Epoch 45/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0890 - val_loss: 0.0704\n",
      "Epoch 46/100\n",
      "35620/35620 [==============================] - 2s 57us/sample - loss: 0.0890 - val_loss: 0.0710\n",
      "Epoch 47/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0885 - val_loss: 0.0714\n",
      "Epoch 48/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0882 - val_loss: 0.0728\n",
      "Epoch 49/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0881 - val_loss: 0.0729\n",
      "Epoch 50/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0880 - val_loss: 0.0727\n",
      "Epoch 51/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0876 - val_loss: 0.0730\n",
      "Epoch 52/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0882 - val_loss: 0.0717\n",
      "Epoch 53/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0876 - val_loss: 0.0713\n",
      "Epoch 54/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0873 - val_loss: 0.0766\n",
      "Epoch 55/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0873 - val_loss: 0.0729\n",
      "Epoch 56/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0871 - val_loss: 0.0710\n",
      "Epoch 57/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0868 - val_loss: 0.0713\n",
      "Epoch 58/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0866 - val_loss: 0.0752\n",
      "Epoch 59/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0866 - val_loss: 0.0718\n",
      "Epoch 60/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0863 - val_loss: 0.0717\n",
      "Epoch 61/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0864 - val_loss: 0.0730\n",
      "Epoch 62/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0863 - val_loss: 0.0753\n",
      "Epoch 63/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0860 - val_loss: 0.0703\n",
      "Epoch 64/100\n",
      "35620/35620 [==============================] - 2s 46us/sample - loss: 0.0856 - val_loss: 0.0713\n",
      "Epoch 65/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0856 - val_loss: 0.0732\n",
      "Epoch 66/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0858 - val_loss: 0.0720\n",
      "Epoch 67/100\n",
      "35620/35620 [==============================] - 2s 49us/sample - loss: 0.0856 - val_loss: 0.0713\n",
      "Epoch 68/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0854 - val_loss: 0.0738\n",
      "Epoch 69/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0852 - val_loss: 0.0703\n",
      "Epoch 70/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0851 - val_loss: 0.0719\n",
      "Epoch 71/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0850 - val_loss: 0.0713\n",
      "Epoch 72/100\n",
      "35620/35620 [==============================] - 2s 49us/sample - loss: 0.0848 - val_loss: 0.0695\n",
      "Epoch 73/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0845 - val_loss: 0.0717\n",
      "Epoch 74/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0845 - val_loss: 0.0741\n",
      "Epoch 75/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0842 - val_loss: 0.0715\n",
      "Epoch 76/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0842 - val_loss: 0.0732\n",
      "Epoch 77/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0840 - val_loss: 0.0696\n",
      "Epoch 78/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0840 - val_loss: 0.0727\n",
      "Epoch 79/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0838 - val_loss: 0.0703\n",
      "Epoch 80/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0836 - val_loss: 0.0734\n",
      "Epoch 81/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0834 - val_loss: 0.0719\n",
      "Epoch 82/100\n",
      "35620/35620 [==============================] - 2s 56us/sample - loss: 0.0832 - val_loss: 0.0740\n",
      "Epoch 83/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0835 - val_loss: 0.0708\n",
      "Epoch 84/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0832 - val_loss: 0.0712\n",
      "Epoch 85/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0829 - val_loss: 0.0714\n",
      "Epoch 86/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0827 - val_loss: 0.0704\n",
      "Epoch 87/100\n",
      "35620/35620 [==============================] - 2s 52us/sample - loss: 0.0831 - val_loss: 0.0701\n",
      "Epoch 88/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0826 - val_loss: 0.0735\n",
      "Epoch 89/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0824 - val_loss: 0.0713\n",
      "Epoch 90/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0823 - val_loss: 0.0711\n",
      "Epoch 91/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0825 - val_loss: 0.0706\n",
      "Epoch 92/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0822 - val_loss: 0.0720\n",
      "Epoch 93/100\n",
      "35620/35620 [==============================] - 2s 51us/sample - loss: 0.0820 - val_loss: 0.0731\n",
      "Epoch 94/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0820 - val_loss: 0.0693\n",
      "Epoch 95/100\n",
      "35620/35620 [==============================] - 2s 57us/sample - loss: 0.0817 - val_loss: 0.0709\n",
      "Epoch 96/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0818 - val_loss: 0.0699\n",
      "Epoch 97/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0816 - val_loss: 0.0731\n",
      "Epoch 98/100\n",
      "35620/35620 [==============================] - 2s 55us/sample - loss: 0.0812 - val_loss: 0.0732\n",
      "Epoch 99/100\n",
      "35620/35620 [==============================] - 2s 54us/sample - loss: 0.0815 - val_loss: 0.0711\n",
      "Epoch 100/100\n",
      "35620/35620 [==============================] - 2s 53us/sample - loss: 0.0809 - val_loss: 0.0723\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error: 5542.84375\n",
      "MAPE: 0.13364083289538206\n",
      "MAE: 3627.847345955141\n",
      "R2 score: 0.48519575978271434\n",
      " \n",
      " \n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# lag=14\n",
    "ds=['october','november','december']\n",
    "\n",
    "data_LSTM_X, data_LSTM_Y = sequence_data_build(data, lag)\n",
    "totday = int(data_LSTM_X.shape[0]/20)\n",
    "m1 = [totday-61, totday-31, totday, ]\n",
    "m2 = [m1[0]-31, m1[1]-30, m1[2]-31, ]\n",
    "for i in range(len(m1)):\n",
    "    trainX, trainY, testX, testY = train_test_build(data_LSTM_X, data_LSTM_Y, m1[i], m2[i])\n",
    "    testYcopy=testY\n",
    "    saving = True\n",
    "    EarlyStop = True\n",
    "    rmse, mape, mae, r2, history = model_build(trainX, trainY, testX, testY, units, saving, ds[i])\n",
    "        \n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.xlabel(\"Epochs\")\n",
    "    pyplot.ylabel(\"Mean absolute error\")\n",
    "    pyplot.savefig(\"SM2F_\" + ds[i] + \".png\")\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "    print(\"Root mean square error: {0}\".format(rmse))\n",
    "    print(\"MAPE: {0}\".format(mape))\n",
    "    print(\"MAE: {0}\".format(mae))\n",
    "    print(\"R2 score: {0}\".format(r2))\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag vector\n",
      "[7, 14]\n",
      "LSTM units\n",
      "[2, 4, 8, 16, 32, 64, 128]\n",
      "Cross-validation results\n",
      "14 64\n",
      "----------------------------\n",
      "RMSE\n",
      "[[[6270.82080078 5260.97314453 4387.34326172 4482.60009766 4100.24658203\n",
      "   4066.93164062 3902.28417969]\n",
      "  [5701.08105469 4862.9765625  4068.1953125  4014.50341797 3809.52416992\n",
      "   3844.63891602 4052.32250977]]\n",
      "\n",
      " [[6299.99560547 5755.0703125  5071.83789062 4916.08251953 5006.66455078\n",
      "   4596.02392578 4345.10400391]\n",
      "  [5798.83447266 5231.83789062 4950.19140625 4827.86816406 4438.41845703\n",
      "   4477.07324219 4371.40429688]]\n",
      "\n",
      " [[8054.99121094 7558.93701172 7060.42138672 6622.62353516 6839.13134766\n",
      "   6735.82080078 6660.04931641]\n",
      "  [7782.54248047 7225.49414062 6855.95605469 6759.65429688 6748.21337891\n",
      "   6414.30664062 6358.10009766]]]\n",
      "----------------------------\n",
      "MAE\n",
      "[[[0.30030921 0.21361311 0.12598986 0.12768412 0.11348939 0.103996\n",
      "   0.09985002]\n",
      "  [0.20893302 0.15592491 0.11132591 0.10836389 0.11878732 0.10015129\n",
      "   0.10227432]]\n",
      "\n",
      " [[0.26636167 0.22359581 0.14894052 0.14926151 0.13991611 0.12109962\n",
      "   0.1205764 ]\n",
      "  [0.20249728 0.17333011 0.15627859 0.14435087 0.127443   0.11778685\n",
      "   0.1143107 ]]\n",
      "\n",
      " [[0.2332221  0.19906996 0.1689997  0.14883707 0.15700632 0.14484913\n",
      "   0.14635594]\n",
      "  [0.19860789 0.19232971 0.18649394 0.15064836 0.14840172 0.15482215\n",
      "   0.14083892]]]\n",
      "----------------------------\n",
      "MAPE\n",
      "[[[4822.76705007 3886.20675797 3111.28132285 3157.25823226 2826.67229004\n",
      "   2764.52763042 2611.16679176]\n",
      "  [4257.75325455 3528.09024304 2913.71925009 2841.22830614 2717.85612557\n",
      "   2682.39862533 2808.82141586]]\n",
      "\n",
      " [[4678.02613447 4181.37986706 3534.93085977 3447.41044882 3426.39722388\n",
      "   3093.95271705 3029.11980729]\n",
      "  [4266.86248228 3804.19091127 3528.35159755 3323.83518185 3133.21773406\n",
      "   3079.14930184 3032.95928089]]\n",
      "\n",
      " [[5436.67670614 4833.58008423 4539.20640544 4207.19189982 4320.75024089\n",
      "   4116.90658244 4032.79200846]\n",
      "  [5162.39343099 4597.20228841 4433.76703735 4274.6470166  4126.7024117\n",
      "   3906.3002592  3881.55881083]]]\n",
      "----------------------------\n",
      "R2-score\n",
      "[[[0.7109118  0.79652372 0.85849074 0.85227922 0.87640482 0.87840512\n",
      "   0.88805122]\n",
      "  [0.76105606 0.82614549 0.87832953 0.88151995 0.89331015 0.89133425\n",
      "   0.87927711]]\n",
      "\n",
      " [[0.70861129 0.75683923 0.8111474  0.82256855 0.81596975 0.84491964\n",
      "   0.86139061]\n",
      "  [0.75312697 0.79904409 0.82009789 0.82887909 0.85537319 0.85284308\n",
      "   0.85970759]]\n",
      "\n",
      " [[0.61533641 0.66125539 0.70446281 0.73997741 0.72269813 0.7310126\n",
      "   0.73703022]\n",
      "  [0.64091776 0.69048191 0.72133211 0.7291057  0.73002188 0.75607835\n",
      "   0.76033442]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"lag vector\")\n",
    "print(lag_vec)\n",
    "print(\"LSTM units\")\n",
    "print(units_vec)\n",
    "print(\"Cross-validation results\")\n",
    "print(lag,units)\n",
    "print(\"----------------------------\")\n",
    "print(\"RMSE\")\n",
    "print(results[0,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"MAE\")\n",
    "print(results[1,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"MAPE\")\n",
    "print(results[2,:])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"R2-score\")\n",
    "print(results[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1812"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
